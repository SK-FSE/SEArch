[{"generalization": 1, "reinforcement": 1, "learn": 1, "selective": 1, "noise": 1, "injection": 1, "information": 1, "bottleneck": 1, "maximilian": 1, "igl": 1, "": 9, "university": 1, "oxford": 1, "kamil": 1, "ciosek": 1, "microsoft": 6, "research": 6, "cheng": 1, "zhang": 1, "yingzhen": 1, "li": 1, "sam": 1, "devlin": 1, "sebastian": 1, "tschiatschek": 1, "katja": 1, "hofmann": 1, "abstract": 1, "ability": 1, "policies": 1, "generalize": 1, "new": 1, "environments": 1, "key": 1, "broad": 1, "application": 1, "rl": 1, "agents": 1}, {"promise": 1, "approach": 1, "prevent": 1, "agents": 1, "policy": 1, "overfitting": 1, "limit": 1, "set": 1, "train": 1, "environments": 1, "apply": 1, "regularization": 1, "techniques": 1, "originally": 1, "develop": 1, "supervise": 1, "learn": 1}, {"however": 1, "stark": 1, "differences": 1, "supervise": 1, "learn": 1, "rl": 1}, {"discuss": 1, "differences": 1, "propose": 1, "modifications": 1, "exist": 1, "regularization": 1, "techniques": 1, "order": 1, "better": 1, "adapt": 1, "rl": 1}, {"particular": 1, "focus": 1, "regularization": 1, "techniques": 1, "rely": 1, "injection": 1, "noise": 1, "learn": 1, "function": 1, "family": 1, "include": 1, "widely": 1, "use": 1, "approach": 1, "dropout": 1, "batch": 1, "normalization": 1}, {"adapt": 1, "rl": 1, "propose": 1, "selective": 1, "noise": 2, "injection": 1, "sni": 1, "maintain": 1, "regularize": 1, "effect": 2, "inject": 1, "mitigate": 1, "adverse": 1, "gradient": 1, "quality": 1}, {"furthermore": 1, "demonstrate": 1, "information": 1, "bottleneck": 1, "ib": 1, "particularly": 1, "well": 1, "suit": 1, "regularization": 1, "technique": 1, "rl": 2, "effective": 1, "lowdata": 1, "regime": 1, "encounter": 1, "early": 1, "train": 1, "agents": 1}, {"combine": 1, "ib": 1, "sni": 1, "significantly": 1, "outperform": 1, "current": 1, "state": 1, "art": 1, "result": 1, "include": 1, "recently": 1, "propose": 1, "generalization": 1, "benchmark": 1, "coinrun": 1}, {"1": 1, "": 2, "introduction": 1, "deep": 1, "reinforcement": 1, "learn": 1, "rl": 1, "use": 1, "successfully": 1, "train": 1, "policies": 1, "impressive": 1, "performance": 1, "range": 1, "challenge": 1, "task": 2, "include": 1, "atari": 1, "6": 1, "16": 1, "31": 1, "continuous": 1, "control": 1, "35": 1, "46": 1, "longranged": 1, "temporal": 1, "dependencies": 1, "33": 1}, {"settings": 1, "challenge": 1, "able": 1, "successfully": 1, "explore": 1, "learn": 1, "policies": 1, "complex": 1, "enough": 1, "solve": 1, "train": 1, "task": 1}, {"consequently": 1, "focus": 1, "work": 1, "improve": 1, "learn": 1, "performance": 1, "agents": 1, "train": 1, "environment": 1, "less": 1, "attention": 1, "pay": 1, "generalization": 1, "test": 1, "environments": 1}, {"however": 1, "able": 1, "generalize": 1, "key": 1, "requirement": 1, "broad": 1, "application": 1, "autonomous": 1, "agents": 1}, {"spur": 1, "several": 1, "recent": 1, "work": 1, "show": 1, "rl": 1, "agents": 2, "overfit": 1, "train": 1, "environment": 1, "15": 1, "58": 1, "62": 1, "65": 1, "66": 1, "multiple": 1, "benchmarks": 1, "evaluate": 1, "generalization": 1, "capabilities": 1, "propose": 1, "typically": 1, "procedurally": 1, "generate": 1, "modify": 1, "level": 1, "video": 1, "game": 1, "8": 1, "11": 1, "20": 1, "21": 1, "32": 1, "63": 1}, {"learn": 2, "generalizable": 1, "policies": 1, "environments": 1, "remain": 1, "open": 1, "question": 1, "early": 1, "result": 1, "show": 1, "use": 1, "regularization": 1, "techniques": 1, "like": 1, "weight": 1, "decay": 1, "dropout": 1, "batch": 1, "normalization": 1, "establish": 1, "supervise": 1, "paradigm": 1, "also": 1, "useful": 1, "rl": 1, "agents": 1, "11": 1}, {"work": 1, "build": 1, "result": 1, "highlight": 1, "two": 1, "important": 1, "differences": 1, "supervise": 1, "learn": 1, "rl": 1, "need": 1, "take": 1, "account": 1, "regularize": 1, "agents": 1}, {"": 4, "work": 1, "perform": 1, "internship": 1, "microsoft": 1, "research": 1, "cambridge": 1, "cosenior": 1, "author": 1, "33rd": 1, "conference": 1, "neural": 1, "information": 1, "process": 1, "systems": 1, "neurips": 1, "2019": 1, "vancouver": 1, "canada": 1}, {"first": 1, "rl": 1, "train": 1, "data": 1, "depend": 1, "model": 1, "consequently": 1, "regularization": 2, "method": 1, "stochastic": 1, "techniques": 1, "like": 1, "dropout": 1, "batchnorm": 1, "adverse": 1, "effect": 1}, {"example": 1, "inject": 1, "stochasticity": 1, "policy": 1, "lead": 1, "prematurely": 1, "end": 1, "episodes": 1, "prevent": 1, "agent": 1, "observe": 1, "future": 1, "reward": 1}, {"furthermore": 1, "stochastic": 1, "regularization": 1, "destabilize": 1, "train": 1, "learn": 1, "critic": 1, "offpolicy": 1, "importance": 1, "weight": 1}, {"mitigate": 1, "adverse": 1, "effect": 1, "effectively": 1, "apply": 1, "stochastic": 1, "regularization": 1, "techniques": 1, "rl": 1, "propose": 1, "selective": 1, "noise": 1, "injection": 1, "sni": 1}, {"selectively": 1, "apply": 1, "stochasticity": 1, "serve": 1, "regularization": 1, "otherwise": 1, "compute": 1, "output": 1, "regularize": 1, "network": 1, "deterministically": 1}, {"focus": 1, "evaluation": 1, "dropout": 1, "variational": 1, "information": 1, "bottleneck": 1, "vib": 1, "propose": 1, "method": 1, "applicable": 1, "form": 1, "stochastic": 1, "regularization": 1}, {"second": 1, "difference": 1, "rl": 2, "supervise": 1, "learn": 1, "nonstationarity": 1, "datadistribution": 1}, {"despite": 1, "many": 1, "rl": 1, "algorithms": 1, "utilize": 1, "millions": 1, "even": 1, "billions": 1, "observations": 1, "diversity": 1, "state": 1, "encounter": 1, "early": 1, "train": 1, "small": 1, "make": 1, "difficult": 1, "learn": 1, "general": 1, "feature": 1}, {"remain": 1, "open": 1, "question": 1, "deep": 1, "neural": 1, "network": 1, "generalize": 1, "despite": 1, "able": 1, "perfectly": 1, "memorize": 1, "train": 1, "data": 1, "5": 1, "64": 1, "show": 1, "optimal": 1, "point": 1, "worstcase": 1, "generalization": 1, "bind": 1, "require": 1, "model": 1, "rely": 1, "compress": 1, "set": 1, "feature": 1, "fewer": 1, "datapoints": 1, "47": 1, "54": 1}, {"therefore": 1, "bias": 1, "agent": 2, "towards": 1, "general": 1, "feature": 1, "even": 1, "early": 1, "train": 1, "adapt": 1, "information": 2, "bottleneck": 2, "ib": 1, "principle": 1, "actorcritic": 1, "call": 1, "actor": 1, "critic": 1, "ibac": 1}, {"contrast": 1, "regularization": 1, "techniques": 1, "ibac": 1, "directly": 1, "incentivizes": 1, "compression": 1, "input": 1, "feature": 2, "result": 1, "robust": 1, "shift": 1, "datadistribution": 1, "enable": 1, "better": 1, "generalization": 1, "heldout": 1, "test": 1, "environments": 1}, {"evaluate": 1, "propose": 1, "techniques": 1, "use": 1, "proximal": 1, "policy": 1, "optimization": 1, "ppo": 1, "offpolicy": 1, "actorcritic": 1, "algorithm": 1, "two": 1, "challenge": 1, "generalization": 1, "task": 1, "multiroom": 1, "9": 1, "coinrun": 1, "11": 1}, {"show": 1, "benefit": 1, "ibac": 1, "sni": 1, "individually": 1, "well": 1, "combination": 1, "result": 2, "ibacsni": 1, "significantly": 1, "outperform": 1, "previous": 1, "state": 1, "art": 1}, {"2": 2, "": 8, "background": 1, "consider": 1, "distribution": 3, "qm": 1, "markov": 1, "decision": 1, "process": 1, "mdps": 1, "tuple": 1, "sm": 2, "tm": 2, "rm": 2, "pm": 2, "consist": 1, "statespace": 1, "actionspace": 1, "transition": 1, "s0": 2, "reward": 1, "function": 1, "initial": 1, "state": 1, "38": 1}, {"train": 2, "either": 1, "assume": 1, "unlimited": 1, "access": 1, "qm": 1, "like": 1, "section": 1, "52": 1, "multiroom": 1, "restrict": 1, "fix": 1, "set": 1, "environments": 1, "mtrain": 1, "": 3, "m1": 1}, {"": 1}, {"": 1}, {"": 3, "mn": 1, "mi": 1, "q": 1, "like": 1, "section": 1, "53": 1, "coinrun": 1}, {"goal": 1, "learn": 1, "process": 1, "find": 1, "policy": 1, "h": 1, "parameterizedi": 1, "": 6, "maximize": 1, "pt": 1, "discount": 1, "expect": 1, "reward": 1, "j": 1, "eqtm": 1, "pm": 1, "rm": 1, "st": 1}, {"although": 1, "rl": 1, "method": 2, "t0": 1, "offpolicy": 1, "correction": 1, "term": 1, "could": 1, "use": 1, "propose": 1, "sni": 1, "ppo": 1, "46": 1, "show": 1, "strong": 1, "performance": 1, "enable": 1, "direct": 1, "comparison": 1, "prior": 1, "work": 1, "11": 1}, {"actorcritic": 1, "version": 1, "algorithm": 1, "collect": 1, "trajectory": 1, "data": 1, "use": 1, "rollout": 1, "policy": 1, "r": 2, "st": 2, "": 13, "subsequently": 1, "optimize": 1, "surrogate": 1, "loss": 1, "lppo": 1, "ed": 1, "minct": 1, "clipct": 1, "1": 3, "ct": 1, "k": 1, "epochs": 1}, {"advantage": 1, "compute": 1, "a2c": 1, "30": 1}, {"": 2, "st": 1, "efficient": 1, "approximate": 1, "trust": 1, "region": 1, "method": 1, "44": 1, "optimize": 1, "pessimistic": 1, "lower": 1, "bind": 1, "objective": 1, "function": 1, "collect": 1, "data": 1}, {"correspond": 1, "estimate": 1, "gradient": 1, "wrt": 1, "policy": 1, "conservatively": 1, "since": 1, "move": 2, "": 6, "away": 1, "r": 1, "ct": 1, "outside": 1, "choose": 1, "range": 1, "1": 2, "take": 1, "account": 1, "decrease": 1, "performance": 1}, {"similarly": 1, "value": 3, "function": 3, "loss": 1, "minimize": 1, "upper": 1, "bind": 1, "square": 1, "error": 1, "": 11, "1": 3, "v": 6, "lppo": 1, "ed": 1, "max": 1, "2": 4, "r": 3, "clipv": 1, "vtarget": 2, "bootstrapped": 1, "target": 1, "30": 1, "previous": 1}, {"overall": 1, "minimization": 1, "objective": 1, "": 5, "lt": 1, "lppo": 1, "v": 1, "lvppo": 1, "3": 1, "h": 3, "denote": 1, "entropy": 1, "bonus": 1, "encourage": 1, "exploration": 1, "prevent": 1, "policy": 1, "collapse": 1, "prematurely": 1}, {"follow": 1, "discuss": 1, "regularization": 1, "techniques": 1, "use": 1, "mitigate": 1, "overfitting": 1, "state": 1, "mdps": 1, "far": 1, "see": 1, "train": 1}, {"2": 1, "": 3, "21": 1, "regularization": 1, "techniques": 2, "supervise": 2, "learn": 2, "classifiers": 1, "often": 1, "regularize": 1, "use": 1, "variety": 1, "prevent": 1, "overfitting": 1}, {"briefly": 1, "present": 1, "several": 1, "major": 1, "approach": 1, "either": 1, "utilize": 1, "baseline": 1, "extend": 1, "rl": 1, "section": 1, "4": 1}, {"weight": 2, "decay": 1, "also": 1, "call": 1, "l2": 1, "regularization": 1, "reduce": 1, "magnitude": 1, "": 2, "add": 1, "additional": 1, "loss": 1, "term": 1, "w": 1, "12": 1, "kk22": 1}, {"gradient": 1, "update": 1, "form": 1, "": 4, "r": 1, "l": 2, "2w": 1, "kk22": 1, "decay": 1, "weight": 1, "addition": 1, "optimize": 1, "ie": 1}, {"": 3, "1": 1, "w": 1, "r": 1, "l": 1}, {"data": 2, "augmentation": 1, "refer": 1, "change": 1, "distort": 1, "available": 1, "input": 1, "improve": 1, "generalization": 1}, {"work": 1, "use": 1, "modify": 1, "version": 1, "cutout": 1, "12": 1, "propose": 1, "11": 1, "random": 2, "number": 1, "rectangular": 1, "areas": 1, "input": 1, "image": 1, "fill": 1, "color": 1}, {"batch": 1, "normalization": 1, "17": 1, "18": 1, "normalize": 1, "activations": 1, "specify": 1, "layer": 1, "estimate": 1, "mean": 1, "variance": 1, "use": 1, "current": 1, "minibatch": 1}, {"estimate": 1, "batch": 1, "statistics": 1, "introduce": 1, "noise": 1, "show": 1, "help": 1, "improve": 1, "generalization": 1, "28": 1, "supervise": 1, "learn": 1}, {"another": 1, "widely": 1, "use": 1, "regularization": 1, "technique": 1, "deep": 1, "neural": 1, "network": 1, "dropout": 1, "48": 1}, {"train": 1, "individual": 1, "activations": 1, "randomly": 1, "zero": 1, "fix": 1, "probability": 1, "pd": 1, "": 1}, {"serve": 1, "prevent": 1, "coadaptation": 1, "neurons": 1, "apply": 1, "layer": 1, "inside": 1, "network": 1}, {"one": 1, "common": 1, "choice": 1, "follow": 1, "architecture": 1, "apply": 1, "last": 1, "hide": 1, "layer": 1}, {"lastly": 1, "briefly": 1, "describe": 1, "variational": 2, "information": 2, "bottleneck": 2, "vib": 1, "2": 1, "deep": 1, "approximation": 1, "ib": 1, "53": 1}, {"typically": 1, "use": 1, "regularization": 1, "deep": 1, "supervise": 1, "learn": 1, "demonstrate": 1, "section": 1, "5": 1, "adaptation": 1, "ibac": 1, "show": 1, "strong": 1, "performance": 1, "rl": 1}, {"give": 1, "data": 1, "distribution": 1, "px": 1, "": 1, "learn": 1, "model": 1, "p": 1, "yx": 1, "regularize": 1, "insert": 1, "stochastic": 1, "latent": 2, "variable": 2, "z": 3, "minimize": 1, "mutual": 1, "information": 1, "input": 1, "x": 1, "ix": 1, "maximize": 1, "predictive": 1, "power": 1, "ie": 1}, {"iz": 1, "": 1}, {"vib": 1, "objective": 1, "function": 1, "": 5, "lvib": 1, "epxyp": 1, "zx": 2, "log": 1, "q": 2, "yz": 2, "dkl": 1, "p": 2, "zxkqz": 1, "4": 1, "encoder": 1, "decoder": 1, "qz": 1, "approximate": 1, "latent": 1, "marginal": 1, "often": 1, "fix": 1, "normal": 1, "distribution": 1, "n": 1, "0": 1, "hyperparameter": 1}, {"normal": 1, "distribute": 1, "p": 1, "zx": 1, "eq": 1}, {"4": 1, "optimize": 1, "gradient": 1, "decent": 1, "use": 1, "reparameterization": 1, "trick": 1, "25": 1}, {"3": 1, "": 2, "problem": 1, "use": 1, "stochastic": 1, "regularization": 1, "rl": 1, "take": 1, "closer": 1, "look": 1, "prototypical": 1, "objective": 1, "train": 1, "actorcritic": 1, "methods": 1, "highlight": 1, "important": 1, "differences": 1, "supervise": 1, "learn": 1}, {"base": 1, "observations": 1, "propose": 1, "explanation": 1, "find": 1, "stochastic": 1, "optimization": 1, "methods": 1, "less": 1, "effective": 1, "11": 1, "even": 1, "detrimental": 1, "performance": 1, "combine": 1, "regularization": 1, "techniques": 1, "see": 1, "appendix": 1}, {"": 4, "supervise": 1, "learn": 2, "optimization": 1, "objective": 1, "take": 1, "form": 1, "similar": 1, "max": 1, "ed": 1, "log": 1, "p": 2, "yx": 2, "highlight": 1, "model": 1, "update": 1, "blue": 1, "available": 1, "data": 1, "parameters": 1}, {"hand": 1, "rl": 1, "objective": 1, "actor": 1, "maximize": 1, "p": 1, "": 6, "j": 1, "e": 1, "rm": 1, "st": 1, "convencience": 1, "drop": 1, "q": 1, "tm": 1, "pm": 1, "notation": 1, "expectation": 1}, {"learn": 1, "distribution": 1, "": 1, "part": 1, "datageneration": 1, "compute": 1, "gradients": 1, "do": 1, "policy": 1, "gradient": 1, "methods": 1, "require": 1, "logderivative": 1, "trick": 1}, {"class": 1, "deep": 1, "offpolicy": 1, "actorcritic": 1, "methods": 1, "experimentally": 1, "evaluate": 1, "paper": 1, "one": 1, "also": 1, "typically": 1, "use": 1, "policy": 1, "gradient": 2, "theorem": 1, "52": 1, "estimate": 1, "critic": 1, "v": 1, "baseline": 1, "bootstrapping": 1, "reduce": 1, "variance": 1}, {"consequently": 1, "gradient": 1, "estimation": 1, "become": 1, "2": 1, "3": 1, "x": 1, "": 11, "st": 5, "r": 4, "j": 1, "er": 1, "4": 1, "log": 1, "rt": 1, "v": 2, "st1": 1, "5": 2, "utilize": 1, "rollout": 1, "policy": 1, "collect": 1, "trajectories": 1}, {"deviate": 1, "": 1, "similar": 1, "keep": 1, "offpolicy": 1, "correction": 1, "term": 1, "r": 1, "low": 1, "variance": 1}, {"eq": 1}, {"5": 1, "term": 1, "": 2, "st": 1, "update": 1, "highlight": 1, "orange": 1, "additional": 1, "influence": 1, "learn": 1, "policy": 1, "critic": 1, "gradient": 1}, {"3": 1, "": 2, "denote": 1, "superscript": 1}, {"v": 1}, {"assume": 1, "constant": 1, "write": 1, "optimization": 1, "objective": 1, "critic": 1, "": 6, "lvac": 1, "min": 1, "er": 1, "st": 1, "v": 1}, {"st1": 1, "": 7, "rt": 1, "v": 1, "st": 1, "2": 1, "6": 1, "eqs": 1}, {"5": 1, "6": 1, "see": 1, "injection": 1, "noise": 2, "computation": 2, "r": 4, "v": 2, "degrade": 1, "performance": 1, "several": 1, "ways": 1, "rollouts": 1, "use": 1, "rollout": 1, "policy": 2, "": 4, "lead": 2, "undesirable": 1, "action": 1, "potentially": 1, "end": 1, "episodes": 1, "prematurely": 1, "thereby": 1, "deteriorate": 1, "quality": 1, "observe": 1, "data": 1, "ii": 1, "higher": 1, "variance": 4, "offpolicy": 1, "correction": 1, "term": 1, "inject": 1, "different": 1, "increase": 2, "gradient": 2, "iii": 1, "update": 1, "critic": 1}, {"4": 1, "": 2, "method": 1, "utilize": 1, "strength": 1, "noiseinjecting": 1, "regularization": 1, "techniques": 1, "rl": 1, "introduce": 1, "selective": 1, "noise": 1, "injection": 1, "sni": 1, "follow": 1, "section": 1}, {"goal": 1, "allow": 1, "us": 1, "make": 1, "use": 1, "techniques": 1, "mitigate": 1, "adverse": 1, "effect": 1, "add": 1, "stochasticity": 1, "rl": 1, "gradient": 1, "computation": 1}, {"section": 1, "42": 1, "propose": 1, "information": 1, "bottleneck": 1, "actor": 1, "critic": 1, "ibac": 2, "new": 1, "regularization": 1, "method": 2, "detail": 1, "sni": 1, "apply": 1, "result": 1, "stateofthe": 1, "art": 1, "ibacsni": 1}, {"41": 1, "": 4, "selective": 1, "noise": 2, "injection": 1, "identify": 1, "three": 1, "source": 1, "negative": 1, "effect": 1, "due": 1, "need": 1, "mitigate": 1, "rollout": 1, "policy": 1, "r": 2, "critic": 1, "v": 1, "offpolicy": 1, "correction": 1, "term": 1}, {"first": 1, "introduce": 1, "short": 1, "notation": 1, "eq": 1}, {"5": 1, "r": 2, "j": 1, "": 6, "gac": 1, "v": 1}, {"apply": 1, "sni": 1, "regularization": 1, "technique": 1, "rely": 1, "noiseinjection": 1, "need": 1, "able": 1, "temporarily": 1, "suspend": 1, "noise": 1, "compute": 1, "output": 1, "model": 1, "deterministically": 1}, {"possible": 1, "techniques3": 1, "": 1, "example": 1, "dropout": 2, "freeze": 2, "one": 2, "particular": 1, "mask": 1, "vib": 1, "pass": 1, "mode": 1, "instead": 2, "sample": 1, "posterior": 1, "distribution": 1, "batch": 2, "normalization": 1, "either": 1, "utilize": 1, "move": 1, "average": 1, "statistics": 1, "reuse": 1, "statistic": 1, "multiple": 1, "time": 1}, {"formally": 1, "denote": 1, "": 4, "version": 1, "component": 1, "inject": 1, "regularization": 1, "noise": 1, "suspend": 1}, {"note": 1, "mean": 1, "": 2, "deterministic": 1, "example": 1, "network": 1, "approximate": 1, "parameters": 1, "distribution": 1}, {"sni": 1, "modify": 1, "policy": 1, "gradient": 1, "loss": 1, "follow": 1, "use": 1, "v": 2, "critic": 1, "instead": 1, "eqs": 1}, {"5": 1, "6": 1, "eliminate": 1, "unnecessary": 1, "noise": 1, "critic": 1, "ii": 1, "use": 1, "": 4, "r": 2, "rollout": 1, "policy": 1, "instead": 1}, {"regularization": 1, "techniques": 1, "reduce": 1, "probability": 1, "undesirable": 1, "action": 1, "iii": 1, "compute": 1, "policy": 1, "gradient": 1, "mixture": 1, "gradients": 1, "": 23, "follow": 1, "sni": 1, "gac": 3, "r": 3, "v": 3, "1": 1, "7": 1, "first": 1, "term": 1, "guarantee": 1, "lower": 1, "variance": 1, "offpolicy": 1, "importance": 1, "weight": 1, "especially": 1, "important": 1, "early": 1, "train": 1, "network": 1, "yet": 1, "learn": 1, "compensate": 1, "inject": 1, "noise": 1}, {"second": 1, "term": 1, "use": 2, "noiseinjected": 1, "policy": 1, "update": 1, "thereby": 1, "take": 1, "advantage": 1, "regularize": 1, "effect": 1, "still": 1, "reduce": 1, "unnecessary": 1, "variance": 1, "": 3, "r": 1, "v": 1}, {"note": 1, "share": 1, "rollout": 1, "policy": 1, "": 2, "r": 1, "term": 1, "allow": 1, "us": 1, "use": 1, "collect": 1, "data": 1}, {"furthermore": 1, "computations": 1, "share": 1, "term": 1, "parallelize": 1}, {"42": 1, "": 2, "information": 1, "bottleneck": 1, "actor": 1, "critic": 1, "early": 1, "train": 2, "rl": 1, "agent": 1, "often": 1, "face": 1, "little": 1, "variation": 1, "data": 1}, {"observe": 1, "state": 2, "distribute": 1, "around": 1, "initial": 1, "s0": 1, "": 1, "make": 1, "spurious": 1, "correlations": 1, "low": 1, "amount": 1, "data": 1, "likely": 1}, {"furthermore": 1, "neither": 1, "policy": 1, "critic": 1, "sufficiently": 1, "converge": 1, "yet": 1, "high": 1, "variance": 1, "target": 1, "value": 1, "loss": 1, "function": 1}, {"combination": 1, "make": 1, "harder": 1, "less": 1, "likely": 1, "network": 1, "learn": 1, "desirable": 1, "feature": 1, "robust": 1, "shift": 1, "datadistribution": 1, "train": 1, "generalize": 1, "well": 1, "heldout": 1, "test": 1, "mdps": 1}, {"3": 1, "": 1, "work": 2, "focus": 1, "vib": 1, "dropout": 1, "show": 1, "promise": 1, "result": 1, "without": 1, "sni": 1, "see": 1, "section": 1, "5": 1, "leave": 1, "application": 1, "regularization": 1, "techniques": 1, "future": 1}, {"4": 1, "": 1, "counteract": 1, "reduce": 1, "signaltonoise": 1, "ratio": 1, "goal": 1, "explicitly": 1, "bias": 1, "learn": 1, "towards": 1, "find": 1, "compress": 1, "feature": 1, "show": 1, "tighter": 1, "worstcase": 1, "generalization": 1, "bind": 1, "54": 1}, {"higher": 1, "compression": 1, "guarantee": 1, "robustness": 1, "shift": 1, "datadistribution": 1, "believe": 1, "reasonable": 1, "assumption": 1, "majority": 1, "mdps": 1, "example": 1, "rely": 1, "consistent": 1, "underlie": 1, "transition": 1, "mechanism": 1, "like": 1, "physical": 1, "laws": 1}, {"incentivize": 1, "compress": 1, "feature": 1, "use": 1, "approach": 1, "similar": 1, "vib": 1, "2": 1, "minimize": 1, "mutual": 1, "information": 1, "z": 3, "state": 1, "latent": 1, "representation": 1, "maximize": 1, "iz": 1, "predictive": 1, "power": 1, "action": 1}, {"reinterpret": 1, "policy": 1, "gradient": 1, "update": 1, "maximization": 1, "logmarginal": 1, "likelihood": 1, "": 6, "data": 1, "distribution": 2, "sa": 1, "ps": 1, "asa": 1, "discount": 1, "state": 1, "advantage": 1, "function": 1, "z": 2, "normalization": 1, "constant": 1}, {"take": 1, "semigradient": 1, "objective": 1, "ie": 1}, {"assume": 1, "ps": 1, "fix": 1, "recover": 1, "policy": 1, "gradient": 1, "z": 2, "r": 1, "epsa": 1, "log": 2, "": 4, "asr": 1, "asa": 1, "ds": 1, "da": 1}, {"8": 1, "follow": 1, "step": 1, "2": 1, "introduce": 1, "stochastic": 1, "latent": 1, "variable": 1, "z": 2, "minimize": 1, "maximize": 1, "iz": 1, "ps": 1, "result": 2, "new": 1, "objective": 2, "": 16, "lib": 3, "epsap": 1, "zs": 2, "log": 2, "q": 2, "az": 1, "dkl": 2, "p": 4, "zskqz": 2, "9": 1, "take": 1, "gradient": 2, "use": 1, "reparameterization": 1, "trick": 1, "25": 1, "write": 1, "encoder": 1, "deterministic": 1, "function": 1, "f": 1, "r": 4, "e": 1, "asp": 1, "af": 1, "10": 1, "lkl": 2, "ac": 1, "modify": 1, "policy": 1, "additional": 1, "regularization": 1, "term": 1}, {"policy": 2, "gradient": 1, "algorithms": 1, "heuristically": 1, "add": 1, "entropy": 1, "bonus": 1, "h": 1, "prevent": 1, "distribution": 1, "collapse": 1}, {"however": 1, "term": 1, "also": 1, "influence": 1, "distributions": 1, "z": 1}, {"practice": 1, "interest": 1, "prevent": 1, "q": 2, "az": 2, "": 5, "ez": 1, "collapse": 1, "rollout": 1, "policy": 1, "rely": 1, "stochasticity": 1, "z": 1, "additionally": 1, "p": 1, "zs": 1, "already": 1, "entropyregularized": 1, "ib": 1, "loss": 1, "term4": 1}, {"consequently": 1, "adapt": 1, "heuristic": 1, "entropy": 1, "bonus": 1, "z": 1, "ib": 2, "h": 4, "": 10, "p": 1, "zhq": 1, "az": 1, "ds": 1, "dz": 1, "11": 1, "result": 1, "overall": 1, "loss": 2, "function": 1, "propose": 1, "information": 1, "bottleneck": 1, "actor": 1, "critic": 1, "ibac": 1, "v": 3, "kl": 1, "ltibac": 1, "lib": 1, "l": 2, "ac": 2, "hyperparameters": 1, "balance": 1, "term": 1}, {"12": 1, "": 1, "ibac": 1, "incentivizes": 1, "compress": 1, "feature": 1, "also": 1, "introduce": 1, "stochasticity": 1}, {"consequently": 1, "combine": 1, "sni": 1, "improve": 1, "performance": 1, "demonstrate": 1, "section": 1, "52": 1, "53": 1}, {"compute": 1, "noisesuspended": 1, "policy": 1, "": 6, "critic": 1, "v": 3, "use": 2, "mode": 2, "z": 4, "input": 1, "q": 1, "az": 1, "p": 1, "zs": 1, "condition": 1, "instead": 1, "also": 1, "compress": 1, "feature": 1}, {"note": 1, "sni": 1, "": 1, "1": 1, "ie": 1}, {"term": 1, "gac": 1, "": 6, "r": 1, "v": 1, "effectively": 1, "recover": 1, "l2": 1, "penalty": 1, "activations": 1, "since": 1, "variance": 1, "z": 1, "always": 1, "ignore": 1, "kldivergence": 1, "two": 1, "gaussians": 1, "minimize": 1, "square": 1, "difference": 1, "mean": 1}, {"5": 1, "": 2, "experiment": 2, "follow": 1, "present": 1, "series": 1, "show": 1, "ib": 1, "find": 1, "general": 1, "feature": 1, "lowdata": 1, "regime": 1, "translate": 1, "improve": 1, "generalization": 1, "rl": 1, "ibac": 1, "agents": 1, "especially": 1, "combine": 1, "sni": 1}, {"evaluate": 1, "propose": 2, "regularization": 1, "techniques": 1, "two": 1, "environments": 1, "one": 1, "gridworld": 1, "challenge": 1, "generalization": 1, "requirements": 1, "9": 1, "previous": 1, "approach": 1, "unable": 1, "find": 1, "solution": 1, "recently": 1, "coinrun": 1, "benchmark": 1, "11": 1}, {"show": 1, "ibacsni": 1, "outperform": 1, "previous": 1, "state": 1, "art": 1, "environments": 1, "large": 1, "margin": 1}, {"detail": 1, "use": 1, "hyperparameters": 1, "network": 1, "architectures": 1, "find": 2, "appendix": 1, "code": 1, "reproduce": 1, "result": 1, "httpsgithubcommicrosoft": 1, "ibacsni": 1}, {"4": 1, "": 10, "dkl": 1, "p": 2, "zskrz": 1, "ep": 2, "zs": 4, "log": 3, "5": 1, "rz": 2, "hp": 1, "51": 1, "learn": 1, "feature": 1, "lowdata": 1, "regime": 1, "figure": 1, "1": 1, "show": 1, "loss": 1, "testdata": 1, "lower": 1, "better": 1}, {"leave": 1, "higher": 1, "": 1}, {"f": 2, "result": 1, "larger": 1, "difference": 1, "generality": 1, "feature": 1, "c": 3, "g": 2, "": 2, "make": 1, "easier": 1, "fit": 1, "general": 1}, {"right": 1, "learn": 1, "g": 1, "c": 1, "fewer": 1, "datapoints": 1, "challenge": 1, "need": 1, "early": 1, "train": 1, "rl": 1, "agents": 1}, {"first": 1, "start": 1, "supervise": 1, "set": 1, "show": 1, "synthetic": 1, "dataset": 1, "vib": 1, "particularly": 1, "strong": 1, "find": 1, "general": 1, "feature": 1, "lowdata": 1, "regime": 1, "presence": 1, "multiple": 1, "signal": 1, "vary": 1, "degrees": 1, "generality": 1}, {"motivation": 1, "lowdata": 1, "regime": 1, "commonly": 1, "encounter": 1, "rl": 1, "early": 1, "train": 1, "many": 1, "environments": 1, "allow": 1, "agent": 1, "base": 1, "decision": 1, "variety": 1, "feature": 1, "state": 1, "would": 1, "like": 1, "find": 1, "general": 1, "ones": 1}, {"dx": 1, "generate": 1, "train": 1, "dataset": 1, "dtrain": 1, "": 3, "ci": 2, "xi": 2, "n": 1, "class": 1, "i1": 1, "observations": 1, "2": 2, "r": 1, "1": 1}, {"": 1}, {"": 1}, {"": 2, "nc": 1}, {"data": 1, "point": 1, "generate": 2, "first": 1, "draw": 1, "class": 1, "ci": 2, "": 2, "catnc": 1, "uniform": 1, "categorical": 1, "distribution": 1, "vector": 1, "xi": 1, "embed": 1, "information": 1, "two": 1, "different": 1, "ways": 1, "g": 1, "c": 2, "f": 1, "see": 1, "appendix": 1, "b": 1, "detail": 1}, {"importantly": 1, "g": 1, "c": 1, "share": 1, "train": 1, "test": 1, "set": 1}, {"allow": 1, "us": 1, "measure": 2, "model": 2, "relative": 1, "reliance": 1, "g": 1, "c": 2, "f": 1, "test": 1, "performance": 1, "perfectly": 1, "fit": 1, "train": 1, "data": 1}, {"allow": 1, "f": 1, "c": 1, "encode": 1, "information": 1, "ci": 1, "": 1}, {"f": 1, "different": 1, "ways": 1}, {"consequently": 1, "higher": 1, "": 1}, {"f": 2, "": 1, "less": 1, "general": 1, "c": 1}, {"fig": 1}, {"1": 1, "measure": 1, "test": 1, "performance": 1, "fully": 1, "train": 2, "classification": 1, "model": 1, "vary": 3, "different": 1, "regularization": 1, "techniques": 1, "generality": 1, "f": 1, "c": 1, "ii": 1, "number": 1, "datapoints": 1, "set": 1}, {"find": 2, "techniques": 1, "perform": 1, "comparably": 1, "exception": 1, "vib": 1, "able": 1, "general": 1, "feature": 2, "lowdata": 1, "regime": 1, "presence": 1, "multiple": 1, "small": 1, "differences": 1, "generality": 1}, {"next": 1, "section": 1, "show": 1, "translate": 1, "faster": 1, "train": 1, "performance": 1, "gain": 1, "rl": 1, "propose": 1, "algorithm": 1, "ibac": 1}, {"52": 1, "": 2, "multiroom": 1, "figure": 1, "2": 1, "leave": 1, "typical": 1, "layout": 1, "environment": 1}, {"red": 1, "triangle": 1, "denote": 1, "agent": 1, "direction": 1, "green": 1, "full": 1, "square": 2, "goal": 1, "color": 1, "box": 1, "doors": 1, "grey": 1, "wall": 1}, {"middle": 1, "probability": 1, "find": 1, "goal": 1, "depend": 1, "level": 2, "size": 1, "model": 1, "train": 1}, {"show": 1, "mean": 1, "standard": 1, "error": 1, "across": 1, "30": 1, "different": 1, "seed": 1}, {"right": 1, "mean": 1, "standard": 1, "error": 1, "return": 1, "model": 1, "average": 1, "across": 1, "room": 1, "size": 1}, {"section": 1, "show": 1, "ibac": 1, "help": 1, "learn": 1, "rl": 1, "task": 1, "require": 1, "generalization": 1}, {"task": 1, "distinguish": 1, "train": 1, "test": 1, "episode": 1, "draw": 1, "randomly": 1, "full": 1, "distribution": 1, "mdps": 1, "qm": 1}, {"number": 1, "mdps": 1, "large": 1, "learn": 2, "successful": 1, "agent": 1, "general": 1, "feature": 1, "transferrable": 1, "episodes": 1}, {"6": 1, "": 1, "experiment": 1, "base": 1, "9": 1}, {"aim": 1, "agent": 1, "traverse": 1, "sequence": 1, "room": 1, "reach": 1, "goal": 1, "green": 1, "square": 1, "fig": 1}, {"2": 1, "quickly": 1, "possible": 1}, {"take": 1, "discrete": 1, "action": 1, "rotate": 1, "90": 1, "either": 1, "direction": 1, "move": 1, "forward": 1, "toggle": 1, "doors": 1, "open": 1, "close": 1}, {"observation": 1, "receive": 1, "agent": 1, "include": 1, "full": 1, "grid": 1, "one": 1, "pixel": 1, "per": 1, "square": 1, "object": 2, "type": 1, "status": 1, "like": 1, "direction": 1, "encode": 1, "3": 1, "color": 1, "channel": 1}, {"crucially": 1, "episode": 1, "layout": 1, "generate": 1, "randomly": 1, "place": 1, "random": 1, "number": 1, "room": 1, "nr": 1, "2": 2, "1": 1, "3": 1, "sequence": 1, "connect": 1, "one": 1, "door": 1}, {"result": 1, "fig": 1}, {"2": 1, "show": 1, "ibac": 1, "agents": 1, "much": 1, "better": 1, "successfully": 1, "learn": 1, "solve": 1, "task": 1, "especially": 1, "layouts": 1, "room": 1}, {"fully": 1, "train": 1, "agents": 1, "solve": 1, "less": 1, "3": 1, "layouts": 2, "two": 1, "room": 1, "none": 1, "ones": 1, "three": 1, "ibacsni": 1, "still": 1, "succeed": 1, "impressive": 1, "43": 1, "21": 1}, {"difficulty": 1, "seemingly": 1, "simple": 1, "task": 1, "arise": 1, "generalization": 2, "requirements": 1, "since": 1, "layout": 1, "randomly": 1, "generate": 1, "episode": 1, "state": 1, "observe": 1, "rarely": 1, "especially": 1, "multiroom": 1, "layouts": 1, "require": 1, "allow": 1, "learn": 1}, {"1": 1, "room": 1, "layout": 1, "reduce": 2, "policy": 1, "stochasticity": 1, "sni": 1, "agent": 1, "slightly": 1, "performance": 2, "improve": 1, "complex": 1, "layouts": 1, "higher": 1, "noise": 1, "become": 1, "detrimental": 1}, {"next": 1, "section": 1, "see": 1, "also": 1, "hold": 1, "much": 1, "complex": 1, "coinrun": 1, "environment": 1, "sni": 1, "significantly": 1, "improve": 1, "ibac": 1, "performance": 1}, {"53": 1, "": 2, "coinrun": 1, "figure": 1, "3": 1, "leave": 1, "performance": 1, "various": 1, "agents": 1, "test": 1, "environments": 1}, {"note": 1, "batchnorm": 1, "correspond": 1, "best": 1, "perform": 1, "agent": 1, "11": 1}, {"furthermore": 1, "dropoutsni": 1, "": 2, "1": 1, "similar": 1, "dropout": 1, "implementation": 1, "use": 1, "11": 1, "previously": 1, "evaluate": 1, "weight": 1, "decay": 1, "data": 1, "augmentation": 1}, {"middle": 1, "difference": 1, "test": 1, "performance": 2, "train": 1, "see": 1, "fig": 1}, {"7": 1}, {"without": 1, "standard": 1, "deviation": 1, "readability": 1}, {"right": 1, "average": 1, "approximate": 1, "kldivergence": 1, "rollout": 1, "policy": 2, "update": 1, "use": 1, "proxy": 1, "variance": 1, "importance": 1, "weight": 1}, {"mean": 1, "standard": 1, "deviation": 1, "across": 1, "three": 1, "random": 1, "seed": 1}, {"previous": 1, "environment": 1, "able": 1, "show": 1, "ibac": 1, "sni": 1, "help": 1, "agents": 1, "find": 1, "general": 1, "feature": 1, "faster": 1}, {"next": 1, "show": 1, "lead": 1, "higher": 1, "final": 1, "performance": 1, "previously": 1, "unseen": 1, "test": 1, "environments": 1}, {"evaluate": 1, "propose": 2, "regularization": 1, "techniques": 1, "coinrun": 1, "11": 1, "recently": 1, "generalization": 1, "benchmark": 1, "highdimensional": 1, "observations": 1, "large": 1, "variety": 1, "level": 1}, {"several": 1, "regularization": 1, "techniques": 1, "previously": 1, "evaluate": 1, "make": 1, "ideal": 1, "evaluation": 1, "environment": 1, "ibac": 1, "sni": 1}, {"follow": 1, "set": 1, "propose": 1, "11": 1, "use": 1, "500": 1, "level": 2, "train": 1, "evaluate": 1, "randomly": 1, "draw": 1, "new": 1, "highest": 1, "difficulty": 1}, {"11": 1, "show": 1, "combine": 1, "multiple": 1, "regularization": 1, "techniques": 1, "improve": 1, "performance": 1, "best": 1, "perform": 1, "agent": 1, "utilize": 1, "data": 1, "augmentation": 1, "weight": 1, "decay": 1, "batch": 1, "normalization": 1}, {"goal": 1, "push": 1, "state": 1, "art": 1, "environment": 1, "accurately": 1, "compare": 1, "result": 1, "fig": 1}, {"3": 1, "use": 1, "weight": 1, "decay": 1, "dataaugmentation": 1, "experiment": 1}, {"consequently": 1, "baseline": 1, "fig": 1}, {"3": 1, "refer": 1, "use": 2, "weight": 2, "decay": 2, "dataaugmentation": 2, "whereas": 1, "experiment": 1, "dropout": 1, "batch": 1, "normalization": 1, "ibac": 1, "addition": 1}, {"result": 1, "without": 1, "baseline": 2, "techniques": 2, "find": 2, "appendix": 1, "first": 1, "almost": 1, "previously": 1, "propose": 1, "regularization": 1, "decrease": 1, "performance": 1, "compare": 1, "see": 1, "fig": 1}, {"3": 1, "leave": 1, "batch": 1, "normalization": 1, "perform": 1, "worst": 1, "possibly": 1, "due": 1, "unusual": 1, "interaction": 1, "weight": 1, "decay": 1, "56": 1}, {"note": 1, "combination": 1, "batch": 1, "normalization": 1, "highest": 1, "perform": 1, "agent": 1, "11": 1}, {"conjecture": 1, "regularization": 1, "techniques": 1, "rely": 1, "stochasticity": 1, "introduce": 1, "additional": 1, "instability": 1, "train": 1, "update": 1, "possibly": 1, "deteriorate": 1, "performance": 1, "especially": 1, "regularize": 1, "effect": 1, "sufficiently": 1, "different": 1, "weight": 1, "decay": 1, "dataaugmentation": 1, "already": 1, "achieve": 1}, {"result": 1, "apply": 1, "batch": 1, "normalization": 1, "dropout": 1, "7": 1, "": 1, "without": 1, "sni": 2, "although": 1, "mitigate": 1, "adverse": 1, "effect": 1}, {"consequently": 1, "already": 1, "improve": 1, "state": 1, "art": 1, "rely": 1, "two": 1, "nonstochastic": 1, "techniques": 1}, {"furthermore": 1, "find": 1, "ibac": 1, "combination": 1, "sni": 1, "able": 1, "significantly": 1, "outperform": 1, "new": 1, "state": 1, "art": 1, "baseline": 1}, {"also": 1, "find": 1, "ibac": 1, "": 2, "05": 1, "achieve": 1, "better": 1, "performance": 1, "1": 1, "justify": 1, "use": 1, "term": 1, "eq": 1}, {"7": 1}, {"proxy": 1, "variance": 1, "offpolicy": 1, "correction": 1, "term": 1, "": 2, "show": 1, "fig": 1}, {"3": 1, "right": 1, "estimate": 1, "average": 1, "kldivergence": 1, "rollout": 1, "policy": 2, "update": 1, "term": 1, "gac": 2, "": 11, "r": 2, "v": 2, "denote": 2, "det": 1, "stoch": 1}, {"ppo": 1, "use": 1, "datapoints": 1, "multiple": 1, "time": 1, "nonzero": 1, "even": 1, "deterministic": 1, "term": 1}, {"first": 1, "see": 1, "use": 1, "deterministic": 1, "version": 1, "reduce": 1, "kldivergence": 1, "explain": 1, "positive": 1, "influence": 1, "gac": 1, "": 6, "r": 1, "v": 1}, {"second": 1, "see": 2, "kldivergence": 1, "stochastic": 1, "part": 2, "much": 1, "higher": 1, "dropout": 2, "ibac": 1, "offer": 1, "explanation": 1, "rely": 1, "purely": 1, "deterministic": 1, "": 3, "1": 1, "outperform": 1, "equal": 1, "mix": 1, "05": 1, "fig": 1}, {"6": 1}, {"r": 1, "": 3, "6": 1, "relate": 1, "work": 1, "generalization": 1, "rl": 1, "take": 1, "variety": 1, "form": 1, "necessitate": 1, "different": 1, "type": 1, "regularization": 1}, {"position": 1, "work": 1, "distinguish": 1, "two": 1, "type": 1, "whilst": 1, "mutually": 1, "exclusive": 1, "believe": 1, "conceptually": 1, "distinct": 1, "find": 1, "useful": 1, "isolate": 1, "study": 1, "approach": 1, "improve": 1, "generalization": 1}, {"first": 1, "type": 1, "robustness": 1, "uncertainty": 1, "refer": 1, "settings": 1, "unobserved": 1, "mdp": 1, "influence": 1, "transition": 1, "dynamics": 1, "reward": 1, "structure": 1}, {"consequently": 1, "current": 2, "state": 1, "might": 1, "contain": 1, "enough": 1, "information": 1, "act": 1, "optimally": 1, "mdp": 1, "need": 1, "find": 1, "action": 1, "optimal": 1, "uncertainty": 1, "set": 1, "often": 1, "arise": 1, "robotics": 1, "control": 1, "exact": 1, "physical": 1, "characteristics": 1, "unknown": 1, "domain": 1, "shift": 1, "occur": 1, "27": 1}, {"consequently": 1, "domain": 1, "randomization": 1, "injection": 1, "randomness": 1, "environment": 1, "often": 1, "purposefully": 1, "apply": 1, "train": 1, "allow": 1, "simtoreal": 1, "transfer": 1, "26": 1, "55": 1}, {"noise": 1, "inject": 1, "state": 1, "environment": 1, "50": 1, "parameters": 1, "transition": 1, "distribution": 1, "like": 1, "friction": 1, "coefficients": 1, "mass": 1, "value": 1, "3": 1, "34": 1, "60": 1}, {"noise": 1, "inject": 1, "dynamics": 1, "also": 1, "manipulate": 1, "adversarially": 1, "29": 1, "36": 1, "39": 1}, {"goal": 1, "prevent": 1, "overfitting": 1, "specific": 1, "mdps": 1, "also": 1, "find": 1, "use": 1, "smaller": 1, "40": 1, "simpler": 1, "66": 1, "network": 1, "help": 1}, {"also": 1, "aim": 1, "learn": 2, "adaptive": 1, "policy": 1, "treat": 1, "environment": 1, "partially": 1, "observable": 1, "markov": 1, "decision": 1, "process": 1, "pomdp": 1, "35": 1, "60": 1, "similar": 1, "view": 1, "problem": 2, "framework": 1, "bayesian": 1, "rl": 1, "37": 1, "metalearning": 1, "1": 1, "10": 1, "13": 1, "43": 1, "51": 1, "57": 1}, {"hand": 1, "distinguish": 1, "feature": 2, "robustness": 1, "apply": 1, "environments": 1, "highdimensional": 1, "observations": 1, "like": 1, "image": 1, "generalization": 1, "previously": 1, "unseen": 1, "state": 1, "improve": 1, "learn": 1, "extract": 1, "better": 1, "focus": 1, "paper": 1}, {"recently": 1, "range": 1, "benchmarks": 1, "typically": 1, "utilize": 1, "procedurally": 1, "generate": 1, "level": 1, "propose": 1, "evaluate": 1, "type": 1, "generalization": 1, "4": 1, "11": 1, "19": 1, "20": 1, "21": 1, "22": 1, "32": 1, "59": 1, "63": 1}, {"improve": 1, "generalization": 1, "settings": 1, "rely": 1, "generate": 1, "diverse": 1, "observation": 1, "data": 1, "11": 1, "42": 1, "55": 1, "strong": 1, "often": 1, "relational": 1, "inductive": 1, "bias": 1, "apply": 1, "architecture": 1, "23": 1, "49": 1, "61": 1}, {"contrary": 1, "result": 1, "continuous": 1, "control": 1, "domains": 1, "deeper": 1, "network": 1, "find": 1, "successful": 1, "7": 1, "11": 1}, {"furthermore": 1, "set": 1, "similar": 1, "supervise": 1, "learn": 1, "establish": 1, "regularization": 1, "techniques": 1, "like": 1, "weight": 1, "decay": 1, "dropout": 1, "batchnormalization": 1, "also": 1, "successfully": 1, "apply": 1, "especially": 1, "settings": 1, "limit": 1, "number": 1, "train": 1, "environments": 1, "11": 1}, {"work": 1, "closely": 1, "relate": 1}, {"build": 1, "result": 1, "improve": 1, "upon": 1, "take": 1, "account": 1, "specific": 1, "ways": 1, "rl": 1, "different": 1, "supervise": 1, "set": 1}, {"also": 1, "consider": 1, "vib": 1, "regularization": 1, "technique": 1}, {"combine": 1, "rl": 1, "vib": 1, "recently": 1, "explore": 1, "learn": 1, "goalconditioned": 1, "policies": 1, "14": 1, "metarl": 1, "41": 1}, {"previous": 1, "work": 1, "14": 1, "41": 1, "also": 1, "differ": 1, "ibac": 1, "architecture": 1, "propose": 1, "condition": 1, "action": 1, "selection": 1, "encode": 1, "raw": 1, "state": 1, "observation": 1}, {"study": 1, "complement": 1, "contribution": 1, "make": 1, "provide": 1, "evidence": 1, "vib": 1, "use": 2, "wider": 1, "range": 1, "rl": 1, "algorithms": 1, "include": 1, "demonstrate": 1, "benefit": 1, "soft": 1, "actorcritic": 1, "continuous": 1, "control": 1, "mujoco": 1, "41": 1, "onpolicy": 1, "a2c": 1, "minigrid": 1, "minipacman": 1, "14": 1}, {"8": 1, "": 3, "7": 1, "conclusion": 1, "work": 1, "highlight": 1, "two": 1, "important": 1, "differences": 1, "supervise": 1, "learn": 2, "rl": 1, "first": 1, "train": 1, "data": 1, "generate": 1, "use": 1, "model": 1}, {"consequently": 1, "use": 1, "stochastic": 1, "regularization": 1, "methods": 1, "induce": 1, "adverse": 1, "effect": 1, "reduce": 1, "quality": 1, "data": 1}, {"conjecture": 1, "explain": 1, "observe": 1, "lower": 1, "performance": 1, "batch": 1, "normalization": 1, "dropout": 1}, {"second": 1, "rl": 1, "often": 1, "encounter": 1, "noisy": 1, "lowdata": 1, "regime": 1, "early": 1, "train": 1, "complicate": 1, "extraction": 1, "general": 1, "feature": 1}, {"argue": 1, "differences": 1, "inform": 1, "choice": 1, "regularization": 1, "techniques": 1, "use": 1, "rl": 1}, {"mitigate": 1, "adverse": 1, "effect": 1, "stochastic": 1, "regularization": 1, "propose": 1, "selective": 1, "noise": 2, "injection": 1, "sni": 1, "selectively": 1, "inject": 1, "model": 1, "prevent": 1, "reduce": 1, "data": 1, "quality": 1, "higher": 1, "gradient": 1, "variance": 1, "noisy": 1, "critic": 1}, {"hand": 1, "learn": 1, "compress": 1, "general": 1, "feature": 1, "noisy": 1, "lowdata": 1, "regime": 1, "propose": 1, "information": 2, "bottleneck": 2, "actor": 1, "critic": 1, "ibac": 1, "utilize": 1, "variational": 1, "part": 1, "agent": 1}, {"experimentally": 1, "demonstrate": 1, "vib": 1, "able": 1, "extract": 1, "better": 2, "feature": 1, "lowdata": 1, "regime": 1, "translate": 1, "generalization": 1, "ibac": 1, "rl": 1}, {"furthermore": 1, "complex": 1, "environments": 1, "sni": 2, "key": 1, "good": 1, "performance": 1, "allow": 1, "combine": 1, "algorithm": 1, "ibac": 1, "": 2, "achieve": 1, "state": 1, "art": 1, "challenge": 1, "generalization": 1, "benchmarks": 1}, {"believe": 1, "result": 1, "present": 1, "inform": 1, "range": 1, "future": 1, "work": 1, "improve": 1, "exist": 1, "algorithms": 1, "find": 1, "new": 1, "regularization": 1, "techniques": 1, "adapt": 1, "rl": 1}, {"acknowledgments": 1, "would": 1, "like": 1, "thank": 1, "shimon": 1, "whiteson": 1, "helpful": 1, "feedback": 1, "sebastian": 1, "lee": 1, "luke": 1, "harris": 1, "hiske": 1, "overweg": 1, "patrick": 1, "fernandes": 1, "help": 2, "experimental": 1, "evaluations": 1, "adrian": 1, "ogrady": 1, "jaroslaw": 1, "rzepecki": 1, "andre": 1, "kramer": 1, "compute": 1, "infrastructure": 1}, {"igl": 1, "support": 1, "uk": 1, "epsrc": 1, "cdt": 1, "autonomous": 1, "intelligent": 1, "machine": 1, "systems": 1}, {"reference": 1, "1": 1, "maruan": 1, "alshedivat": 1, "trapit": 1, "bansal": 1, "yura": 1, "burda": 1, "ilya": 1, "sutskever": 1, "igor": 1, "mordatch": 1, "pieter": 1, "abbeel": 1}, {"continuous": 1, "adaptation": 1, "via": 1, "metalearning": 1, "nonstationary": 1, "competitive": 1, "environments": 1}, {"international": 1, "conference": 1, "learn": 1, "representations": 1, "2018": 1}, {"2": 1, "alexander": 1, "alemi": 1, "ian": 1, "fischer": 1, "joshua": 1, "v": 1, "dillon": 1, "kevin": 1, "murphy": 1}, {"deep": 1, "variational": 1, "information": 1, "bottleneck": 1}, {"5th": 1, "international": 1, "conference": 2, "learn": 1, "representations": 1, "iclr": 1, "2017": 3, "toulon": 1, "france": 1, "april": 1, "2426": 1, "track": 1, "proceed": 1}, {"3": 1, "rika": 1, "antonova": 1, "silvia": 1, "cruciani": 1, "christian": 1, "smith": 1, "danica": 1, "kragic": 1}, {"reinforcement": 1, "learn": 1, "pivot": 1, "task": 1}, {"arxiv": 1, "preprint": 1, "arxiv170300472": 1, "2017": 1}, {"4": 1, "edward": 1, "beeching": 1, "christian": 1, "wolf": 1, "jilles": 1, "dibangoye": 1, "olivier": 1, "simonin": 1}, {"deep": 1, "reinforcement": 1, "learn": 1, "budget": 1, "3d": 1, "control": 1, "reason": 1, "without": 1, "supercomputer": 1}, {"corr": 1, "abs190401806": 1, "2019": 1}, {"5": 1, "mikhail": 1, "belkin": 1, "daniel": 1, "hsu": 1, "siyuan": 1, "soumik": 1, "mandal": 1}, {"reconcile": 1, "modern": 1, "machine": 1, "learn": 1, "biasvariance": 1, "tradeoff": 1}, {"arxiv": 1, "preprint": 1, "arxiv181211118": 1, "2018": 1}, {"6": 1, "marc": 1, "g": 1, "bellemare": 1, "yavar": 1, "naddaf": 1, "joel": 1, "veness": 1, "michael": 1, "bowl": 1}, {"arcade": 1, "learn": 1, "environment": 1, "evaluation": 1, "platform": 1, "general": 1, "agents": 1}, {"journal": 1, "artificial": 1, "intelligence": 1, "research": 1, "47253279": 1, "2013": 1}, {"7": 1, "alon": 1, "brutzkus": 1, "amir": 1, "globerson": 1}, {"overparameterization": 1, "improve": 1, "generalization": 1, "xor": 1, "detection": 1, "problem": 1}, {"corr": 1, "abs181003037": 1, "2018": 1}, {"8": 1, "devendra": 1, "singh": 1, "chaplot": 1, "guillaume": 1, "lample": 1, "kanthashree": 1, "mysore": 1, "sathyendra": 1, "ruslan": 1, "salakhutdinov": 1}, {"transfer": 1, "deep": 1, "reinforcement": 1, "learn": 1, "3d": 1, "environments": 1, "empirical": 1, "study": 1}, {"nip": 1, "deep": 1, "reinforcemente": 1, "lean": 1, "workshop": 1, "2016": 1}, {"9": 2, "": 1, "maxime": 1, "chevalierboisvert": 1, "lucas": 1, "willems": 1}, {"minimalistic": 1, "gridworld": 1, "environment": 1, "openai": 1, "gym": 1}, {"httpsgithubcommaximecbgymminigrid": 1, "2018": 1}, {"10": 1, "ignasi": 1, "clavera": 1, "anusha": 1, "nagabandi": 1, "ronald": 1, "fear": 1, "pieter": 1, "abbeel": 1, "sergey": 1, "levine": 1, "chelsea": 1, "finn": 1}, {"learn": 1, "adapt": 1, "metalearning": 1, "modelbased": 1, "control": 1}, {"corr": 1, "abs180311347": 1, "2018": 1}, {"11": 1, "karl": 1, "cobbe": 1, "oleg": 1, "klimov": 1, "chris": 1, "hesse": 1, "taehoon": 1, "kim": 1, "john": 1, "schulman": 1}, {"quantify": 1, "generalization": 1, "reinforcement": 1, "learn": 1}, {"proceed": 1, "36th": 1, "international": 1, "conference": 1, "machine": 1, "learn": 1, "2019": 1}, {"12": 1, "terrance": 1, "devries": 1, "graham": 1, "w": 1, "taylor": 1}, {"improve": 1, "regularization": 1, "convolutional": 1, "neural": 1, "network": 1, "cutout": 1}, {"arxiv": 1, "preprint": 1, "arxiv170804552": 1, "2017": 1}, {"13": 1, "yan": 1, "duan": 1, "john": 1, "schulman": 1, "xi": 1, "chen": 1, "peter": 1, "l": 1, "bartlett": 1, "ilya": 1, "sutskever": 1, "pieter": 1, "abbeel": 1}, {"rl2": 1, "fast": 1, "reinforcement": 2, "learn": 2, "via": 1, "slow": 1}, {"arxiv": 1, "preprint": 1, "arxiv161102779": 1, "2016": 1}, {"14": 1, "anirudh": 1, "goyal": 1, "riashat": 1, "islam": 1, "dj": 1, "strouse": 1, "zafarali": 1, "ahmed": 1, "hugo": 1, "larochelle": 1, "matthew": 1, "botvinick": 1, "sergey": 1, "levine": 1, "yoshua": 1, "bengio": 1}, {"infobot": 1, "transfer": 1, "exploration": 1, "via": 1, "information": 1, "bottleneck": 1}, {"international": 1, "conference": 1, "learn": 1, "representations": 1, "2019": 1}, {"15": 1, "peter": 1, "henderson": 1, "riashat": 1, "islam": 1, "philip": 1, "bachman": 1, "joelle": 1, "pineau": 1, "doina": 1, "precup": 1, "david": 1, "meger": 1}, {"deep": 1, "reinforcement": 1, "learn": 1, "matter": 1}, {"thirtysecond": 1, "aaai": 1, "conference": 1, "artificial": 1, "intelligence": 1, "2018": 1}, {"16": 1, "matteo": 1, "hessel": 1, "joseph": 1, "modayil": 1, "hado": 1, "van": 1, "hasselt": 1, "tom": 1, "schaul": 1, "georg": 1, "ostrovski": 1, "dabney": 1, "dan": 1, "horgan": 1, "bilal": 1, "piot": 1, "mohammad": 1, "azar": 1, "david": 1, "silver": 1}, {"rainbow": 1, "combine": 1, "improvements": 1, "deep": 1, "reinforcement": 1, "learn": 1}, {"thirtysecond": 1, "aaai": 1, "conference": 1, "artificial": 1, "intelligence": 1, "2018": 1}, {"17": 1, "elad": 1, "hoffer": 1, "itay": 1, "hubara": 1, "daniel": 1, "soudry": 1}, {"train": 2, "longer": 1, "generalize": 1, "better": 1, "close": 1, "generalization": 1, "gap": 1, "large": 1, "batch": 1, "neural": 1, "network": 1}, {"advance": 1, "neural": 1, "information": 1, "process": 1, "systems": 1, "page": 1, "17311741": 1, "2017": 1}, {"18": 1, "sergey": 1, "ioffe": 1, "christian": 1, "szegedy": 1}, {"batch": 1, "normalization": 1, "accelerate": 1, "deep": 1, "network": 1, "train": 1, "reduce": 1, "internal": 1, "covariate": 1, "shift": 1}, {"international": 1, "conference": 1, "machine": 1, "learn": 1, "page": 1, "448456": 1, "2015": 1}, {"19": 1, "matthew": 1, "johnson": 1, "katja": 1, "hofmann": 1, "tim": 1, "hutton": 1, "david": 1, "bignell": 1}, {"malmo": 1, "platform": 1, "artificial": 1, "intelligence": 1, "experimentation": 1}, {"ijcai": 1, "page": 1, "42464247": 1, "2016": 1}, {"20": 1, "arthur": 1, "juliani": 1, "ahmed": 1, "khalifa": 1, "vincentpierre": 1, "berges": 1, "jonathan": 1, "harper": 1, "hunter": 1, "henry": 1, "adam": 1, "crespi": 1, "julian": 1, "togelius": 1, "danny": 1, "lange": 1}, {"obstacle": 1, "tower": 1, "generalization": 1, "challenge": 1, "vision": 1, "control": 1, "plan": 1}, {"corr": 1, "abs190201378": 1, "2019": 1}, {"21": 1, "niels": 1, "justesen": 1, "ruben": 1, "rodriguez": 1, "torrado": 1, "philip": 1, "bontrager": 1, "ahmed": 1, "khalifa": 1, "julian": 1, "togelius": 1, "sebastian": 1, "risi": 1}, {"illuminate": 1, "generalization": 1, "deep": 1, "reinforcement": 1, "learn": 1, "procedural": 1, "level": 1, "generation": 1}, {"arxiv": 1, "preprint": 1, "arxiv180610729": 1, "2018": 1}, {"22": 1, "yuji": 1, "kanagawa": 1, "tomoyuki": 1, "kaneko": 1}, {"roguegym": 1, "new": 1, "challenge": 1, "generalization": 1, "reinforcement": 1, "learn": 1}, {"arxiv": 1, "preprint": 1, "arxiv190408129": 1, "2019": 1}, {"23": 1, "ken": 1, "kansky": 1, "tom": 1, "silver": 1, "david": 1, "mly": 1, "mohamed": 1, "eldawy": 1, "miguel": 1, "lzarogredilla": 1, "xinghua": 1, "lou": 1, "nimrod": 1, "dorfman": 1, "szymon": 1, "sidor": 1, "scott": 1, "phoenix": 1, "dileep": 1, "george": 1}, {"schema": 1, "network": 1, "zeroshot": 1, "transfer": 1, "generative": 1, "causal": 1, "model": 1, "intuitive": 1, "physics": 1}, {"proceed": 1, "34th": 1, "international": 1, "conference": 1, "machine": 1, "learningvolume": 1, "70": 1, "page": 1, "18091818": 1}, {"jmlr": 1}, {"org": 1, "2017": 1}, {"24": 1, "diederik": 1, "p": 1, "kingma": 1, "jimmy": 1, "ba": 1}, {"adam": 1, "method": 1, "stochastic": 1, "optimization": 1}, {"3rd": 1, "international": 1, "conference": 2, "learn": 1, "representations": 1, "iclr": 1, "2015": 3, "san": 1, "diego": 1, "ca": 1, "usa": 1, "may": 1, "79": 1, "track": 1, "proceed": 1}, {"10": 1, "": 1, "25": 1, "diederik": 1, "p": 1, "kingma": 1, "max": 1, "well": 1}, {"autoencoding": 1, "variational": 1, "bay": 1}, {"2nd": 1, "international": 1, "conference": 2, "learn": 1, "representations": 1, "iclr": 1, "2014": 3, "banff": 1, "ab": 1, "canada": 1, "april": 1, "1416": 1, "track": 1, "proceed": 1}, {"26": 1, "sylvain": 1, "koos": 1, "jeanbaptiste": 1, "mouret": 1, "stphane": 1, "doncieux": 1}, {"transferability": 1, "approach": 1, "cross": 1, "reality": 1, "gap": 1, "evolutionary": 1, "robotics": 1}, {"ieee": 1, "transactions": 1, "evolutionary": 1, "computation": 1, "171122145": 1, "2013": 1}, {"27": 1, "sergey": 1, "levine": 1, "peter": 1, "pastor": 1, "alex": 1, "krizhevsky": 1, "julian": 1, "ibarz": 1, "deirdre": 1, "quillen": 1}, {"learn": 2, "handeye": 1, "coordination": 1, "robotic": 1, "grasp": 1, "deep": 1, "largescale": 1, "data": 1, "collection": 1}, {"international": 1, "journal": 1, "robotics": 1, "research": 1, "3745421436": 1, "2018": 1}, {"28": 1, "ping": 1, "luo": 1, "xinjiang": 1, "wang": 1, "wenqi": 1, "shao": 1, "zhanglin": 1, "peng": 1}, {"towards": 1, "understand": 1, "regularization": 1, "batch": 1, "normalization": 1}, {"international": 1, "conference": 1, "learn": 1, "representations": 1, "2019": 1}, {"29": 1, "ajay": 1, "mandlekar": 1, "yuke": 1, "zhu": 1, "animesh": 1, "garg": 1, "li": 1, "feifei": 1, "silvio": 1, "savarese": 1}, {"adversarially": 1, "robust": 1, "policy": 1, "learn": 1, "active": 1, "construction": 1, "physicallyplausible": 1, "perturbations": 1}, {"2017": 1, "ieeersj": 1, "international": 1, "conference": 1, "intelligent": 1, "robots": 1, "systems": 1, "iros": 1, "page": 1, "39323939": 1}, {"ieee": 1, "2017": 1}, {"30": 1, "volodymyr": 1, "mnih": 1, "adria": 1, "puigdomenech": 1, "badia": 1, "mehdi": 1, "mirza": 1, "alex": 1, "grave": 1, "timothy": 1, "lillicrap": 1, "tim": 1, "harley": 1, "david": 1, "silver": 1, "koray": 1, "kavukcuoglu": 1}, {"asynchronous": 1, "methods": 1, "deep": 1, "reinforcement": 1, "learn": 1}, {"international": 1, "conference": 1, "machine": 1, "learn": 1, "page": 1, "19281937": 1, "2016": 1}, {"31": 1, "volodymyr": 1, "mnih": 1, "koray": 1, "kavukcuoglu": 1, "david": 1, "silver": 1, "alex": 1, "grave": 1, "ioannis": 1, "antonoglou": 1, "daan": 1, "wierstra": 1, "martin": 1, "riedmiller": 1}, {"play": 1, "atari": 1, "deep": 1, "reinforcement": 1, "learn": 1}, {"corr": 1, "abs13125602": 1, "2013": 1}, {"32": 1, "alex": 1, "nichol": 1, "vicki": 1, "pfau": 1, "christopher": 1, "hesse": 1, "oleg": 1, "klimov": 1, "john": 1, "schulman": 1}, {"gotta": 1, "learn": 1, "fast": 1, "new": 1, "benchmark": 1, "generalization": 1, "rl": 1}, {"arxiv": 1, "preprint": 1, "arxiv180403720": 1, "2018": 1}, {"33": 1, "openai": 1}, {"openai": 1, "five": 1}, {"httpsblogopenaicomopenaifive": 1, "2018": 1}, {"34": 1, "charles": 1, "packer": 1, "katelyn": 1, "gao": 1, "jernej": 1, "kos": 1, "philipp": 1, "krhenbhl": 1, "vladlen": 1, "koltun": 1, "dawn": 1, "song": 1}, {"assess": 1, "generalization": 1, "deep": 1, "reinforcement": 1, "learn": 1}, {"arxiv": 1, "preprint": 1, "arxiv181012282": 1, "2018": 1}, {"35": 1, "xue": 1, "bin": 1, "peng": 1, "marcin": 1, "andrychowicz": 1, "wojciech": 1, "zaremba": 1, "pieter": 1, "abbeel": 1}, {"simtoreal": 1, "transfer": 1, "robotic": 1, "control": 1, "dynamics": 1, "randomization": 1}, {"2018": 1, "ieee": 1, "international": 1, "conference": 1, "robotics": 1, "automation": 1, "icra": 1, "page": 1, "18": 1}, {"ieee": 1, "2018": 1}, {"36": 1, "lerrel": 1, "pinto": 1, "jam": 1, "davidson": 1, "rahul": 1, "sukthankar": 1, "abhinav": 1, "gupta": 1}, {"robust": 1, "adversarial": 1, "reinforcement": 1, "learn": 1}, {"proceed": 1, "34th": 1, "international": 1, "conference": 1, "machine": 1, "learningvolume": 1, "70": 1, "page": 1, "28172826": 1}, {"jmlr": 1}, {"org": 1, "2017": 1}, {"37": 1, "pascal": 1, "poupart": 1, "nikos": 1, "vlassis": 1, "jesse": 1, "hoey": 1, "kevin": 1, "regan": 1}, {"analytic": 1, "solution": 1, "discrete": 1, "bayesian": 1, "reinforcement": 1, "learn": 1}, {"proceed": 1, "23rd": 1, "international": 1, "conference": 1, "machine": 1, "learn": 1, "page": 1, "697704": 1}, {"acm": 1, "2006": 1}, {"38": 1, "martin": 1, "l": 1, "puterman": 1}, {"markov": 1, "decision": 1, "process": 1, "discrete": 1, "stochastic": 1, "dynamic": 1, "program": 1}, {"john": 1, "wiley": 1, "": 1, "sons": 1, "2014": 1}, {"39": 1, "aravind": 1, "rajeswaran": 1, "sarvjeet": 1, "ghotra": 1, "balaraman": 1, "ravindran": 1, "sergey": 1, "levine": 1}, {"epopt": 1, "learn": 1, "robust": 1, "neural": 1, "network": 1, "policies": 1, "use": 1, "model": 1, "ensembles": 1}, {"5th": 1, "international": 1, "conference": 2, "learn": 1, "representations": 1, "iclr": 1, "2017": 3, "toulon": 1, "france": 1, "april": 1, "2426": 1, "track": 1, "proceed": 1}, {"40": 1, "aravind": 1, "rajeswaran": 1, "kendall": 1, "lowrey": 1, "emanuel": 1, "v": 1, "todorov": 1, "sham": 1, "kakade": 1}, {"towards": 1, "generalization": 1, "simplicity": 1, "continuous": 1, "control": 1}, {"advance": 1, "neural": 1, "information": 1, "process": 1, "systems": 1, "page": 1, "65506561": 1, "2017": 1}, {"11": 1, "": 1, "41": 1, "kate": 1, "rakelly": 1, "aurick": 1, "zhou": 1, "deirdre": 1, "quillen": 1, "chelsea": 1, "finn": 1, "sergey": 1, "levine": 1}, {"efficient": 1, "offpolicy": 1, "metareinforcement": 1, "learn": 1, "via": 1, "probabilistic": 1, "context": 1, "variables": 1}, {"proceed": 1, "36th": 1, "international": 1, "conference": 1, "machine": 1, "learn": 1, "2019": 1}, {"42": 1, "fereshteh": 1, "sadeghi": 1, "sergey": 1, "levine": 1}, {"cad2rl": 1, "real": 2, "singleimage": 1, "flight": 1, "without": 1, "single": 1, "image": 1}, {"robotics": 1, "science": 1, "systems": 1, "xiii": 1, "massachusetts": 2, "institute": 1, "technology": 1, "cambridge": 1, "usa": 1, "july": 1, "1216": 1, "2017": 2}, {"43": 1, "tom": 1, "schaul": 1, "daniel": 1, "horgan": 1, "karol": 1, "gregor": 1, "david": 1, "silver": 1}, {"universal": 1, "value": 1, "function": 1, "approximators": 1}, {"international": 1, "conference": 1, "machine": 1, "learn": 1, "page": 1, "13121320": 1, "2015": 1}, {"44": 1, "john": 1, "schulman": 1, "sergey": 1, "levine": 1, "pieter": 1, "abbeel": 1, "michael": 1, "jordan": 1, "philipp": 1, "moritz": 1}, {"trust": 1, "region": 1, "policy": 1, "optimization": 1}, {"international": 1, "conference": 1, "machine": 1, "learn": 1, "page": 1, "18891897": 1, "2015": 1}, {"45": 1, "john": 1, "schulman": 1, "philipp": 1, "moritz": 1, "sergey": 1, "levine": 1, "michael": 1, "jordan": 1, "pieter": 1, "abbeel": 1}, {"highdimensional": 1, "continuous": 1, "control": 1, "use": 1, "generalize": 1, "advantage": 1, "estimation": 1}, {"4th": 1, "international": 1, "conference": 2, "learn": 1, "representations": 1, "iclr": 1, "2016": 3, "san": 1, "juan": 1, "puerto": 1, "rico": 1, "may": 1, "24": 1, "track": 1, "proceed": 1}, {"46": 1, "john": 1, "schulman": 1, "filip": 1, "wolski": 1, "prafulla": 1, "dhariwal": 1, "alec": 1, "radford": 1, "oleg": 1, "klimov": 1}, {"proximal": 1, "policy": 1, "optimization": 1, "algorithms": 1}, {"arxiv": 1, "preprint": 1, "arxiv170706347": 1, "2017": 1}, {"47": 1, "ohad": 1, "shamir": 1, "sivan": 1, "sabato": 1, "naftali": 1, "tishby": 1}, {"learn": 1, "generalization": 1, "information": 1, "bottleneck": 1}, {"theoretical": 1, "computer": 1, "science": 1, "411293026962711": 1, "2010": 1}, {"48": 1, "nitish": 1, "srivastava": 1, "geoffrey": 1, "hinton": 1, "alex": 1, "krizhevsky": 1, "ilya": 1, "sutskever": 1, "ruslan": 1, "salakhutdinov": 1}, {"dropout": 1, "simple": 1, "way": 1, "prevent": 1, "neural": 1, "network": 1, "overfitting": 1}, {"journal": 1, "machine": 1, "learn": 1, "research": 1, "15119291958": 1, "2014": 1}, {"49": 1, "mario": 1, "srouji": 1, "jian": 1, "zhang": 1, "ruslan": 1, "salakhutdinov": 1}, {"structure": 1, "control": 1, "net": 1, "deep": 1, "reinforcement": 1, "learn": 1}, {"international": 1, "conference": 1, "machine": 1, "learn": 1, "page": 1, "47494758": 1, "2018": 1}, {"50": 1, "freek": 1, "stulp": 1, "evangelos": 1, "theodorou": 1, "jonas": 1, "buchli": 1, "stefan": 1, "schaal": 1}, {"learn": 1, "grasp": 1, "uncertainty": 1}, {"2011": 1, "ieee": 1, "international": 1, "conference": 1, "robotics": 1, "automation": 1, "page": 1, "57035708": 1}, {"ieee": 1, "2011": 1}, {"51": 1, "flood": 1, "sing": 1, "li": 1, "zhang": 1, "tao": 1, "xiang": 1, "timothy": 1, "hospedales": 1, "yongxin": 1, "yang": 1}, {"learn": 3, "metacritic": 1, "network": 1, "sample": 1, "efficient": 1}, {"arxiv": 1, "preprint": 1, "arxiv170609529": 1, "2017": 1}, {"52": 1, "richard": 1, "sutton": 1, "david": 1, "mcallester": 1, "satinder": 1, "p": 1, "singh": 1, "yishay": 1, "mansour": 1}, {"policy": 1, "gradient": 1, "methods": 1, "reinforcement": 1, "learn": 1, "function": 1, "approximation": 1}, {"advance": 1, "neural": 1, "information": 1, "process": 1, "systems": 1, "page": 1, "10571063": 1, "2000": 1}, {"53": 1, "naftali": 1, "tishby": 1, "fernando": 1, "c": 1, "pereira": 1, "william": 1, "bialek": 1}, {"information": 1, "bottleneck": 1, "method": 1}, {"arxiv": 1, "preprint": 1, "physics0004057": 1, "2000": 1}, {"54": 1, "naftali": 1, "tishby": 1, "noga": 1, "zaslavsky": 1}, {"deep": 1, "learn": 1, "information": 1, "bottleneck": 1, "principle": 1}, {"2015": 1, "ieee": 1, "information": 1, "theory": 1, "workshop": 1, "itw": 1, "page": 1, "15": 1}, {"ieee": 1, "2015": 1}, {"55": 1, "josh": 1, "tobin": 1, "rachel": 1, "fong": 1, "alex": 1, "ray": 1, "jonas": 1, "schneider": 1, "wojciech": 1, "zaremba": 1, "pieter": 1, "abbeel": 1}, {"domain": 1, "randomization": 1, "transfer": 1, "deep": 1, "neural": 1, "network": 1, "simulation": 1, "real": 1, "world": 1}, {"2017": 1, "ieeersj": 1, "international": 1, "conference": 1, "intelligent": 1, "robots": 1, "systems": 1, "iros": 1, "page": 1, "2330": 1}, {"ieee": 1, "2017": 1}, {"56": 1, "twan": 1, "van": 1, "laarhoven": 1}, {"l2": 1, "regularization": 1, "versus": 1, "batch": 1, "weight": 1, "normalization": 1}, {"arxiv": 1, "preprint": 1, "arxiv170605350": 1, "2017": 1}, {"57": 1, "jane": 1, "x": 1, "wang": 1, "zeb": 1, "kurthnelson": 1, "dhruva": 1, "tirumala": 1, "hubert": 1, "soyer": 1, "joel": 1, "z": 1, "leibo": 1, "rmi": 1, "munos": 1, "charles": 1, "blundell": 1, "dharshan": 1, "kumaran": 1, "matthew": 1, "botvinick": 1}, {"learn": 2, "reinforcement": 1}, {"corr": 1, "abs161105763": 1, "2016": 1}, {"12": 1, "": 1, "58": 1, "shimon": 1, "whiteson": 1, "brian": 1, "tanner": 1, "matthew": 1, "e": 1, "taylor": 1, "peter": 1, "stone": 1}, {"protect": 1, "evaluation": 1, "overfitting": 1, "empirical": 1, "reinforcement": 1, "learn": 1}, {"2011": 1, "ieee": 1, "symposium": 1, "adaptive": 1, "dynamic": 1, "program": 1, "reinforcement": 1, "learn": 1, "adprl": 1, "page": 1, "120127": 1}, {"ieee": 1, "2011": 1}, {"59": 1, "marek": 1, "wydmuch": 1, "micha": 1, "kempka": 1, "wojciech": 1, "jaskowski": 1}, {"vizdoom": 1, "competitions": 1, "play": 1, "doom": 1, "pixels": 1}, {"ieee": 1, "transactions": 1, "game": 1, "2018": 1}, {"60": 1, "wenhao": 1, "yu": 1, "jie": 1, "tan": 1, "c": 1, "karen": 1, "liu": 1, "greg": 1, "turk": 1}, {"prepare": 1, "unknown": 1, "learn": 1, "universal": 1, "policy": 1, "online": 1, "system": 1, "identification": 1}, {"robotics": 1, "science": 1, "systems": 1, "xiii": 1, "massachusetts": 2, "institute": 1, "technology": 1, "cambridge": 1, "usa": 1, "july": 1, "1216": 1, "2017": 2}, {"61": 1, "vinicius": 1, "zambaldi": 1, "david": 2, "raposo": 1, "adam": 1, "santoro": 1, "victor": 1, "bapst": 1, "yujia": 1, "li": 1, "igor": 1, "babuschkin": 1, "karl": 1, "tuyls": 1, "reichert": 1, "timothy": 1, "lillicrap": 1, "edward": 1, "lockhart": 1, "murray": 1, "shanahan": 1, "victoria": 1, "langston": 1, "razvan": 1, "pascanu": 1, "matthew": 1, "botvinick": 1, "oriol": 1, "vinyals": 1, "peter": 1, "battaglia": 1}, {"deep": 1, "reinforcement": 1, "learn": 1, "relational": 1, "inductive": 1, "bias": 1}, {"international": 1, "conference": 1, "learn": 1, "representations": 1, "2019": 1}, {"62": 1, "amy": 1, "zhang": 1, "nicolas": 1, "ballas": 1, "joelle": 1, "pineau": 1}, {"dissection": 1, "overfitting": 1, "generalization": 1, "continuous": 1, "reinforcement": 1, "learn": 1}, {"arxiv": 1, "preprint": 1, "arxiv180607937": 1, "2018": 1}, {"63": 1, "amy": 1, "zhang": 1, "yuxin": 1, "wu": 1, "joelle": 1, "pineau": 1}, {"natural": 1, "environment": 1, "benchmarks": 1, "reinforcement": 1, "learn": 1}, {"arxiv": 1, "preprint": 1, "arxiv181106032": 1, "2018": 1}, {"64": 1, "chiyuan": 1, "zhang": 1, "samy": 1, "bengio": 1, "moritz": 1, "hardt": 1, "benjamin": 1, "recht": 1, "oriol": 1, "vinyals": 1}, {"understand": 1, "deep": 1, "learn": 1, "require": 1, "rethink": 1, "generalization": 1}, {"5th": 1, "international": 1, "conference": 2, "learn": 1, "representations": 1, "iclr": 1, "2017": 3, "toulon": 1, "france": 1, "april": 1, "2426": 1, "track": 1, "proceed": 1}, {"65": 1, "chiyuan": 1, "zhang": 1, "oriol": 1, "vinyals": 1, "remi": 1, "munos": 1, "samy": 1, "bengio": 1}, {"study": 1, "overfitting": 1, "deep": 1, "reinforcement": 1, "learn": 1}, {"arxiv": 1, "preprint": 1, "arxiv180406893": 1, "2018": 1}, {"66": 1, "chenyang": 1, "zhao": 1, "olivier": 1, "siguad": 1, "freek": 1, "stulp": 1, "timothy": 1, "hospedales": 1}, {"investigate": 1, "generalisation": 1, "continuous": 1, "deep": 1, "reinforcement": 1, "learn": 1}, {"arxiv": 1, "preprint": 1, "arxiv190207015": 1, "2019": 1}, {"13": 1}]