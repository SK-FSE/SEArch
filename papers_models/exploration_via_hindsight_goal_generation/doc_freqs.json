[{"exploration": 1, "via": 1, "hindsight": 1, "goal": 2, "generation": 1, "": 3, "zhizhou": 1, "ren": 1, "kefan": 1, "dong": 1, "institute": 1, "interdisciplinary": 1, "information": 1, "sciences": 1, "tsinghua": 1, "university": 5, "department": 4, "computer": 3, "science": 3, "illinois": 3, "urbanachampaign": 3, "rzz16": 1, "dkf16mailstsinghuaeducn": 1, "yuan": 1, "zhou": 1, "industrial": 1, "enterprise": 1, "systems": 1, "engineer": 1, "yuanzillinoisedu": 1, "qiang": 1, "liu": 1, "texas": 1, "austin": 1, "lqiangcsutexasedu": 1, "jian": 1, "peng": 1, "jianpengillinoisedu": 1, "abstract": 1, "goaloriented": 1, "reinforcement": 1, "learn": 1, "recently": 1, "practical": 1, "framework": 1, "robotic": 1, "manipulation": 1, "task": 1, "agent": 1, "require": 1, "reach": 1, "certain": 1, "define": 1, "function": 1, "state": 1, "space": 1}, {"however": 1, "sparsity": 1, "reward": 1, "definition": 1, "make": 1, "traditional": 1, "reinforcement": 1, "learn": 1, "algorithms": 1, "inefficient": 1}, {"hindsight": 1, "experience": 1, "replay": 1, "recent": 1, "advance": 1, "greatly": 1, "improve": 1, "sample": 1, "efficiency": 1, "practical": 1, "applicability": 1, "problems": 1}, {"exploit": 1, "previous": 1, "replay": 1, "construct": 1, "imaginary": 1, "goals": 1, "simple": 1, "heuristic": 1, "way": 1, "act": 1, "like": 1, "implicit": 1, "curriculum": 1, "alleviate": 1, "challenge": 1, "sparse": 1, "reward": 1, "signal": 1}, {"paper": 1, "introduce": 1, "hindsight": 2, "goal": 2, "generation": 1, "hgg": 1, "novel": 1, "algorithmic": 1, "framework": 1, "generate": 1, "valuable": 1, "goals": 1, "easy": 1, "agent": 2, "achieve": 1, "short": 1, "term": 2, "also": 1, "potential": 1, "guide": 1, "reach": 1, "actual": 1, "long": 1}, {"extensively": 1, "evaluate": 1, "goal": 1, "generation": 1, "algorithm": 1, "number": 1, "robotic": 1, "manipulation": 1, "task": 1, "demonstrate": 1, "substantially": 1, "improvement": 1, "original": 1, "term": 1, "sample": 1, "efficiency": 1}, {"1": 1, "": 2, "introduction": 1, "recent": 1, "advance": 1, "deep": 1, "reinforcement": 1, "learn": 1, "rl": 1, "include": 2, "policy": 1, "gradient": 1, "methods": 1, "schulman": 1, "et": 6, "al": 6, "2015": 3, "2017": 1, "qlearning": 1, "mnih": 2, "demonstrate": 1, "large": 1, "number": 1, "successful": 1, "applications": 1, "solve": 1, "hard": 1, "sequential": 1, "decision": 1, "problems": 1, "robotics": 1, "levine": 1, "2016": 2, "game": 1, "silver": 1, "recommendation": 1, "systems": 1, "karatzoglou": 1, "2013": 1, "among": 1, "others": 1}, {"train": 1, "wellbehaved": 1, "policy": 2, "deep": 1, "reinforcement": 1, "learn": 2, "algorithms": 1, "use": 1, "neural": 1, "network": 1, "functional": 1, "approximators": 1, "stateaction": 1, "value": 1, "function": 1, "distribution": 1, "optimize": 1, "longterm": 1, "expect": 1, "return": 1}, {"convergence": 1, "train": 1, "process": 1, "particularly": 1, "qlearning": 1, "heavily": 1, "dependent": 1, "temporal": 1, "pattern": 1, "reward": 1, "function": 1, "szepesvri": 1, "1998": 1}, {"example": 1, "nonzero": 1, "rewardreturn": 1, "provide": 1, "end": 1, "rollout": 1, "trajectory": 1, "length": 1, "l": 2, "reward": 1, "observe": 1, "lth": 1, "time": 1, "step": 2, "bellman": 1, "update": 1, "qfunction": 1, "would": 1, "become": 1, "inefficient": 1, "require": 1, "least": 1, "propagate": 1, "final": 1, "return": 1, "": 2, "work": 1, "do": 1, "zhizhou": 1, "kefan": 1, "visit": 1, "students": 1, "uiuc": 1}, {"33rd": 1, "conference": 1, "neural": 1, "information": 1, "process": 1, "systems": 1, "neurips": 1, "2019": 1, "vancouver": 1, "canada": 1}, {"qfunction": 1, "earlier": 1, "stateaction": 1, "pair": 1}, {"sparse": 1, "episodic": 1, "reward": 1, "signal": 1, "ubiquitous": 1, "many": 1, "realworld": 1, "problems": 1, "include": 1, "complex": 1, "game": 1, "robotic": 1, "manipulation": 1, "task": 1, "andrychowicz": 1, "et": 1, "al": 1, "2017": 1}, {"therefore": 1, "despite": 1, "notable": 1, "success": 1, "application": 1, "rl": 1, "still": 1, "quite": 1, "limit": 1, "realworld": 1, "problems": 1, "reward": 1, "function": 1, "sparse": 1, "hard": 1, "engineer": 1, "ng": 1, "et": 1, "al": 1, "1999": 1}, {"practice": 1, "human": 1, "experts": 1, "need": 2, "design": 1, "reward": 1, "function": 1, "would": 1, "reflect": 1, "task": 1, "solve": 1, "also": 1, "carefully": 1, "shape": 1, "dense": 1, "way": 1, "optimization": 1, "rl": 1, "algorithms": 1, "ensure": 1, "good": 1, "performance": 1}, {"however": 1, "design": 1, "dense": 1, "reward": 2, "function": 1, "nontrivial": 1, "realworld": 1, "problems": 1, "sparse": 1}, {"example": 1, "goaloriented": 1, "robotics": 1, "task": 1, "agent": 1, "require": 1, "reach": 1, "state": 2, "satisfy": 1, "predefined": 1, "condition": 1, "within": 1, "set": 1, "interest": 1}, {"many": 1, "previous": 1, "efforts": 1, "show": 1, "sparse": 1, "indicator": 1, "reward": 2, "instead": 1, "engineer": 1, "dense": 1, "often": 1, "provide": 1, "better": 1, "practical": 1, "performance": 1, "train": 1, "deep": 1, "qlearning": 1, "policy": 1, "optimization": 1, "algorithms": 1, "andrychowicz": 1, "et": 1, "al": 1, "2017": 1}, {"paper": 1, "focus": 1, "improve": 1, "train": 1, "exploration": 1, "goaloriented": 1, "rl": 1, "problems": 1}, {"notable": 1, "advance": 1, "call": 1, "hindsight": 1, "experience": 1, "replay": 1, "andrychowicz": 1, "et": 1, "al": 1, "2017": 1, "greatly": 1, "improve": 1, "practical": 1, "success": 1, "offpolicy": 1, "deep": 1, "qlearning": 1, "goaloriented": 1, "rl": 1, "problems": 1, "include": 1, "several": 1, "difficult": 1, "robotic": 1, "manipulation": 1, "task": 1}, {"key": 1, "idea": 1, "revisit": 1, "previous": 1, "state": 2, "experience": 1, "replay": 1, "construct": 1, "number": 1, "achieve": 1, "hindsight": 1, "goals": 1, "base": 1, "visit": 1, "intermediate": 1}, {"hindsight": 1, "goals": 1, "relate": 1, "trajectories": 1, "use": 1, "train": 1, "universal": 1, "value": 1, "function": 1, "parameterized": 1, "goal": 1, "input": 1, "algorithms": 1, "deep": 1, "deterministic": 1, "policy": 1, "gradient": 1, "ddpg": 1, "lillicrap": 1, "et": 1, "al": 1}, {"2016": 1}, {"good": 1, "way": 1, "think": 1, "success": 1, "view": 1, "implicit": 1, "curriculum": 1, "first": 1, "learn": 1, "intermediate": 1, "goals": 2, "easy": 1, "achieve": 1, "use": 1, "current": 1, "value": 1, "function": 1, "later": 1, "difficult": 1, "closer": 1, "final": 1, "goal": 1}, {"notable": 1, "difference": 1, "curriculum": 1, "learn": 1, "require": 1, "explicit": 1, "distribution": 1, "initial": 1, "environment": 1, "state": 1, "appear": 1, "applicable": 1, "many": 1, "real": 1, "problems": 1}, {"paper": 1, "study": 1, "problem": 1, "automatically": 1, "generate": 1, "valuable": 1, "hindsight": 1, "goals": 1, "effective": 1, "exploration": 1}, {"different": 1, "random": 2, "curriculum": 1, "heuristics": 1, "use": 1, "original": 1, "goal": 2, "draw": 1, "achieve": 2, "state": 1, "trajectory": 1, "propose": 1, "new": 1, "approach": 1, "find": 1, "intermediate": 1, "goals": 1, "easy": 1, "short": 1, "term": 2, "also": 1, "would": 1, "likely": 1, "lead": 1, "reach": 1, "final": 1, "long": 1}, {"first": 1, "approximate": 1, "value": 2, "function": 2, "actual": 1, "goal": 2, "distribution": 2, "lower": 1, "bind": 1, "decompose": 1, "two": 2, "term": 1, "base": 1, "hindsight": 1, "wasserstein": 1, "distance": 1, "distributions": 1}, {"introduce": 1, "efficient": 1, "discrete": 1, "wasserstein": 1, "barycenter": 1, "solver": 1, "generate": 1, "set": 1, "hindsight": 1, "goals": 1, "optimize": 1, "lower": 1, "bind": 1}, {"finally": 1, "goals": 1, "use": 1, "exploration": 1}, {"experiment": 1, "evaluate": 1, "hindsight": 1, "goal": 1, "generation": 1, "approach": 1, "broad": 1, "set": 1, "robotic": 1, "manipulation": 1, "task": 1}, {"incorporate": 1, "hindsight": 1, "goals": 1, "significant": 1, "improvement": 1, "sample": 1, "efficiency": 1, "demonstrate": 1, "ddpgher": 1}, {"ablation": 1, "study": 1, "show": 1, "exploration": 1, "strategy": 1, "robust": 1, "across": 1, "wide": 1, "set": 1, "hyperparameters": 1}, {"2": 1, "": 2, "background": 1, "reinforcement": 2, "learn": 2, "goal": 1, "agent": 1, "interact": 1, "give": 1, "environment": 1, "maximize": 1, "expect": 1, "cumulative": 1, "reward": 1}, {"environment": 1, "usually": 1, "model": 1, "markov": 1, "decision": 1, "process": 1, "mdp": 1, "give": 1, "tuples": 1, "hs": 1, "p": 1, "r": 1, "": 1, "represent": 1, "set": 1, "state": 1, "action": 1, "respectively": 1}, {"p": 1, "": 6, "transition": 1, "function": 2, "r": 1, "0": 1, "1": 1, "reward": 1}, {"": 1, "discount": 1, "factor": 1}, {"agent": 1, "try": 1, "find": 1, "policy": 1, "": 6, "maximize": 1, "expect": 1, "curriculum": 1, "reward": 1, "v": 1, "s0": 2, "usually": 1, "give": 1, "draw": 1, "distribution": 1, "0": 1, "initial": 1, "state": 1}, {"value": 1, "function": 1, "v": 2, "": 10, "define": 1, "x": 1, "es0": 1, "sit": 1, "st": 2, "st1": 1, "p": 1, "rst": 1}, {"t0": 1, "": 1, "goaloriented": 2, "mdp": 3, "paper": 1, "consider": 1, "specific": 1, "class": 1, "call": 1}, {"use": 1, "g": 1, "denote": 1, "set": 1, "goals": 1}, {"different": 1, "traditional": 1, "mdp": 1, "reward": 1, "function": 1, "r": 1, "goalconditioned": 1, "sparse": 1, "binary": 1, "signal": 1, "indicate": 1, "whether": 1, "goal": 1, "achieve": 1, "": 8, "0": 1, "kst1": 1, "gk2": 1, "g": 1, "rg": 1, "st": 1, "st1": 1, "1": 2, "otherwise": 1}, {"2": 1, "": 4, "g": 1, "know": 1, "tractable": 1, "map": 1, "define": 1, "goal": 1, "representation": 1}, {"g": 1, "give": 1, "threshold": 1, "indicate": 1, "whether": 1, "goal": 1, "consider": 1, "reach": 1, "see": 1, "plappert": 1, "et": 1, "al": 1}, {"2018": 1}, {"universal": 2, "value": 3, "function": 3, "idea": 1, "use": 1, "single": 1, "functional": 1, "approximator": 1, "neural": 1, "network": 1, "represent": 1, "large": 1, "number": 1}, {"goaloriented": 1, "mdps": 1, "goalbased": 1, "value": 1, "function": 1, "policy": 1, "": 13, "give": 1, "goal": 1, "g": 3, "define": 1, "v": 2, "state": 1, "x": 1, "es0": 1, "sit": 1, "st": 3, "gst1": 1, "p": 1, "rg": 1, "st1": 1}, {"2": 1, "t0": 1, "": 10, "let": 1, "g": 4, "0": 1, "1": 1, "joint": 1, "distribution": 2, "start": 2, "state": 1, "s0": 2, "goal": 1, "every": 1, "episode": 1, "stategoal": 1, "pair": 1, "draw": 1, "task": 1}, {"agent": 1, "try": 1, "find": 1, "policy": 1, "": 16, "g": 2, "maximize": 1, "expectation": 1, "discount": 1, "cumulative": 1, "reward": 1, "v": 2, "e": 1, "s0": 2, "gt": 1, "3": 1, "goaloriented": 1, "mdp": 1, "characterize": 1, "several": 1, "reinforcement": 1, "benchmark": 1, "task": 2, "robotics": 1, "openai": 1, "gym": 1, "environment": 1, "plappert": 1, "et": 1, "al": 1, "2018": 1}, {"example": 1, "fetchpush": 1, "see": 1, "figure": 1, "1": 1, "task": 1, "agent": 1, "need": 1, "learn": 1, "push": 1, "box": 1, "designate": 1, "point": 1}, {"task": 1, "state": 1, "system": 1, "contain": 1, "status": 1, "robot": 1, "box": 1}, {"goal": 1, "g": 1, "hand": 1, "indicate": 1, "designate": 1, "position": 1, "box": 1}, {"thus": 1, "map": 2, "": 1, "define": 1, "system": 1, "state": 2, "position": 1, "box": 1, "access": 1, "simulator": 2, "one": 1, "common": 1, "assumption": 1, "make": 1, "previous": 1, "work": 1, "universal": 1, "allow": 1, "environment": 1, "reset": 1, "give": 1, "florensa": 1, "et": 2, "al": 2, "2017": 1, "ecoffet": 1, "2019": 1}, {"kind": 1, "simulator": 1, "excessively": 1, "powerful": 1, "hard": 1, "build": 1, "act": 1, "real": 1, "world": 1}, {"contrary": 1, "method": 1, "require": 1, "universal": 1, "simulator": 1, "thus": 1, "realizable": 1}, {"3": 1, "": 2, "relate": 1, "work": 1, "multigoal": 1, "rl": 1, "role": 1, "goalconditioned": 1, "policy": 1, "investigate": 1, "widely": 1, "deep": 1, "reinforcement": 1, "learn": 1, "scenarios": 1, "pong": 1, "et": 1, "al": 1, "2019": 1}, {"examples": 1, "include": 1, "grasp": 1, "skills": 1, "imitation": 1, "learn": 1, "pathak": 1, "et": 8, "al": 8, "2018": 3, "srinivas": 1, "disentangle": 1, "task": 1, "knowledge": 1, "environment": 1, "mao": 1, "2018a": 1, "ghosh": 1, "2019": 3, "constitute": 1, "lowerlevel": 1, "controller": 1, "hierarchical": 1, "rl": 1, "oh": 1, "2017": 1, "nachum": 1, "huang": 1, "eysenbach": 1}, {"learn": 2, "universal": 1, "value": 1, "function": 2, "parameterizes": 1, "goal": 1, "use": 1, "approximator": 1, "schaul": 1, "et": 3, "al": 3, "2015": 1, "agent": 1, "able": 1, "multiple": 1, "task": 1, "simultaneously": 1, "kaelbling": 1, "1993": 1, "veeriah": 1, "2018": 1, "identify": 1, "important": 1, "decision": 1, "state": 1, "goyal": 1, "2019b": 1}, {"show": 1, "multitask": 1, "learn": 1, "goalconditioned": 1, "policy": 1, "improve": 1, "generalizability": 1, "unseen": 1, "goals": 1, "eg": 1, "schaul": 1, "et": 1, "al": 1}, {"2015": 1}, {"hindsight": 2, "experience": 3, "replay": 3, "andrychowicz": 1, "et": 1, "al": 1, "2017": 1, "effective": 1, "strategy": 1, "generate": 1, "reward": 1, "signal": 1, "failure": 1, "trajectories": 1}, {"idea": 1, "hindsight": 1, "experience": 1, "replay": 1, "extend": 1, "various": 1, "goalconditioned": 2, "problems": 1, "hierarchical": 1, "rl": 1, "levy": 1, "et": 6, "al": 6, "2019": 4, "dynamic": 1, "goal": 1, "pursuit": 1, "fang": 1, "2019a": 1, "imitation": 1, "ding": 1, "sun": 1, "visual": 1, "robotics": 1, "applications": 1, "nair": 1, "2018": 1, "sahni": 1}, {"also": 1, "show": 1, "hindsight": 1, "experience": 1, "replay": 1, "combine": 1, "onpolicy": 1, "reinforcement": 1, "learn": 1, "algorithms": 1, "importance": 1, "sample": 1, "rauber": 1, "et": 1, "al": 1, "2019": 1}, {"curriculum": 2, "learn": 5, "rl": 2, "usually": 1, "suggest": 1, "use": 1, "sequence": 1, "auxiliary": 1, "task": 1, "guide": 1, "policy": 1, "optimization": 1, "also": 1, "relate": 1, "multitask": 1, "lifelong": 1, "transfer": 1}, {"research": 1, "interest": 1, "automatic": 1, "curriculum": 1, "design": 1, "see": 1, "rapid": 1, "growth": 1, "recently": 1, "approach": 1, "propose": 1, "schedule": 1, "give": 1, "set": 1, "auxiliary": 1, "task": 1, "riedmiller": 1, "et": 6, "al": 6, "2018": 4, "colas": 2, "2019": 1, "provide": 1, "intrinsic": 1, "motivation": 1, "forestier": 1, "2017": 1, "pr": 1, "sukhbaatar": 1}, {"generate": 1, "goals": 1, "lead": 1, "highvalue": 1, "state": 1, "could": 1, "substantially": 1, "improve": 1, "sample": 1, "efficiency": 1, "rl": 1, "agent": 1, "goyal": 1, "et": 1, "al": 1, "2019a": 1}, {"guide": 1, "exploration": 1, "curriculum": 1, "generation": 1, "also": 1, "active": 1, "research": 1, "topic": 1, "either": 1, "initial": 1, "state": 1, "florensa": 2, "et": 2, "al": 2, "2017": 1, "goal": 1, "position": 1, "baranes": 1, "oudeyer": 1, "2013": 1, "2018": 1, "consider": 1, "manipulable": 1, "factor": 1, "generate": 1, "intermediate": 1, "task": 1}, {"however": 1, "3": 1, "": 1, "curriculum": 2, "learn": 2, "methods": 1, "domainspecific": 1, "still": 1, "open": 1, "build": 1, "generalize": 1, "framework": 1}, {"4": 1, "": 2, "automatic": 1, "hindsight": 1, "goal": 1, "generation": 1, "discuss": 1, "previous": 1, "section": 1, "provide": 1, "effective": 1, "solution": 1, "resolve": 1, "sparse": 1, "reward": 1, "challenge": 1, "object": 1, "manipulation": 1, "task": 1, "achieve": 1, "state": 1, "past": 1, "trajectories": 1, "replay": 1, "imaginary": 1, "goals": 1}, {"word": 1, "modify": 1, "task": 1, "distribution": 1, "replay": 1, "buffer": 1, "generate": 1, "set": 1, "auxiliary": 1, "nearby": 1, "goals": 1, "use": 1, "exploration": 1, "improve": 1, "performance": 1, "offpolicy": 1, "rl": 1, "agent": 1, "expect": 1, "reach": 1, "distant": 1, "goal": 1}, {"however": 1, "distribution": 2, "hindsight": 1, "goals": 1, "policy": 1, "train": 1, "might": 1, "differ": 1, "significantly": 1, "original": 1, "task": 1, "goal": 1}, {"take": 1, "figure": 2, "1": 2, "example": 1, "desire": 1, "goal": 1, "distribution": 1, "lie": 1, "red": 1, "segment": 1, "visualization": 1, "hindfar": 1, "away": 1, "initial": 1, "position": 1}, {"situation": 1, "hindsight": 1, "sight": 1, "goals": 1, "pink": 1, "particles": 1}, {"goals": 1, "may": 1, "effective": 1, "enough": 1, "promote": 1, "policy": 1, "optimization": 1, "original": 1, "task": 1}, {"goal": 1, "work": 1, "develop": 1, "new": 1, "approach": 1, "generate": 1, "valuable": 1, "hindsight": 1, "goals": 1, "improve": 1, "performance": 1, "original": 1, "task": 1}, {"rest": 1, "section": 1, "present": 1, "new": 1, "algorithmic": 1, "framework": 1, "well": 1, "implementation": 1, "automatic": 1, "hindsight": 1, "goal": 1, "generation": 1, "better": 1, "exploration": 1}, {"41": 1, "": 2, "algorithmic": 1, "framework": 1, "follow": 1, "florensa": 1, "et": 1, "al": 1}, {"2018": 1, "approach": 1, "rely": 1, "follow": 1, "generalizability": 1, "assumption": 1}, {"assumption": 1, "1": 1}, {"value": 1, "function": 1, "policy": 1, "": 1, "specific": 1, "goal": 2, "g": 3, "generalizability": 1, "another": 1, "0": 1, "close": 1, "one": 1, "possible": 1, "mathematical": 1, "characterization": 1, "assumption": 1, "1": 1, "via": 1, "lipschitz": 1, "continuity": 1}, {"similar": 1, "assumptions": 1, "widely": 1, "apply": 1, "many": 1, "scenarios": 1, "asadi": 1, "et": 2, "al": 2, "2018": 1, "luo": 1, "2019": 1, "v": 2, "": 21, "g": 9, "s0": 4, "0": 6, "l": 1, "ds": 3, "4": 1, "metric": 1, "define": 1, "cks": 1, "k2": 2, "kg": 1}, {"5": 1, "": 2, "hyperparameter": 1, "c": 1, "0": 1, "provide": 1, "tradeoff": 1, "distance": 2, "initial": 1, "state": 1, "final": 1, "goals": 1}, {"": 1, "state": 2, "abstraction": 1, "map": 1, "space": 2, "goal": 1}, {"experiment": 1, "task": 1, "openai": 1, "gym": 1, "environment": 1, "plappert": 1, "et": 1, "al": 1, "2018": 1, "simply": 1, "adopt": 1, "stategoal": 1, "mappings": 1, "define": 1, "1": 1}, {"although": 1, "lipschitz": 1, "continuity": 2, "may": 1, "hold": 1, "every": 1, "s0": 1, "": 2, "g": 3, "0": 1, "require": 1, "specific": 1, "region": 1}, {"reasonable": 1, "claim": 1, "bind": 1, "eq": 1}, {"4": 1, "hold": 1, "g": 4, "s0": 2, "": 4, "0": 2, "ds": 1, "large": 1}, {"partly": 1, "due": 1, "reward": 2, "sparsity": 1, "distant": 1, "goals": 1, "optimize": 1, "expect": 1, "cumulative": 1, "see": 1, "eq": 1}, {"3": 1, "scratch": 1, "difficult": 1}, {"instead": 1, "propose": 1, "optimize": 2, "relax": 1, "lower": 1, "bind": 1, "introduce": 1, "intermediate": 1, "goals": 1, "may": 1, "easier": 1}, {"provide": 1, "theorem": 1, "1": 1, "establish": 1, "lower": 1, "bind": 1}, {"theorem": 1, "1": 1}, {"assume": 1, "generalizability": 1, "condition": 1, "eq": 1}, {"4": 1, "hold": 1, "two": 1, "distributions": 1, "g": 2, "": 14, "s0": 1, "0": 4, "v": 2, "l": 1, "dt": 1}, {"6": 1, "": 22, "wasserstein": 1, "distance": 1, "base": 1, "dt": 1, "1": 8, "2": 8, "inf": 1, "e": 1, "ds0": 1, "g": 4, "s0": 3, "denote": 1, "collection": 1, "joint": 1, "distribution": 1, "whose": 1, "marginal": 1, "probabilities": 1, "respectively": 1}, {"4": 1, "": 1, "proof": 1, "theorem": 1, "1": 1, "defer": 1, "appendix": 1}, {"follow": 1, "theorem": 1, "1": 1, "optimize": 1, "cumulative": 1, "reward": 1, "eq": 1}, {"3": 1, "relax": 1, "follow": 1, "surrogate": 1, "problem": 1, "max": 1, "": 9, "v": 1, "l": 1, "dt": 1}, {"7": 1, "": 1, "note": 1, "new": 1, "objective": 1, "function": 1, "intuitive": 1}, {"instead": 1, "optimize": 2, "difficult": 1, "goaltask": 1, "distribution": 1, "": 5, "hope": 1, "find": 1, "collection": 1, "surrogate": 1, "goals": 1, "easy": 1, "also": 1, "close": 1, "converge": 1, "towards": 1}, {"however": 1, "joint": 1, "optimization": 1, "": 1, "nontrivial": 1}, {"highdimensional": 1, "distribution": 2, "task": 2, "b": 1, "policy": 1, "": 4, "optimize": 1, "respect": 1, "shift": 1, "c": 1, "estimation": 1, "value": 1, "function": 1, "v": 1, "may": 1, "quite": 1, "accurate": 1, "train": 1}, {"inspire": 1, "andrychowicz": 1, "et": 1, "al": 1}, {"2017": 1, "adopt": 1, "idea": 1, "use": 1, "hindsight": 1, "goals": 1}, {"first": 1, "enforce": 1, "finite": 1, "set": 1, "k": 1, "particles": 1, "already": 1, "achieve": 1, "statesgoals": 1, "replay": 1, "buffer": 1, "b": 1}, {"another": 1, "word": 1, "support": 1, "set": 1, "lie": 1, "inside": 1, "b": 1}, {"meanwhile": 1, "notice": 1, "direct": 1, "implementation": 1, "problem": 1, "eq": 1}, {"7": 1, "may": 2, "lead": 1, "degeneration": 1, "hindsight": 1, "goal": 1, "selection": 1, "train": 1, "process": 1, "ie": 1, "goals": 1, "draw": 1, "single": 1, "trajectory": 1, "thus": 1, "able": 1, "provide": 1, "sufficient": 1, "exploration": 1}, {"therefore": 1, "introduce": 1, "extra": 1, "diversity": 1, "constraint": 1, "ie": 1, "every": 1, "trajectory": 1, "": 4, "b": 1, "state": 1, "select": 1}, {"practice": 1, "find": 1, "simply": 1, "set": 1, "1": 1, "would": 1, "result": 1, "reasonable": 1, "performance": 1}, {"show": 1, "section": 1, "53": 1, "diversity": 1, "constraint": 1, "indeed": 1, "improve": 1, "robustness": 1, "algorithm": 1}, {"finally": 1, "optimization": 1, "problem": 1, "aim": 1, "solve": 1, "max": 1, "": 2, "k": 1, "st": 1}, {"v": 1, "": 27, "l": 1, "dt": 1, "x": 3, "1s0": 2, "st": 4, "1": 1, "b": 2, "s0": 2, "k": 1, "solve": 1, "optimization": 1, "adapt": 1, "twostage": 1, "iterative": 1, "algorithm": 1}, {"first": 1, "apply": 1, "policy": 1, "optimization": 1, "algorithm": 1, "example": 1, "ddpg": 1, "maximize": 1, "value": 1, "function": 1, "condition": 1, "task": 1, "set": 1, "": 1}, {"fix": 1, "": 1, "optimize": 1, "hindsight": 1, "set": 1, "subject": 1, "diversity": 1, "constraint": 1, "variant": 1, "wellknown": 1, "wasserstein": 1, "barycenter": 1, "problem": 1, "bias": 1, "term": 1, "value": 1, "function": 1, "particle": 1}, {"iterate": 1, "process": 1, "policy": 1, "achieve": 1, "desirable": 1, "performance": 1, "reach": 1, "computation": 1, "budget": 1}, {"hard": 1, "see": 1, "first": 1, "optimization": 1, "value": 1, "function": 1, "straightforward": 1}, {"work": 1, "simply": 1, "use": 1, "ddpgher": 1, "framework": 1}, {"second": 1, "optimization": 1, "hindsight": 1, "goals": 1, "nontrivial": 1}, {"follow": 1, "describe": 1, "efficient": 1, "approximation": 1, "algorithm": 1}, {"42": 1, "": 2, "solve": 2, "wasserstein": 2, "barycenter": 2, "problem": 3, "via": 1, "bipartite": 2, "match": 2, "since": 1, "assume": 1, "hindsight": 1, "k": 1, "particles": 1, "approximately": 1, "combinatorial": 1, "set": 1}, {"instead": 1, "deal": 1, "": 5, "draw": 1, "k": 2, "sample": 1, "empirically": 1, "approximate": 1, "set": 1, "particles": 1, "tb": 1}, {"way": 2, "hindsight": 1, "task": 1, "set": 1, "solve": 1, "follow": 1}, {"every": 1, "task": 1, "instance": 1, "si0": 3, "": 40, "g": 4, "tb": 2, "find": 1, "state": 1, "trajectory": 1, "sit": 2, "b": 1, "together": 1, "minimize": 1, "sum": 1, "x": 1, "wsi0": 2, "8": 1, "define": 1, "cksi0": 1, "k2": 2, "min": 1, "kg": 1, "1": 1, "v": 1, "s0": 1, "st": 1}, {"l": 1, "": 8, "9": 1, "finally": 1, "select": 1, "correspond": 1, "achieve": 1, "state": 1, "st": 2, "construct": 1, "hindsight": 1, "goal": 1, "s0": 1}, {"hard": 1, "see": 1, "combinatorial": 1, "optimization": 1, "exactly": 1, "identify": 1, "optimal": 1, "solution": 1, "5": 1, "": 1, "abovementioned": 1, "wasserstein": 1, "barycenter": 1, "problem": 1}, {"practice": 1, "lipschitz": 1, "constant": 1, "l": 1, "unknown": 1, "therefore": 1, "treat": 1, "hyperparameter": 1}, {"optimal": 1, "solution": 1, "combinatorial": 1, "problem": 1, "eq": 1}, {"8": 1, "solve": 1, "efficiently": 1, "wellknown": 1, "maximum": 1, "weight": 1, "bipartite": 1, "match": 1, "munkres": 1, "1957": 1, "duan": 1, "su": 1, "2012": 1}, {"bipartite": 1, "graph": 1, "gvx": 1, "": 2, "vy": 1, "e": 1, "construct": 1, "follow": 1}, {"vertices": 1, "split": 1, "two": 1, "partition": 1, "vx": 1, "": 2, "vy": 1}, {"every": 1, "vertex": 2, "vx": 1, "represent": 2, "task": 1, "instance": 1, "s0": 1, "": 6, "g": 1, "vy": 1, "trajectory": 1, "b": 1}, {"weight": 1, "edge": 1, "connect": 1, "s0": 1, "": 5, "g": 2, "ws0": 1, "define": 1, "eq": 1}, {"9": 1}, {"paper": 1, "apply": 1, "minimum": 1, "cost": 1, "maximum": 1, "flow": 1, "algorithm": 1, "solve": 1, "bipartite": 1, "match": 1, "problem": 1, "example": 1, "see": 1, "ahuja": 1, "et": 1, "al": 1}, {"1993": 1}, {"algorithm": 1, "1": 3, "exploration": 1, "via": 1, "hindsight": 1, "goal": 1, "generation": 1, "hgg": 1, "initialize": 1, "": 5, "2": 2, "b": 1, "3": 1, "iteration": 1}, {"": 1}, {"": 1}, {"": 7, "n": 1, "4": 1, "sample": 1, "si0": 1, "g": 1, "k": 3, "i1": 2, "5": 1, "find": 1, "distinct": 1, "trajectories": 1, "minimize": 1}, {"initialize": 1, "neural": 1, "network": 1, "": 2}, {"sample": 1, "target": 1, "distribution": 1, "": 1}, {"weight": 1, "bipartite": 1, "match": 1, "": 18, "k": 2, "x": 2, "1": 1, "ws0": 1, "g": 2, "cks0": 1, "s0": 2, "k2": 2, "min": 1, "kg": 1, "st": 2, "v": 1, "l": 1, "i1": 3, "construct": 1, "intermediate": 1, "task": 1, "distribution": 1, "si0": 1}, {"": 12, "1": 2, "g": 1, "arg": 1, "min": 1, "kg": 1, "st": 2, "k2": 1, "v": 1, "s0": 1, "l": 1, "sit": 1, "6": 1, "2": 1}, {"": 1}, {"": 1}, {"": 6, "k": 1, "s0": 1, "g": 2, "si0": 1}, {"critical": 1, "step": 1, "hindsight": 1, "goaloriented": 1, "exploration": 1, "": 2, "0": 1, "1": 1}, {"": 1}, {"": 1}, {"": 6, "h": 1, "1": 1, "st": 1, "g": 1, "noise": 1}, {"together": 1, "greedy": 1, "gaussian": 1, "exploration": 1, "st1": 2, "": 14, "p": 1, "st": 2, "rt": 1, "rg": 1, "s0": 1, "a0": 1, "r0": 1, "s1": 1}, {"": 1}, {"": 2}, {"b": 2, "": 6, "1": 1}, {"": 1}, {"": 1}, {"sample": 1, "minibatch": 2, "b": 2, "replay": 1, "buffer": 1, "use": 2, "perform": 1, "one": 1, "step": 1, "value": 1, "policy": 1, "update": 1, "ddpg": 1, "": 2, "7": 1, "8": 1, "9": 1, "10": 1, "11": 1, "12": 1, "13": 1, "14": 1, "15": 1, "16": 1, "17": 1, "overall": 2, "algorithm": 3, "description": 1, "show": 1, "1": 1}, {"note": 1, "exploration": 1, "strategy": 1, "modification": 1, "step": 1, "8": 1, "generate": 1, "hindsight": 1, "goals": 1, "guide": 1, "agent": 1, "collect": 1, "valuable": 1, "trajectories": 1}, {"complementary": 1, "improvements": 1, "ddpgher": 1, "around": 1, "step": 1, "16": 1, "prioritize": 1, "experience": 2, "replay": 2, "strategy": 1, "schaul": 1, "et": 4, "al": 4, "2016": 1, "zhao": 2, "tresp": 1, "2018": 1, "2019": 2, "variants": 1, "hindsight": 1, "fang": 1, "2019b": 1, "bai": 1}, {"5": 1, "": 3, "experiment": 2, "environments": 2, "base": 1, "standard": 1, "robotic": 1, "manipulation": 1, "openai": 1, "gym": 1, "brockman": 1, "et": 1, "al": 1, "20163": 1}, {"addition": 1, "standard": 1, "settings": 1, "better": 1, "visualize": 1, "improvement": 1, "sample": 1, "efficiency": 1, "vary": 1, "target": 1, "task": 1, "distributions": 1, "follow": 1, "ways": 1, "": 1, "fetch": 1, "environments": 1, "initial": 1, "object": 1, "position": 1, "goal": 1, "generate": 1, "uniformly": 1, "random": 1, "two": 1, "distant": 1, "segment": 1}, {"": 2, "handmanipulation": 1, "environments": 1, "task": 1, "require": 1, "agent": 1, "rotate": 1, "object": 1, "give": 1, "pose": 1, "rotations": 1, "around": 1, "zaxis": 1, "consider": 1}, {"restrict": 1, "initial": 1, "3": 1, "": 1, "code": 1, "available": 1, "httpsgithubcomstilwellgithindsightgoalgeneration": 1}, {"6": 1, "": 1, "axisangle": 1, "small": 1, "interval": 1, "target": 1, "pose": 1, "generate": 1, "symmetry": 1}, {"object": 1, "need": 1, "rotate": 1, "": 1, "degree": 1}, {"": 1, "reach": 1, "environment": 1, "fetchreach": 1, "handreach": 1, "support": 1, "randomization": 1, "initial": 1, "state": 1, "restrict": 1, "target": 1, "distribution": 1, "subset": 1, "original": 1, "goal": 1, "space": 1}, {"regard": 1, "baseline": 1, "comparison": 1, "consider": 1, "original": 1, "ddpgher": 1, "algorithm": 1}, {"also": 1, "investigate": 1, "integration": 1, "experience": 1, "replay": 1, "prioritization": 2, "strategies": 1, "energybased": 1, "ebp": 1, "propose": 1, "zhao": 1, "tresp": 1, "2018": 1, "draw": 1, "prior": 1, "knowledge": 1, "physics": 1, "system": 1, "exploit": 1, "valuable": 1, "trajectories": 1}, {"detail": 1, "experiment": 1, "settings": 1, "include": 1, "appendix": 1, "b": 1}, {"51": 1, "": 8, "hgg": 3, "generate": 2, "better": 1, "hindsight": 1, "goals": 1, "exploration": 1, "episode": 4, "500": 1, "b": 1, "1000": 1, "c": 1, "2000": 1, "3000": 1, "figure": 1, "2": 1, "visualization": 1, "goal": 1, "distribution": 1, "fetchpush": 1}, {"initial": 1, "object": 1, "position": 1, "show": 1, "black": 1, "box": 1}, {"blue": 1, "segment": 1, "indicate": 1, "target": 1, "goal": 1, "distribution": 1}, {"row": 1, "present": 2, "distribution": 1, "hindsight": 1, "goals": 3, "generate": 3, "hgg": 1, "method": 1, "bright": 1, "green": 2, "particles": 2, "batch": 1, "recently": 1, "dark": 1, "previous": 1, "iterations": 1}, {"bottom": 1, "row": 1, "present": 1, "distribution": 1, "replay": 1, "goals": 1, "generate": 1}, {"first": 1, "check": 1, "whether": 1, "hgg": 1, "able": 1, "generate": 1, "meaningful": 1, "hindsight": 1, "goals": 1, "exploration": 1}, {"compare": 1, "hgg": 1, "fetchpush": 1, "environment": 1}, {"show": 1, "figure": 1, "2": 1, "hgg": 1, "algorithm": 1, "generate": 1, "goals": 1, "gradually": 1, "move": 1, "towards": 1, "target": 1, "region": 1}, {"since": 1, "goals": 1, "hindsight": 1, "consider": 1, "achieve": 1, "train": 1}, {"comparison": 1, "replay": 1, "distribution": 1, "ddpgher": 1, "agent": 1, "stick": 1, "around": 1, "initial": 1, "position": 1, "many": 1, "iterations": 1, "indicate": 1, "goals": 1, "may": 1, "able": 1, "efficiently": 1, "guide": 1, "exploration": 1}, {"performance": 1, "benchmark": 1, "robotics": 1, "task": 2, "": 1, "figure": 1, "3": 1, "learn": 1, "curve": 1, "variant": 1, "number": 1, "goaloriented": 1, "robotic": 1, "manipulation": 1}, {"curve": 1, "present": 1, "figure": 1, "train": 1, "default": 1, "hyperparameters": 1, "include": 1, "appendix": 1, "c1": 1}, {"note": 1, "since": 1, "fetchreach": 1, "handreach": 1, "contain": 1, "object": 1, "instance": 1, "ebp": 2, "include": 1, "versions": 1}, {"7": 1, "": 1, "check": 1, "whether": 1, "exploration": 1, "provide": 1, "goals": 1, "generate": 1, "hgg": 1, "result": 1, "better": 1, "policy": 1, "train": 1, "performance": 1}, {"show": 1, "figure": 1, "3": 1, "compare": 1, "vanilla": 1, "energybased": 1, "prioritization": 1, "herebp": 1, "hgg": 1, "hggebp": 1}, {"worth": 1, "note": 1, "since": 1, "ebp": 1, "design": 1, "bellman": 1, "equation": 1, "update": 1, "complementary": 1, "hggbased": 1, "exploration": 1, "approach": 1}, {"among": 1, "eight": 1, "environments": 1, "hgg": 1, "substantially": 1, "outperform": 1, "four": 2, "comparable": 1, "performance": 1, "either": 1, "simple": 1, "difficult": 1}, {"combine": 1, "ebp": 1, "hggebp": 1, "achieve": 1, "best": 1, "performance": 1, "six": 1, "environments": 1, "eligible": 1}, {"performance": 1, "task": 2, "obstacle": 1, "difficult": 1, "craft": 1, "metric": 1, "may": 1, "suitable": 1, "2": 1, "distance": 1, "use": 1, "eq": 1}, {"5": 1}, {"show": 1, "figure": 1, "4": 1, "create": 1, "environment": 1, "base": 1, "fetchpush": 1, "rigid": 1, "obstacle": 1}, {"object": 1, "goal": 1, "uniformly": 1, "generate": 1, "green": 1, "red": 1, "segment": 1, "respectively": 1}, {"brown": 1, "block": 1, "static": 1, "wall": 1, "cannot": 1, "move": 1}, {"addition": 1, "2": 1, "": 1, "also": 1, "construct": 1, "distance": 1, "figure": 1, "4": 1, "visualization": 1, "fetchpush": 1, "obstacle": 1}, {"metric": 1, "base": 1, "graph": 1, "distance": 2, "mesh": 1, "grid": 1, "plane": 1, "blue": 1, "line": 1, "successful": 1, "trajectory": 1, "handcraft": 1, "measure": 1}, {"detail": 1, "description": 1, "defer": 1, "appendix": 1, "b3": 1}, {"intuitively": 1, "speak": 1, "craft": 1, "distance": 1, "better": 1, "2": 1, "due": 1, "existence": 1, "obstacle": 1}, {"experimental": 1, "result": 1, "suggest": 1, "craft": 1, "distance": 2, "metric": 1, "provide": 1, "better": 1, "guidance": 1, "goal": 1, "generation": 1, "train": 1, "significantly": 1, "improve": 1, "sample": 1, "efficiency": 1, "2": 1}, {"would": 1, "future": 1, "direction": 1, "investigate": 1, "ways": 1, "obtain": 1, "learn": 1, "good": 1, "metric": 1}, {"52": 1, "": 2, "comparison": 1, "explicit": 2, "curriculum": 3, "learn": 3, "since": 1, "method": 3, "see": 1, "exploration": 1, "generate": 1, "hindsight": 1, "goals": 1, "intermediate": 1, "task": 1, "distribution": 1, "also": 1, "compare": 1, "another": 1, "recently": 1, "propose": 1, "rl": 1}, {"florensa": 1, "et": 1, "al": 1}, {"2018": 1, "leverage": 1, "leastsquares": 1, "gin": 1, "mao": 1, "et": 1, "al": 1, "2018b": 1, "mimic": 1, "set": 1, "call": 1, "goals": 1, "intermediate": 1, "difficult": 1, "exploration": 1, "goal": 1, "generator": 1}, {"specifically": 1, "task": 1, "settings": 1, "define": 1, "goal": 1, "set": 1, "goid": 1, "": 9, "g": 3, "f": 2, "1": 1, "figure": 1, "5": 1, "comparison": 1, "curricurepresents": 1, "average": 1, "success": 1, "rate": 1, "small": 1, "region": 1, "close": 1, "lum": 1, "learn": 1}, {"compare": 1, "hgg": 1, "goal": 2, "g": 1, "sample": 2, "goid": 1, "implement": 1, "oracle": 1, "original": 1, "hergoid": 1, "generator": 1, "base": 1, "rejection": 1, "could": 1, "uniformly": 1, "two": 1, "threshold": 1, "value": 1}, {"sample": 1, "goals": 1, "goid": 1}, {"result": 1, "figure": 1, "5": 1, "indicate": 1, "hindsight": 1, "goal": 1, "generation": 1, "substantially": 1, "outperform": 1, "even": 1, "goid": 1, "oracle": 1, "generator": 1}, {"note": 1, "experiment": 1, "run": 1, "environment": 1, "fix": 1, "initial": 1, "state": 1, "due": 1, "limitation": 1, "florensa": 1, "et": 1, "al": 1}, {"2018": 1}, {"choice": 1, "": 1, "also": 1, "suggest": 1, "florensa": 1, "et": 1, "al": 1}, {"2018": 1}, {"53": 1, "": 2, "ablation": 2, "study": 1, "hyperparameter": 1, "selection": 1, "section": 1, "set": 2, "test": 1, "several": 1, "hyperparameters": 1, "use": 1, "hindsight": 1, "goal": 1, "generation": 1, "algorithm": 1}, {"lipschitz": 2, "l": 1, "selection": 1, "constant": 1, "task": 1, "dependent": 1, "since": 1, "iss": 1, "relate": 1, "scale": 1, "value": 1, "function": 1, "goal": 1, "distance": 1}, {"robotics": 1, "task": 1, "test": 1, "paper": 1, "find": 1, "easier": 1, "set": 1, "l": 1, "first": 1, "divide": 1, "upper": 1, "bind": 1, "distance": 1, "two": 1, "final": 1, "goals": 1, "environment": 1}, {"test": 2, "choices": 1, "l": 2, "several": 1, "environments": 2, "find": 2, "easy": 1, "range": 1, "work": 1, "well": 1, "show": 1, "robustness": 1, "section": 1}, {"show": 1, "learn": 1, "curve": 1, "fetchpush": 1, "different": 1, "l": 2, "appear": 1, "performance": 1, "hgg": 1, "reasonable": 1, "long": 1, "small": 1}, {"task": 1, "test": 1, "comparisons": 1, "set": 1, "l": 1, "": 1, "50": 1}, {"distance": 1, "weight": 1, "c": 2, "parameter": 1, "define": 1, "tradeoff": 1, "initial": 1, "state": 1, "similarity": 2, "goal": 1}, {"larger": 1, "c": 1, "encourage": 1, "algorithm": 1, "choose": 1, "hindsight": 1, "goals": 1, "closer": 1, "initial": 1, "state": 1}, {"8": 1, "": 1, "result": 1, "figure": 1, "6": 1, "indicate": 1, "choice": 1, "c": 1, "indeed": 1, "robust": 1}, {"task": 1, "test": 1, "comparisons": 1, "set": 1, "c": 1, "": 1, "30": 1}, {"number": 1, "hindsight": 1, "goals": 1, "k": 2, "find": 1, "simple": 1, "task": 1, "choice": 1, "critical": 1}, {"even": 1, "greedy": 1, "approach": 1, "correspond": 1, "k": 1, "": 1, "1": 1, "achieve": 1, "competitive": 1, "performance": 1, "eg": 1}, {"fetchpush": 1, "third": 1, "panel": 1, "figure": 1, "6": 1}, {"difficult": 1, "environment": 1, "fetchpickandplace": 1, "larger": 1, "batch": 1, "size": 1, "significantly": 1, "reduce": 1, "variance": 1, "train": 1, "result": 1}, {"task": 1, "test": 1, "comparisons": 1, "plot": 1, "best": 1, "result": 1, "give": 1, "k": 1, "": 1, "50": 1, "100": 1}, {"figure": 1, "6": 1, "ablation": 1, "study": 1, "hyperparameter": 1, "selection": 1}, {"several": 1, "curve": 1, "omit": 1, "forth": 1, "panel": 1, "provide": 1, "clear": 1, "view": 1, "variance": 1, "comparison": 1}, {"full": 1, "version": 1, "defer": 1, "appendix": 1, "d4": 1}, {"6": 1, "": 2, "conclusion": 1, "present": 1, "novel": 1, "automatic": 1, "hindsight": 2, "goal": 1, "generation": 1, "algorithm": 1, "valuable": 1, "imaginary": 1, "task": 1, "generate": 1, "enable": 1, "efficient": 1, "exploration": 1, "goaloriented": 1, "offpolicy": 1, "reinforcement": 1, "learn": 1}, {"formulate": 1, "idea": 1, "surrogate": 1, "optimization": 1, "identify": 1, "hindsight": 1, "goals": 1, "easy": 1, "achieve": 1, "also": 1, "likely": 1, "lead": 1, "actual": 1, "goal": 1}, {"introduce": 1, "combinatorial": 1, "solver": 1, "generate": 1, "intermediate": 1, "task": 1}, {"extensive": 1, "experiment": 1, "demonstrate": 1, "better": 1, "goaloriented": 1, "exploration": 1, "method": 1, "original": 1, "curriculum": 1, "learn": 2, "collection": 1, "robotic": 1, "task": 1}, {"future": 1, "direction": 1, "incorporate": 1, "controllable": 1, "representation": 1, "learn": 1, "thomas": 1, "et": 3, "al": 3, "2017": 1, "provide": 1, "taskspecific": 1, "distance": 2, "metric": 1, "ghosh": 1, "2019": 1, "srinivas": 1, "2018": 1, "may": 1, "generalize": 1, "method": 1, "complicate": 1, "case": 1, "standard": 1, "wasserstein": 1, "cannot": 1, "apply": 1, "directly": 1}, {"reference": 1, "ravindra": 1, "k": 1, "ahuja": 1, "thomas": 1, "l": 1, "magnanti": 1, "jam": 1, "b": 1, "orlin": 1}, {"network": 1, "flow": 1, "theory": 1, "algorithms": 1, "applications": 1}, {"prenticehall": 1, "inc": 1, "upper": 1, "saddle": 1, "river": 1, "nj": 1, "usa": 1, "1993": 1}, {"isbn": 1, "013617549x": 1}, {"marcin": 1, "andrychowicz": 1, "filip": 1, "wolski": 1, "alex": 1, "ray": 1, "jonas": 1, "schneider": 1, "rachel": 1, "fong": 1, "peter": 1, "welinder": 1, "bob": 1, "mcgrew": 1, "josh": 1, "tobin": 1, "openai": 1, "pieter": 1, "abbeel": 1, "wojciech": 1, "zaremba": 1}, {"hindsight": 1, "experience": 1, "replay": 1}, {"advance": 1, "neural": 1, "information": 1, "process": 1, "systems": 1, "page": 1, "50485058": 1, "2017": 1}, {"kavosh": 1, "asadi": 1, "dipendra": 1, "misra": 1, "michael": 1, "littman": 1}, {"lipschitz": 1, "continuity": 1, "modelbased": 1, "reinforcement": 1, "learn": 1}, {"international": 1, "conference": 1, "machine": 1, "learn": 1, "page": 1, "264273": 1, "2018": 1}, {"chenjia": 1, "bai": 1, "peng": 1, "liu": 1, "wei": 1, "zhao": 1, "xianglong": 1, "tang": 1}, {"guide": 1, "goal": 1, "generation": 1, "hindsight": 1, "multigoal": 1, "reinforcement": 1, "learn": 1}, {"neurocomputing": 1, "2019": 1}, {"adrien": 1, "baranes": 1, "pierreyves": 1, "oudeyer": 1}, {"active": 1, "learn": 1, "inverse": 1, "model": 1, "intrinsically": 1, "motivate": 1, "goal": 1, "exploration": 1, "robots": 1}, {"robotics": 1, "autonomous": 1, "systems": 1, "6114973": 1, "2013": 1}, {"greg": 1, "brockman": 1, "vicki": 1, "cheung": 1, "ludwig": 1, "pettersson": 1, "jonas": 1, "schneider": 1, "john": 1, "schulman": 1, "jie": 1, "tang": 1, "wojciech": 1, "zaremba": 1}, {"openai": 1, "gym": 1, "2016": 1}, {"cdric": 1, "colas": 1, "olivier": 1, "sigaud": 1, "pierreyves": 1, "oudeyer": 1}, {"geppg": 1, "decouple": 1, "exploration": 1, "exploitation": 1, "deep": 1, "reinforcement": 1, "learn": 1, "algorithms": 1}, {"international": 1, "conference": 1, "machine": 1, "learn": 1, "page": 1, "10381047": 1, "2018": 1}, {"cdric": 1, "colas": 1, "pierreyves": 1, "oudeyer": 1, "olivier": 1, "sigaud": 1, "pierre": 1, "fournier": 1, "mohamed": 1, "chetouani": 1}, {"curious": 1, "intrinsically": 1, "motivate": 1, "modular": 1, "multigoal": 1, "reinforcement": 1, "learn": 1}, {"international": 1, "conference": 1, "machine": 1, "learn": 1, "page": 1, "13311340": 1, "2019": 1}, {"9": 1, "": 1, "yiming": 1, "ding": 1, "carlos": 1, "florensa": 1, "pieter": 1, "abbeel": 1, "mariano": 1, "phielipp": 1}, {"goalconditioned": 1, "imitation": 1, "learn": 1}, {"advance": 1, "neural": 1, "information": 1, "process": 1, "systems": 1, "2019": 1}, {"run": 1, "duan": 1, "hsinhao": 1, "su": 1}, {"scale": 1, "algorithm": 1, "maximum": 1, "weight": 1, "match": 1, "bipartite": 1, "graph": 1}, {"proceed": 1, "twentythird": 1, "annual": 1, "acmsiam": 1, "symposium": 1, "discrete": 1, "algorithms": 1, "page": 1, "14131424": 1}, {"society": 1, "industrial": 1, "apply": 1, "mathematics": 1, "2012": 1}, {"adrien": 1, "ecoffet": 1, "joost": 1, "huizinga": 1, "joel": 1, "lehman": 1, "kenneth": 1, "stanley": 1, "jeff": 1, "clune": 1}, {"goexplore": 1, "new": 1, "approach": 1, "hardexploration": 1, "problems": 1}, {"arxiv": 1, "preprint": 1, "arxiv190110995": 1, "2019": 1}, {"benjamin": 1, "eysenbach": 1, "ruslan": 1, "salakhutdinov": 1, "sergey": 1, "levine": 1}, {"search": 1, "replay": 1, "buffer": 1, "bridge": 1, "plan": 1, "reinforcement": 1, "learn": 1}, {"advance": 1, "neural": 1, "information": 1, "process": 1, "systems": 1, "2019": 1}, {"meng": 1, "fang": 1, "cheng": 1, "zhou": 1, "bei": 1, "shi": 1, "boqing": 1, "gong": 1, "jia": 1, "xu": 1, "tong": 1, "zhang": 1}, {"dher": 1, "hindsight": 1, "experience": 1, "replay": 1, "dynamic": 1, "goals": 1}, {"international": 1, "conference": 1, "learn": 1, "representations": 1, "2019a": 1}, {"meng": 1, "fang": 1, "tianyi": 1, "zhou": 1, "yali": 1, "du": 1, "lei": 1, "han": 1, "zhengyou": 1, "zhang": 1}, {"curriculumguided": 1, "hindsight": 1, "experience": 1, "replay": 1}, {"advance": 1, "neural": 1, "information": 1, "process": 1, "systems": 1, "2019b": 1}, {"carlos": 1, "florensa": 1, "david": 1, "hold": 1, "markus": 1, "wulfmeier": 1, "michael": 1, "zhang": 1, "pieter": 1, "abbeel": 1}, {"reverse": 1, "curriculum": 1, "generation": 1, "reinforcement": 1, "learn": 1}, {"conference": 1, "robot": 1, "learn": 1, "page": 1, "482495": 1, "2017": 1}, {"carlos": 1, "florensa": 1, "david": 1, "hold": 1, "xinyang": 1, "geng": 1, "pieter": 1, "abbeel": 1}, {"automatic": 1, "goal": 1, "generation": 1, "reinforcement": 1, "learn": 1, "agents": 1}, {"international": 1, "conference": 1, "machine": 1, "learn": 1, "page": 1, "1514": 1, "1523": 1, "2018": 1}, {"sbastien": 1, "forestier": 1, "yoan": 1, "mollard": 1, "pierreyves": 1, "oudeyer": 1}, {"intrinsically": 1, "motivate": 1, "goal": 1, "exploration": 1, "process": 1, "automatic": 1, "curriculum": 1, "learn": 1}, {"arxiv": 1, "preprint": 1, "arxiv170802190": 1, "2017": 1}, {"dibya": 1, "ghosh": 1, "abhishek": 1, "gupta": 1, "sergey": 1, "levine": 1}, {"learn": 1, "actionable": 1, "representations": 1, "goalconditioned": 1, "policies": 1}, {"international": 1, "conference": 1, "learn": 1, "representations": 1, "2019": 1}, {"anirudh": 1, "goyal": 1, "philemon": 1, "brakel": 1, "william": 1, "fedus": 1, "soumye": 1, "singhal": 1, "timothy": 1, "lillicrap": 1, "sergey": 1, "levine": 1, "hugo": 1, "larochelle": 1, "yoshua": 1, "bengio": 1}, {"recall": 1, "trace": 1, "backtrack": 1, "model": 1, "efficient": 1, "reinforcement": 1, "learn": 1}, {"international": 1, "conference": 1, "learn": 1, "representations": 1, "2019a": 1}, {"anirudh": 1, "goyal": 1, "riashat": 1, "islam": 1, "daniel": 1, "strouse": 1, "zafarali": 1, "ahmed": 1, "matthew": 1, "botvinick": 1, "hugo": 1, "larochelle": 1, "sergey": 1, "levine": 1, "yoshua": 1, "bengio": 1}, {"infobot": 1, "transfer": 1, "exploration": 1, "via": 1, "information": 1, "bottleneck": 1}, {"international": 1, "conference": 1, "learn": 1, "representations": 1, "2019b": 1}, {"zhiao": 1, "huang": 1, "fangchen": 1, "liu": 1, "hao": 1, "su": 1}, {"map": 1, "state": 1, "space": 1, "use": 1, "landmarks": 1, "universal": 1, "goal": 1, "reach": 1}, {"advance": 1, "neural": 1, "information": 1, "process": 1, "systems": 1, "2019": 1}, {"leslie": 1, "pack": 1, "kaelbling": 1}, {"learn": 1, "achieve": 1, "goals": 1}, {"ijcai": 1, "page": 1, "10941099": 1}, {"citeseer": 1, "1993": 1}, {"alexandros": 1, "karatzoglou": 1, "linas": 1, "baltrunas": 1, "yue": 1, "shi": 1}, {"learn": 1, "rank": 1, "recommender": 1, "systems": 1}, {"proceed": 1, "7th": 1, "acm": 1, "conference": 1, "recommender": 1, "systems": 1, "page": 1, "493494": 1}, {"acm": 1, "2013": 1}, {"sergey": 1, "levine": 1, "chelsea": 1, "finn": 1, "trevor": 1, "darrell": 1, "pieter": 1, "abbeel": 1}, {"endtoend": 1, "train": 1, "deep": 1, "visuomotor": 1, "policies": 1}, {"journal": 1, "machine": 1, "learn": 1, "research": 1, "17113341373": 1, "2016": 1}, {"andrew": 1, "levy": 1, "george": 1, "konidaris": 1, "robert": 1, "platt": 1, "kate": 1, "saenko": 1}, {"learn": 1, "multilevel": 1, "hierarchies": 1, "hindsight": 1}, {"international": 1, "conference": 1, "learn": 1, "representations": 1, "2019": 1}, {"timothy": 1, "p": 1, "lillicrap": 1, "jonathan": 1, "j": 1, "hunt": 1, "alexander": 1, "pritzel": 1, "nicolas": 1, "heess": 1, "tom": 1, "erez": 1, "yuval": 1, "tassa": 1, "david": 1, "silver": 1, "daan": 1, "wierstra": 1}, {"continuous": 1, "control": 1, "deep": 1, "reinforcement": 1, "learn": 1}, {"international": 1, "conference": 1, "learn": 1, "representations": 1, "2016": 1}, {"yuping": 1, "luo": 1, "huazhe": 1, "xu": 1, "yuanzhi": 1, "li": 1, "yuandong": 1, "tian": 1, "trevor": 1, "darrell": 1, "tengyu": 1}, {"algorithmic": 1, "framework": 1, "modelbased": 1, "deep": 1, "reinforcement": 1, "learn": 1, "theoretical": 1, "guarantee": 1}, {"international": 1, "conference": 1, "learn": 1, "representations": 1, "2019": 1}, {"10": 1, "": 1, "jiayuan": 1, "mao": 1, "honghua": 1, "dong": 1, "joseph": 1, "j": 1, "lim": 1}, {"universal": 1, "agent": 1, "disentangle": 1, "environments": 1, "task": 1}, {"international": 1, "conference": 1, "learn": 1, "representations": 1, "2018a": 1}, {"xudong": 1, "mao": 1, "qing": 1, "li": 1, "haoran": 1, "xie": 1, "raymond": 1, "yiu": 1, "keung": 1, "lau": 1, "zhen": 1, "wang": 1, "stephen": 1, "paul": 1, "smolley": 1}, {"effectiveness": 1, "least": 1, "square": 1, "generative": 1, "adversarial": 1, "network": 1}, {"ieee": 1, "transactions": 1, "pattern": 1, "analysis": 1, "machine": 1, "intelligence": 1, "2018b": 1}, {"volodymyr": 1, "mnih": 1, "koray": 1, "kavukcuoglu": 1, "david": 1, "silver": 1, "andrei": 1, "rusu": 1, "joel": 1, "veness": 1, "marc": 1, "g": 1, "bellemare": 1, "alex": 1, "grave": 1, "martin": 1, "riedmiller": 1, "andreas": 1, "k": 1, "fidjeland": 1, "georg": 1, "ostrovski": 1, "et": 1, "al": 1}, {"humanlevel": 1, "control": 1, "deep": 1, "reinforcement": 1, "learn": 1}, {"nature": 1, "5187540529": 1, "2015": 1}, {"jam": 1, "munkres": 1}, {"algorithms": 1, "assignment": 1, "transportation": 1, "problems": 1}, {"journal": 1, "society": 1, "industrial": 1, "apply": 1, "mathematics": 1, "513238": 1, "1957": 1}, {"ofir": 1, "nachum": 1, "shixiang": 1, "shane": 1, "gu": 1, "honglak": 1, "lee": 1, "sergey": 1, "levine": 1}, {"dataefficient": 1, "hierarchical": 1, "reinforcement": 1, "learn": 1}, {"advance": 1, "neural": 1, "information": 1, "process": 1, "systems": 1, "page": 1, "33033313": 1, "2018": 1}, {"ashvin": 1, "v": 1, "nair": 1, "vitchyr": 1, "pong": 1, "murtaza": 1, "dalal": 1, "shikhar": 1, "bahl": 1, "steven": 1, "lin": 1, "sergey": 1, "levine": 1}, {"visual": 1, "reinforcement": 1, "learn": 1, "imagine": 1, "goals": 1}, {"advance": 1, "neural": 1, "information": 1, "process": 1, "systems": 1, "page": 1, "91919200": 1, "2018": 1}, {"andrew": 1, "ng": 1, "daishi": 1, "harada": 1, "stuart": 1, "j": 1, "russell": 1}, {"policy": 1, "invariance": 1, "reward": 2, "transformations": 1, "theory": 1, "application": 1, "shape": 1}, {"proceed": 1, "sixteenth": 1, "international": 1, "conference": 1, "machine": 1, "learn": 1, "page": 1, "278287": 1}, {"morgan": 1, "kaufmann": 1, "publishers": 1, "inc": 1, "1999": 1}, {"junhyuk": 1, "oh": 1, "satinder": 1, "singh": 1, "honglak": 1, "lee": 1, "pushmeet": 1, "kohli": 1}, {"zeroshot": 1, "task": 1, "generalization": 1, "multitask": 1, "deep": 1, "reinforcement": 1, "learn": 1}, {"international": 1, "conference": 1, "machine": 1, "learn": 1, "page": 1, "26612670": 1, "2017": 1}, {"deepak": 1, "pathak": 1, "parsa": 1, "mahmoudieh": 1, "guanghao": 1, "luo": 1, "pulkit": 1, "agrawal": 1, "dian": 1, "chen": 1, "yide": 1, "shentu": 1, "evan": 1, "shelhamer": 1, "jitendra": 1, "malik": 1, "alexei": 1, "efros": 1, "trevor": 1, "darrell": 1}, {"zeroshot": 1, "visual": 1, "imitation": 1}, {"international": 1, "conference": 1, "learn": 1, "representations": 1, "2018": 1}, {"alexandre": 1, "pr": 1, "sbastien": 1, "forestier": 1, "olivier": 1, "sigaud": 1, "pierreyves": 1, "oudeyer": 1}, {"unsupervised": 1, "learn": 1, "goal": 2, "space": 1, "intrinsically": 1, "motivate": 1, "exploration": 1}, {"international": 1, "conference": 1, "learn": 1, "representations": 1, "2018": 1}, {"matthias": 1, "plappert": 1, "marcin": 1, "andrychowicz": 1, "alex": 1, "ray": 1, "bob": 1, "mcgrew": 1, "bowen": 1, "baker": 1, "glenn": 1, "powell": 1, "jonas": 1, "schneider": 1, "josh": 1, "tobin": 1, "maciek": 1, "chociej": 1, "peter": 1, "welinder": 1, "et": 1, "al": 1}, {"multigoal": 1, "reinforcement": 1, "learn": 1, "challenge": 1, "robotics": 1, "environments": 1, "request": 1, "research": 1}, {"arxiv": 1, "preprint": 1, "arxiv180209464": 1, "2018": 1}, {"vitchyr": 1, "h": 1, "pong": 1, "murtaza": 1, "dalal": 1, "steven": 1, "lin": 1, "ashvin": 1, "nair": 1, "shikhar": 1, "bahl": 1, "sergey": 1, "levine": 1}, {"skewfit": 1, "statecovering": 1, "selfsupervised": 1, "reinforcement": 1, "learn": 1}, {"arxiv": 1, "preprint": 1, "arxiv190303698": 1, "2019": 1}, {"paulo": 1, "rauber": 1, "avinash": 1, "ummadisingu": 1, "filipe": 1, "mutz": 1, "jrgen": 1, "schmidhuber": 1}, {"hindsight": 1, "policy": 1, "gradients": 1}, {"international": 1, "conference": 1, "learn": 1, "representations": 1, "2019": 1}, {"martin": 1, "riedmiller": 1, "roland": 1, "hafner": 1, "thomas": 1, "lampe": 1, "michael": 1, "neunert": 1, "jonas": 1, "degrave": 1, "tom": 1, "wiele": 1, "vlad": 1, "mnih": 1, "nicolas": 1, "heess": 1, "jost": 1, "tobias": 1, "springenberg": 1}, {"learn": 1, "play": 1, "solve": 1, "sparse": 1, "reward": 1, "task": 1, "scratch": 1}, {"international": 1, "conference": 1, "machine": 1, "learn": 1, "page": 1, "43414350": 1, "2018": 1}, {"himanshu": 1, "sahni": 1, "toby": 1, "buckley": 1, "pieter": 1, "abbeel": 1, "ilya": 1, "kuzovkin": 1}, {"address": 1, "sample": 1, "complexity": 1, "visual": 1, "task": 1, "use": 1, "hallucinatory": 1, "gans": 1}, {"advance": 1, "neural": 1, "information": 1, "process": 1, "systems": 1, "2019": 1}, {"tom": 1, "schaul": 1, "daniel": 1, "horgan": 1, "karol": 1, "gregor": 1, "david": 1, "silver": 1}, {"universal": 1, "value": 1, "function": 1, "approximators": 1}, {"international": 1, "conference": 1, "machine": 1, "learn": 1, "page": 1, "13121320": 1, "2015": 1}, {"tom": 1, "schaul": 1, "john": 1, "quan": 1, "ioannis": 1, "antonoglou": 1, "david": 1, "silver": 1}, {"prioritize": 1, "experience": 1, "replay": 1}, {"international": 1, "conference": 1, "learn": 1, "representations": 1, "2016": 1}, {"11": 1, "": 1, "john": 1, "schulman": 1, "sergey": 1, "levine": 1, "pieter": 1, "abbeel": 1, "michael": 1, "jordan": 1, "philipp": 1, "moritz": 1}, {"trust": 1, "region": 1, "policy": 1, "optimization": 1}, {"international": 1, "conference": 1, "machine": 1, "learn": 1, "page": 1, "18891897": 1, "2015": 1}, {"john": 1, "schulman": 1, "filip": 1, "wolski": 1, "prafulla": 1, "dhariwal": 1, "alec": 1, "radford": 1, "oleg": 1, "klimov": 1}, {"proximal": 1, "policy": 1, "optimization": 1, "algorithms": 1}, {"arxiv": 1, "preprint": 1, "arxiv170706347": 1, "2017": 1}, {"david": 1, "silver": 1, "aja": 1, "huang": 1, "chris": 1, "j": 1, "maddison": 1, "arthur": 1, "guez": 1, "laurent": 1, "sifre": 1, "george": 1, "van": 1, "den": 1, "driessche": 1, "julian": 1, "schrittwieser": 1, "ioannis": 1, "antonoglou": 1, "veda": 1, "panneershelvam": 1, "marc": 1, "lanctot": 1, "et": 1, "al": 1}, {"master": 1, "game": 1, "go": 1, "deep": 1, "neural": 1, "network": 1, "tree": 1, "search": 1}, {"nature": 1, "5297587484": 1, "2016": 1}, {"aravind": 1, "srinivas": 1, "allan": 1, "jabri": 1, "pieter": 1, "abbeel": 1, "sergey": 1, "levine": 1, "chelsea": 1, "finn": 1}, {"universal": 1, "plan": 1, "network": 1, "learn": 1, "generalizable": 1, "representations": 1, "visuomotor": 1, "control": 1}, {"international": 1, "conference": 1, "machine": 1, "learn": 1, "page": 1, "47394748": 1, "2018": 1}, {"sainbayar": 1, "sukhbaatar": 1, "zeming": 1, "lin": 1, "ilya": 1, "kostrikov": 1, "gabriel": 1, "synnaeve": 1, "arthur": 1, "szlam": 1, "rob": 1, "fergus": 1}, {"intrinsic": 1, "motivation": 1, "automatic": 1, "curricula": 1, "via": 1, "asymmetric": 1, "selfplay": 1}, {"international": 1, "conference": 1, "learn": 1, "representations": 1, "2018": 1}, {"hao": 1, "sun": 1, "zhizhong": 1, "li": 1, "xiaotong": 1, "liu": 1, "dahua": 1, "lin": 1, "bolei": 1, "zhou": 1}, {"policy": 1, "continuation": 1, "hindsight": 1, "inverse": 1, "dynamics": 1}, {"advance": 1, "neural": 1, "information": 1, "process": 1, "systems": 1, "2019": 1}, {"csaba": 1, "szepesvri": 1}, {"asymptotic": 1, "convergencerate": 1, "qlearning": 1}, {"advance": 1, "neural": 1, "information": 1, "process": 1, "systems": 1, "page": 1, "10641070": 1, "1998": 1}, {"valentin": 1, "thomas": 1, "jules": 1, "pondard": 1, "emmanuel": 1, "bengio": 2, "marc": 1, "sarfati": 1, "philippe": 1, "beaudoin": 1, "mariejean": 1, "meurs": 1, "joelle": 1, "pineau": 1, "doina": 1, "precup": 1, "yoshua": 1}, {"independently": 1, "controllable": 1, "feature": 1}, {"arxiv": 1, "preprint": 1, "arxiv170801289": 1, "2017": 1}, {"vivek": 1, "veeriah": 1, "junhyuk": 1, "oh": 1, "satinder": 1, "singh": 1}, {"manygoals": 1, "reinforcement": 1, "learn": 1}, {"arxiv": 1, "preprint": 1, "arxiv180609605": 1, "2018": 1}, {"rui": 1, "zhao": 1, "volker": 1, "tresp": 1}, {"energybased": 1, "hindsight": 1, "experience": 1, "prioritization": 1}, {"conference": 1, "robot": 1, "learn": 1, "page": 1, "113122": 1, "2018": 1}, {"rui": 1, "zhao": 1, "xudong": 1, "sun": 1, "volker": 1, "tresp": 1}, {"maximum": 1, "entropyregularized": 1, "multigoal": 1, "reinforcement": 1, "learn": 1}, {"international": 1, "conference": 1, "machine": 1, "learn": 1, "page": 1, "75537562": 1, "2019": 1}, {"12": 1}]