[{"load": 1, "dice": 1, "trade": 1, "bias": 1, "variance": 1, "anyorder": 1, "score": 1, "function": 1, "estimators": 2, "reinforcement": 1, "learn": 1, "": 5, "gregory": 1, "farquhar": 1, "university": 2, "oxford": 2, "shimon": 1, "whiteson": 1, "jakob": 1, "foerster": 1, "facebook": 1, "ai": 1, "research": 1, "abstract": 1, "gradientbased": 1, "methods": 1, "optimisation": 1, "objectives": 1, "stochastic": 1, "settings": 1, "unknown": 1, "intractable": 1, "dynamics": 1, "require": 1, "derivatives": 1}, {"derive": 1, "objective": 1, "automatic": 1, "differentiation": 1, "produce": 1, "lowvariance": 1, "unbiased": 1, "estimators": 1, "derivatives": 1, "order": 1}, {"objective": 1, "compatible": 1, "arbitrary": 1, "advantage": 1, "estimators": 1, "allow": 1, "control": 1, "bias": 1, "variance": 1, "anyorder": 1, "derivatives": 1, "use": 1, "function": 1, "approximation": 1}, {"furthermore": 1, "propose": 1, "method": 1, "trade": 1, "bias": 1, "variance": 1, "higher": 1, "order": 1, "derivatives": 1, "discount": 1, "impact": 1, "distant": 1, "causal": 1, "dependencies": 1}, {"demonstrate": 1, "correctness": 1, "utility": 1, "objective": 1, "analytically": 1, "tractable": 1, "mdps": 1, "metareinforcementlearning": 1, "continuous": 1, "control": 1}, {"1": 1, "": 2, "introduction": 1, "stochastic": 1, "settings": 1, "reinforcement": 1, "learn": 1, "rl": 2, "often": 1, "impossible": 1, "compute": 1, "derivative": 1, "objectives": 1, "depend": 1, "unknown": 1, "intractable": 1, "distribution": 1, "transition": 1, "function": 1, "environment": 1}, {"case": 1, "gradientbased": 1, "optimisation": 1, "possible": 1, "use": 1, "stochastic": 1, "gradient": 1, "estimators": 1}, {"great": 1, "successes": 1, "domains": 1, "find": 1, "build": 1, "estimators": 1, "firstorder": 1, "derivatives": 1, "amenable": 1, "automatic": 1, "differentiation": 1, "use": 1, "optimise": 1, "parameters": 1, "deep": 1, "neural": 1, "network": 1, "franoislavet": 1, "et": 1, "al": 1, "2018": 1}, {"nonetheless": 1, "number": 1, "excite": 1, "applications": 1, "firstorder": 1, "derivatives": 1, "insufficient": 1}, {"metalearning": 1, "multiagent": 1, "learn": 2, "often": 1, "involve": 1, "differentiate": 1, "step": 1, "gradientbased": 1, "learner": 1, "finn": 1, "et": 4, "al": 4, "2017": 1, "stadie": 1, "2018": 1, "zintgraf": 1, "2019": 1, "foerster": 1, "2018a": 1}, {"higherorder": 1, "optimisation": 1, "methods": 1, "also": 1, "improve": 1, "sample": 1, "efficiency": 1, "furmston": 1, "et": 1, "al": 1, "2016": 1}, {"however": 1, "estimate": 1, "higher": 1, "order": 1, "derivatives": 1, "correctly": 1, "low": 1, "variance": 1, "easily": 1, "context": 1, "automatic": 1, "differentiation": 1, "prove": 1, "challenge": 1}, {"foerster": 1, "et": 1, "al": 1}, {"2018b": 1, "propose": 1, "tool": 1, "construct": 1, "estimators": 1, "anyorder": 1, "derivatives": 1, "easy": 1, "use": 1, "avoid": 1, "cumbersome": 1, "manipulations": 1, "otherwise": 1, "require": 1, "account": 1, "dependency": 1, "gradient": 1, "estimate": 1, "distributions": 1, "sample": 1}, {"however": 1, "formulation": 1, "rely": 2, "pure": 1, "montecarlo": 1, "estimate": 2, "objective": 1, "introduce": 1, "unacceptable": 1, "variance": 1, "first": 1, "higherorder": 1, "derivatives": 2, "limit": 1, "uptake": 1, "methods": 1}, {"meanwhile": 1, "great": 1, "stride": 1, "make": 1, "development": 1, "estimators": 1, "firstorder": 1, "derivatives": 1, "stochastic": 1, "objectives": 1}, {"reinforcement": 1, "learn": 2, "use": 1, "value": 1, "function": 1, "critics": 1, "baselines": 1, "extensively": 1, "study": 1}, {"tradeoff": 1, "bias": 1, "variance": 1, "gradient": 1, "estimators": 1, "make": 1, "explicit": 1, "mix": 1, "objectives": 1, "combine": 1, "montecarlo": 1, "sample": 1, "": 3, "correspondence": 1, "gregoryfarquharcsoxacuk": 1, "33rd": 1, "conference": 1, "neural": 1, "information": 1, "process": 1, "systems": 1, "neurips": 1, "2019": 1, "vancouver": 1, "canada": 1}, {"objective": 1, "learn": 1, "value": 1, "function": 1, "schulman": 1, "et": 1, "al": 1, "2015b": 1}, {"techniques": 1, "create": 1, "families": 1, "advantage": 1, "estimators": 1, "use": 1, "reduce": 1, "variance": 1, "accelerate": 1, "credit": 1, "assignment": 1, "firstorder": 1, "optimisation": 1, "apply": 1, "full": 1, "generality": 1, "higherorder": 1, "derivatives": 1}, {"work": 1, "derive": 1, "objective": 1, "differentiate": 1, "number": 1, "time": 1, "produce": 1, "correct": 1, "estimators": 1, "higherorder": 1, "derivatives": 1, "stochastic": 1, "computation": 1, "graph": 1, "scgs": 1, "markov": 1, "property": 1, "find": 1, "rl": 1, "sequence": 1, "model": 1}, {"unlike": 1, "prior": 1, "work": 1, "objective": 1, "fully": 1, "compatible": 1, "arbitrary": 1, "choices": 1, "advantage": 1, "estimators": 1}, {"use": 3, "approximate": 1, "value": 1, "function": 1, "allow": 1, "explicit": 1, "tradeoffs": 1, "bias": 1, "variance": 1, "anyorder": 1, "derivative": 1, "estimate": 1, "make": 1, "know": 1, "techniques": 1, "future": 1, "advantage": 1, "estimation": 1, "methods": 1, "design": 1, "firstorder": 1, "derivatives": 1}, {"furthermore": 1, "propose": 1, "method": 1, "trade": 1, "bias": 1, "variance": 1, "higher": 1, "order": 1, "derivatives": 1, "discount": 1, "impact": 1, "distant": 1, "causal": 1, "dependencies": 1}, {"empirically": 1, "first": 1, "use": 3, "small": 1, "random": 1, "mdps": 1, "admit": 1, "analytic": 1, "solutions": 1, "show": 1, "estimator": 1, "unbiased": 1, "low": 1, "variance": 2, "perfect": 1, "value": 1, "function": 1, "bias": 1, "may": 1, "flexibly": 1, "trade": 1, "two": 1, "hyperparameters": 1}, {"study": 1, "objective": 1, "challenge": 1, "metareinforcementlearning": 1, "problems": 1, "simulate": 1, "continuous": 1, "control": 1, "show": 1, "impact": 1, "various": 1, "parameter": 1, "choices": 1, "train": 1}, {"demonstration": 1, "code": 1, "available": 1, "https": 1, "githubcomoxwhirlloadeddice": 1}, {"handful": 1, "additional": 1, "line": 1, "code": 1, "need": 1, "implement": 1, "objective": 1, "exist": 1, "codebase": 1, "use": 1, "higherorder": 1, "derivatives": 1, "rl": 1}, {"2": 1, "21": 1, "": 2, "background": 1, "gradient": 1, "estimators": 1, "commonly": 1, "face": 1, "objectives": 1, "form": 1, "expectation": 1, "random": 1, "variables": 1}, {"order": 1, "calculate": 1, "gradient": 3, "expectation": 1, "respect": 1, "parameters": 1, "interest": 1, "must": 1, "often": 1, "employ": 1, "estimators": 1, "cannot": 1, "compute": 1, "exactly": 1}, {"example": 1, "reinforcement": 1, "learn": 1, "environment": 1, "dynamics": 1, "unknown": 1, "form": 1, "part": 1, "objective": 1, "expect": 1, "return": 1}, {"polyonymous": 1, "likelihood": 1, "ratio": 1, "score": 1, "function": 1, "reinforce": 1, "estimator": 1, "give": 1, "": 8, "ex": 2, "f": 3, "x": 3, "log": 1, "px": 1}, {"1": 1, "expectation": 1, "rhs": 1, "may": 1, "estimate": 1, "montecarlo": 1, "sample": 1, "draw": 1, "px": 1, "": 1}, {"often": 1, "f": 1, "independent": 1, "": 1, "second": 1, "term": 1, "drop": 1}, {"f": 1, "depend": 2, "": 2, "random": 1, "variable": 1, "may": 2, "reparameterised": 1, "deterministically": 1, "instead": 1, "drop": 1, "first": 1, "term": 1}, {"see": 1, "fu": 1, "2006": 1, "mohamed": 1, "et": 1, "al": 1}, {"2019": 1, "comprehensive": 1, "review": 1}, {"22": 1, "": 2, "stochastic": 3, "computation": 2, "graph": 3, "mdps": 1, "scgs": 1, "direct": 1, "acyclic": 1, "nod": 1, "determinsitic": 1, "function": 1, "edge": 1, "indicate": 1, "functional": 1, "dependencies": 1, "schulman": 1, "et": 1, "al": 1, "2015a": 1}, {"gradient": 1, "estimators": 1, "describe": 1, "may": 1, "use": 1, "estimate": 1, "gradients": 1, "objective": 1, "sum": 1, "cost": 1, "nod": 1, "respect": 1, "parameters": 1, "": 1, "schulman": 1, "et": 1, "al": 1}, {"2015a": 1, "propose": 1, "surrogate": 1, "loss": 1, "single": 1, "objective": 1, "produce": 1, "desire": 1, "gradient": 1, "estimate": 1, "differentiation": 1}, {"weber": 1, "et": 1, "al": 1}, {"2019": 1, "apply": 1, "advance": 1, "firstorder": 1, "gradient": 1, "estimators": 1, "scgs": 1}, {"formalise": 1, "markov": 1, "properties": 1, "scgs": 1, "allow": 1, "flexible": 1, "powerful": 1, "estimators": 1, "originally": 1, "develop": 1, "context": 1, "reinforcement": 1, "learn": 1, "apply": 1}, {"describe": 1, "estimators": 1, "follow": 1, "subsection": 1, "first": 1, "define": 1, "relevant": 1, "subset": 1, "scgs": 1}, {"keep": 1, "main": 1, "body": 1, "paper": 1, "simple": 1, "highlight": 1, "important": 1, "know": 1, "use": 1, "case": 1, "method": 1, "adopt": 1, "notation": 2, "reinforcement": 1, "learn": 1, "rather": 1, "cumbersome": 1, "generic": 1, "scgs": 1}, {"graph": 1, "reinforcement": 1, "learn": 1, "describe": 1, "markov": 1, "decision": 1, "process": 1, "mdp": 1, "begin": 1, "initial": 1, "state": 1, "s0": 1, "time": 1, "": 1, "0": 1}, {"timestep": 1, "action": 2, "sample": 1, "stochastic": 1, "policy": 1, "": 3, "parameterised": 1, "map": 1, "state": 1}, {"add": 1, "stochastic": 1, "node": 1, "graph": 1}, {"stateaction": 1, "pair": 1, "lead": 1, "reward": 1, "rt": 1, "": 2, "next": 1, "state": 1, "st1": 1, "process": 1, "continue": 1}, {"simple": 1, "mdp": 1, "graph": 1, "show": 1, "figure": 1, "1": 1}, {"figure": 1, "many": 1, "problems": 1, "reward": 1, "condition": 1, "state": 2, "rather": 1, "action": 1}, {"consider": 1, "episodic": 1, "problems": 1, "terminate": 1, "step": 1, "although": 1, "result": 1, "may": 1, "extend": 1, "nonterminating": 1, "case": 1}, {"discount": 1, "reward": 1, "cost": 1, "nod": 1, "graph": 1, "lead": 1, "familiar": 1, "reinforcement": 1, "learn": 1, "objective": 2, "2": 1, "": 1, "figure": 1, "1": 1, "example": 1, "scgs": 1, "support": 1, "new": 1}, {"leave": 1, "right": 1, "vanilla": 1, "mdp": 3, "b": 1, "stochastic": 1, "latent": 1, "goal": 1, "variable": 1, "g": 1, "c": 1, "pomdp": 1, "pt": 1, "expect": 1, "discount": 1, "sum": 1, "reward": 1, "j": 1, "": 3, "e": 1, "t0": 1, "rt": 1, "expectation": 1, "take": 1, "respect": 1, "policy": 1, "well": 1, "unknown": 1, "transition": 1, "dynamics": 1, "underlie": 1}, {"generalisation": 1, "result": 1, "hold": 1, "slightly": 1, "general": 1, "class": 1, "scgs": 1, "well": 1, "whose": 1, "objective": 1, "still": 1, "sum": 1, "reward": 1, "time": 1}, {"may": 2, "number": 1, "stochastic": 1, "deterministic": 1, "nod": 2, "xt": 1, "correspond": 1, "timestep": 2, "however": 1, "influence": 2, "future": 1, "reward": 1, "next": 1}, {"formally": 1, "markov": 1, "property": 1, "state": 1, "node": 1, "w": 3, "exist": 1, "direct": 1, "path": 1, "rt0": 1, "": 3, "t0": 1, "block": 1, "xt": 2, "none": 1, "descendants": 1, "definition": 1, "6": 1, "weber": 1, "et": 1, "al": 1}, {"2019": 1}, {"class": 2, "scgs": 1, "capture": 1, "broad": 1, "mdplike": 1, "model": 1, "figure": 1, "1": 1}, {"23": 1, "": 2, "gradient": 1, "estimators": 1, "advantage": 1, "value": 1, "function": 1, "set": 2, "nod": 2, "scg": 1, "expectation": 1, "objective": 1, "stochastic": 1, "variables": 1, "exclude": 1}, {"reduce": 1, "variance": 1, "serve": 1, "control": 1, "variates": 1, "baselines": 1, "critics": 1, "also": 1, "condition": 1, "sample": 1, "value": 1, "take": 1, "correspond": 1, "stochastic": 1, "nod": 1, "ie": 1}, {"sample": 1, "action": 1}, {"difference": 1, "critic": 1, "baseline": 1, "value": 1, "function": 1, "know": 1, "advantage": 1, "replace": 1, "sample": 1, "cost": 1, "gradient": 1, "estimator": 1}, {"baseline": 1, "value": 1, "function": 1, "affect": 1, "variance": 1, "gradient": 1, "estimators": 1, "weaver": 1, "tao": 1, "2001": 1}, {"however": 1, "use": 1, "learn": 1, "imperfect": 1, "critic": 1, "value": 1, "function": 1, "result": 1, "bias": 1, "gradient": 1, "estimators": 1}, {"may": 1, "trade": 1, "bias": 2, "variance": 3, "use": 1, "different": 1, "mixtures": 1, "sample": 1, "cost": 1, "unbiased": 1, "high": 1, "learn": 1, "critic": 1, "value": 1, "function": 1, "low": 1}, {"choice": 1, "advantage": 1, "estimator": 2, "hyperparameters": 1, "use": 1, "tune": 1, "bias": 1, "variance": 1, "result": 1, "gradient": 1, "suit": 1, "problem": 1, "hand": 1}, {"many": 1, "ways": 1, "model": 1, "advantage": 1, "function": 1, "rl": 1}, {"popular": 1, "simple": 1, "family": 1, "advantage": 1, "estimators": 1, "propose": 1, "schulman": 1, "et": 1, "al": 1}, {"2015b": 1, "agae": 1, "": 15, "st": 1, "x": 1, "0": 1, "rt0": 1, "v": 2, "st0": 2, "1": 1}, {"2": 1, "": 8, "t0": 1, "parameter": 1, "trade": 1, "bias": 2, "variance": 3, "1": 1, "form": 1, "sample": 2, "reward": 2, "unbiased": 1, "high": 1, "0": 1, "agae": 1, "use": 1, "next": 1, "rt": 1, "rely": 1, "heavily": 1, "estimate": 1, "value": 1, "function": 1, "v": 1, "reduce": 1, "cost": 1}, {"24": 1, "": 2, "higher": 2, "order": 2, "estimators": 2, "construct": 1, "gradient": 2, "may": 1, "recursively": 1, "apply": 1, "techniques": 1, "treat": 1, "estimate": 1, "objectives": 1, "new": 1, "scg": 1}, {"foerster": 1, "et": 1, "al": 1}, {"2018b": 1, "note": 1, "several": 1, "shortcomings": 1, "surrogate": 1, "loss": 1, "approach": 1, "schulman": 1, "et": 1, "al": 1}, {"2015a": 1, "higherorder": 1, "derivatives": 1}, {"surrogate": 1, "loss": 1, "cannot": 1, "differentiate": 1, "produce": 1, "correct": 1, "higherorder": 1, "estimators": 1}, {"even": 1, "estimate": 1, "produce": 1, "use": 1, "surrogate": 2, "loss": 2, "cannot": 1, "treat": 1, "objectives": 1, "new": 1, "scg": 1, "sever": 1, "dependencies": 1, "sample": 2, "cost": 1, "distribution": 1}, {"3": 1, "": 1, "address": 1, "foerster": 1, "et": 1, "al": 1}, {"2018b": 1, "introduce": 1, "dice": 1, "single": 1, "objective": 1, "may": 1, "differentiate": 1, "repeatedly": 1, "use": 1, "automatic": 1, "differentiation": 1, "produce": 1, "unbiased": 1, "estimators": 1, "derivatives": 1, "order": 1}, {"dice": 1, "objective": 1, "reinforcement": 1, "learn": 1, "give": 1, "j": 1, "": 8, "x": 1, "rt": 1, "3": 1, "t0": 1, "indicate": 1, "set": 1, "stochastic": 1, "nod": 1, "ie": 1}, {"action": 1, "occur": 1, "timestep": 1, "earlier": 1}, {"special": 2, "operator": 2, "act": 1, "set": 1, "stochastic": 1, "nod": 1, "w": 3, "": 6, "always": 1, "evaluate": 1, "1": 1, "behaviour": 1, "differentiation": 2, "x": 1, "log": 1, "pw": 1, "4": 1, "ww": 1, "effect": 1, "automate": 1, "likelihoodratio": 1, "trick": 2, "expectations": 1, "maintain": 1, "dependencies": 1, "apply": 1, "compute": 1, "higher": 1, "order": 1, "derivatives": 1}, {"notational": 1, "convenience": 1, "later": 1, "derivation": 1, "extend": 1, "definition": 1, "slightly": 1, "define": 1, "operation": 1, "empty": 1, "set": 1, "": 2, "1": 1, "zero": 1, "derivative": 1}, {"original": 1, "version": 1, "dice": 1, "two": 1, "critical": 1, "drawbacks": 1, "compare": 1, "stateoftheart": 1, "methods": 1, "describe": 1, "estimate": 1, "firstorder": 1, "derivatives": 1, "stochastic": 1, "objectives": 1}, {"first": 1, "mechanism": 1, "use": 1, "baselines": 1, "reduce": 1, "variance": 1, "estimators": 1, "higher": 1, "order": 1, "derivatives": 1}, {"mao": 1, "et": 1, "al": 1}, {"2019": 1, "liu": 1, "et": 1, "al": 1}, {"2019": 1, "subsequently": 1, "independently": 1, "suggest": 1, "partial": 1, "solution": 1, "problem": 1, "neither": 1, "provide": 1, "proof": 1, "unbiasedness": 1, "estimator": 1, "beyond": 1, "second": 1, "order": 1}, {"second": 1, "dice": 1, "estimator": 1, "mao": 1, "et": 1, "al": 1}, {"2019": 1, "liu": 1, "et": 1, "al": 1}, {"2019": 1, "formulate": 1, "way": 1, "require": 1, "use": 1, "montecarlo": 1, "sample": 1, "cost": 1}, {"without": 1, "form": 1, "permit": 1, "use": 2, "critic": 1, "value": 1, "function": 1, "way": 1, "make": 1, "full": 1, "range": 1, "possible": 1, "advantage": 1, "estimators": 1}, {"exact": 1, "calculation": 1, "higherorder": 1, "derivative": 1, "estimators": 1, "dependence": 1, "give": 1, "reward": 1, "previous": 2, "action": 1, "lead": 1, "nest": 1, "sum": 1, "timesteps": 1}, {"term": 1, "tend": 1, "high": 1, "variance": 1, "estimate": 1, "data": 1, "become": 1, "small": 1, "vicinity": 1, "local": 1, "optima": 1, "note": 1, "furmston": 1, "et": 1, "al": 1}, {"2016": 1}, {"rothfuss": 1, "et": 1, "al": 1}, {"2018": 1, "use": 1, "observation": 1, "propose": 1, "simplify": 1, "version": 1, "dice": 1, "objective": 1, "drop": 1, "dependencies": 1, "jlv": 1, "c": 1, "": 6, "x": 1, "rt": 1, "5": 1, "t0": 1, "estimator": 1, "bias": 1, "higher": 1, "firstorder": 1, "derivatives": 1, "rothfuss": 1, "et": 1, "al": 1}, {"2018": 1, "derive": 1, "correct": 1, "unbiased": 1, "estimator": 1, "order": 1, "make": 1, "use": 1, "advantage": 1, "estimation": 1, "objective": 1, "extend": 1, "applicability": 1, "beyond": 1, "metalearning": 1, "style": 1, "maml": 1, "finn": 1, "et": 1, "al": 1, "2017": 1}, {"next": 1, "section": 1, "introduce": 1, "new": 1, "objective": 1, "may": 1, "make": 1, "use": 1, "critic": 1, "well": 1, "baseline": 1, "value": 1, "function": 1, "thereby": 1, "allow": 1, "bias": 1, "variance": 1, "anyorder": 1, "derivatives": 1, "trade": 1, "choice": 1, "advantage": 1, "estimator": 1}, {"furthermore": 1, "introduce": 1, "discount": 1, "past": 1, "dependencies": 1, "allow": 1, "smooth": 1, "tradeoff": 1, "bias": 1, "variance": 1, "due": 1, "highvariance": 1, "term": 1, "identify": 1, "furmston": 1, "et": 1, "al": 1}, {"2016": 1}, {"3": 1, "": 3, "method": 1, "dice": 1, "objective": 1, "cast": 1, "sum": 1, "reward": 2, "dependencies": 1, "node": 1, "rt": 1, "stochastic": 1, "cause": 1, "capture": 1}, {"use": 2, "critic": 1, "value": 1, "function": 1, "hand": 1, "must": 1, "forwardlooking": 1, "sum": 1, "return": 1}, {"possible": 1, "graph": 1, "maintain": 1, "markov": 1, "property": 1, "define": 1, "section": 1, "22": 1, "respect": 1, "objective": 1, "permit": 1, "sequential": 1, "decomposition": 1, "cost": 1, "nod": 1, "ie": 2, "reward": 1, "rt": 1, "": 3, "stochastic": 1, "cause": 1, "influence": 1, "action": 1}, {"begin": 1, "dice": 1, "objective": 2, "discount": 2, "sum": 2, "reward": 2, "give": 1, "3": 1, "true": 1, "expect": 1, "trajectories": 1, "draw": 1, "policy": 1, "": 2}, {"4": 1, "": 10, "define": 1, "typical": 1, "rl": 1, "return": 1, "rt": 1, "j": 1, "x": 1, "pt": 1, "0": 1, "t0": 1, "rt0": 1}, {"rt": 12, "": 70, "rt1": 3, "t0": 7, "x": 9, "t1": 3, "0": 2, "simply": 1, "take": 1, "change": 1, "variables": 1, "1": 6, "second": 1, "term": 1, "relabeling": 1, "dummy": 1, "variable": 1, "immediately": 1, "back": 1, "j": 1, "at1": 1, "r0": 2, "a0": 1}, {"6": 1, "": 9, "t0": 1, "last": 1, "line": 1, "use": 1, "a0": 1, "1": 2, "rt": 1, "0": 1}, {"objective": 1, "formulate": 1, "term": 1, "forwardslooking": 1, "return": 1, "capture": 1, "dependencies": 1, "sample": 1, "distribution": 1, "": 3}, {"since": 1, "reexpression": 1, "dice": 1, "objective": 2, "apply": 1, "restrict": 1, "class": 1, "scgs": 1, "requisite": 1, "markov": 1, "property": 1, "still": 1, "guarantee": 1, "derivatives": 2, "unbiased": 1, "estimators": 1, "true": 1, "order": 1}, {"proof": 1, "original": 1, "dice": 1, "objective": 1, "give": 1, "foerster": 1, "et": 1, "al": 1}, {"2018b": 1}, {"r0": 1, "carry": 1, "derivatives": 1, "omit": 1, "follow": 1, "estimators": 1, "clarity": 1}, {"include": 1, "however": 1, "ensure": 1, "convenient": 1, "property": 1, "objective": 1, "still": 1, "evaluate": 2, "expectation": 1, "true": 1, "return": 1, "": 3, "always": 1, "zero": 1}, {"introduce": 1, "value": 1, "function": 1}, {"rt": 1, "conditionally": 1, "independent": 1, "": 4, "well": 1, "derivatives": 1, "condition": 1, "st": 1}, {"markov": 1, "property": 1, "scg": 1, "equivalent": 1, "conditional": 1, "independence": 1, "give": 1, "st": 1, "": 2}, {"consider": 1, "expectation": 2, "new": 1, "form": 1, "j": 1, "": 3, "use": 1, "conditional": 1, "independence": 1, "push": 1, "st": 1, "onto": 1, "rt": 1}, {"complete": 1, "derivation": 1, "please": 1, "see": 1, "supplementary": 1, "material": 1}, {"simply": 1, "critic": 1, "value": 1, "function": 1, "define": 1, "qst": 2, "": 32, "e": 4, "rt": 1, "st": 3, "x": 2, "j": 1, "ert": 1, "t0": 2, "7": 1, "furthermore": 1, "baseline": 1, "depend": 1, "change": 1, "expectation": 1, "estimator": 1, "show": 1, "standard": 1, "derivation": 1, "reproduce": 1, "schulman": 1, "et": 1, "al": 1}, {"2015a": 1}, {"reinforcement": 1, "learn": 1, "common": 1, "use": 1, "expect": 1, "state": 1, "value": 1, "v": 1, "st": 1, "": 4, "eat": 1, "qst": 1, "approximation": 1, "optimal": 1, "baseline": 1}, {"estimator": 1, "may": 1, "use": 1, "ast": 1, "": 8, "qst": 1, "v": 1, "st": 1, "place": 1, "rt": 1, "reduce": 1, "variance": 1}, {"derive": 1, "estimator": 1, "term": 1, "advantage": 1, "ast": 2, "": 10, "recover": 1, "unbiased": 1, "estimate": 1, "derivatives": 1, "order": 1, "x": 1, "j": 1}, {"8": 1, "": 3, "practice": 1, "common": 1, "omit": 1, "thus": 1, "optimise": 1, "undiscounted": 1, "return": 1, "still": 1, "use": 1, "discount": 1, "advantage": 1, "variancereduction": 1, "tool": 1}, {"see": 1, "eg": 1, "discussion": 1, "thomas": 1, "2014": 1}, {"5": 1, "": 3, "31": 1, "function": 1, "approximation": 1, "practice": 1, "estimate": 1, "advantage": 1, "must": 1, "make": 1, "limit": 1, "data": 1}, {"inexact": 1, "model": 2, "critic": 1, "value": 1, "function": 1, "due": 1, "limit": 1, "data": 1, "class": 1, "misspecification": 1, "inefficient": 1, "learn": 1, "introduce": 1, "bias": 1, "gradient": 1, "estimators": 1}, {"work": 1, "schulman": 1, "et": 1, "al": 1}, {"2015b": 1, "may": 1, "use": 1, "combinations": 1, "sample": 1, "cost": 1, "estimate": 1, "value": 1, "form": 1, "advantage": 1, "estimators": 1, "trade": 1, "bias": 1, "variance": 1}, {"however": 1, "thank": 1, "new": 1, "estimator": 1, "capture": 1, "full": 1, "dependencies": 1, "advantage": 1, "sample": 1, "distribution": 1, "tradeoffs": 1, "may": 1, "immediately": 1, "apply": 1, "higherorder": 1, "derivatives": 1}, {"approximate": 1, "baseline": 1, "value": 1, "function": 1, "affect": 1, "estimator": 1, "variance": 1}, {"careful": 1, "choice": 1, "baseline": 1, "may": 1, "nonetheless": 1, "great": 1, "significance": 1, "eg": 1, "exploit": 1, "factorisation": 1, "policy": 1, "foerster": 1, "et": 1, "al": 1, "2018c": 1}, {"formulation": 1, "objective": 1, "extend": 1, "methods": 1, "well": 1, "future": 1, "advance": 1, "advantage": 1, "estimation": 1, "first": 1, "order": 2, "higher": 1, "derivatives": 1}, {"32": 1, "": 2, "variance": 2, "due": 2, "higherorder": 2, "dependencies": 2, "correct": 1, "form": 1, "unbiased": 1, "estimator": 1, "use": 1, "proper": 1, "variancereduction": 1, "strategies": 1, "compute": 1, "advantage": 1, "may": 1, "also": 1, "trade": 1, "bias": 1, "estimate": 1, "derivatives": 1, "arise": 1, "full": 1, "history": 1, "causal": 1}, {"particular": 1, "propose": 1, "set": 1, "discount": 1, "factor": 1, "": 2, "0": 1, "1": 1, "prior": 1, "dependencies": 1, "limit": 1, "horizon": 1, "past": 1, "action": 1, "account": 1, "estimate": 1, "higherorder": 1, "derivatives": 1}, {"similarly": 1, "way": 1, "mdp": 1, "discount": 1, "factor": 1, "": 2, "reduce": 1, "variance": 1, "constrain": 2, "horizon": 1, "future": 1, "must": 1, "consider": 2, "far": 1, "past": 1, "causal": 1, "dependencies": 1, "influence": 1, "higher": 1, "order": 1, "derivatives": 1}, {"first": 1, "q": 1, "note": 1, "act": 1, "set": 1, "stochastic": 1, "nod": 1, "w": 3, "decompose": 1, "product": 1, "": 1}, {"implement": 1, "discount": 1, "exponentially": 1, "decay": 1, "past": 1, "contributions": 1, "ww": 1, "j": 1, "": 16, "x": 1, "t0": 2, "tt0": 2, "at0": 2, "0": 1, "t1": 1}, {"9": 1, "": 2, "t0": 1, "0": 1, "final": 1, "objective": 1, "call": 1, "load": 1, "dice": 1}, {"products": 1, "": 1, "may": 1, "compute": 1, "logspace": 1, "action": 1, "probabilities": 1, "transform": 1, "convenient": 1, "numerically": 1, "stable": 1, "sum": 1}, {"algorithm": 1, "1": 1, "show": 1, "objective": 1, "may": 1, "easily": 1, "compute": 1, "episode": 1}, {"algorithm": 1, "1": 1, "compute": 1, "load": 1, "dice": 1, "objective": 1, "require": 1, "trajectory": 1, "state": 1, "st": 1, "": 4, "action": 1, "0": 1}, {"": 1}, {"": 1}, {"j": 1, "0": 1, "": 1}, {"j": 1, "accumulate": 1, "final": 1, "objective": 1, "w0": 1, "": 1}, {"w": 3, "accumulate": 1, "weight": 1, "stochastic": 1, "dependencies": 1, "": 5, "0": 1, "logat": 1, "st": 1}, {"w": 2, "dependencies": 1, "include": 1, "v": 1, "": 4, "logat": 1, "st": 1}, {"v": 2, "dependencies": 1, "exclude": 1, "deps": 1, "": 3, "f": 2, "w": 1}, {"f": 1, "apply": 1, "operator": 1, "logprobabilities": 1, "j": 2, "": 6, "deps": 1, "ast": 1}, {"dependencies": 1, "weight": 1, "advantage": 2, "ast": 1, "": 6, "end": 2, "return": 2, "j": 1, "function": 2, "f": 1, "x": 1, "expx": 1, "stopgradientx": 1, "0": 1, "estimator": 1, "resemble": 1, "jlv": 1, "c": 1, "although": 1, "make": 1, "use": 1}, {"may": 1, "low": 1, "variance": 1, "bias": 1, "regardless": 1, "choice": 1, "advantage": 1, "estimator": 1}, {"": 2, "1": 1, "recover": 1, "estimator": 2, "8": 1, "unbiased": 2, "advantage": 1}, {"intermediate": 1, "value": 1, "": 1, "able": 1, "trade": 1, "bias": 1, "variance": 1, "demonstrate": 1, "empirically": 1, "section": 1, "4": 1}, {"new": 1, "form": 1, "objective": 1, "allow": 1, "us": 1, "use": 1, "": 1, "reduce": 1, "impact": 1, "high": 1, "variance": 1, "term": 1, "identify": 1, "furmston": 1, "et": 1, "al": 1}, {"2016": 1, "rothfuss": 1, "et": 1, "al": 1}, {"2018": 1, "smooth": 1, "way": 1, "rather": 1, "completely": 1, "drop": 1, "term": 1}, {"6": 1, "": 1, "figure": 1, "2": 1, "convergence": 1, "increase": 1, "batch": 1, "size": 1, "unbiased": 1, "anyorder": 1, "estimators": 1, "dice": 2, "baseline": 1, "mao": 1, "et": 1, "al": 1}, {"2019": 1, "load": 1, "dice": 1}, {"also": 1, "lvc": 1, "rothfuss": 1, "et": 1, "al": 1, "2018": 1, "lowvariance": 1, "bias": 1, "estimator": 1}, {"4": 1, "": 3, "experiment": 1, "section": 1, "empirically": 1, "demonstrate": 1, "correctness": 1, "estimator": 3, "absence": 1, "function": 2, "approximation": 1, "show": 1, "bias": 1, "variance": 1, "may": 1, "trade": 1, "choice": 1, "advantage": 1, "approximate": 1, "value": 1, "available": 1, "b": 1, "use": 1, "novel": 1, "discount": 1, "factor": 1}, {"41": 1, "": 2, "bias": 1, "variance": 1, "anyorder": 1, "derivatives": 1, "make": 1, "initial": 1, "analysis": 1, "simple": 1, "interpretable": 1, "use": 1, "small": 1, "random": 1, "mdps": 1, "five": 1, "state": 3, "four": 1, "action": 1, "per": 1, "reward": 1, "depend": 1}, {"mdps": 1, "discount": 1, "value": 1, "may": 1, "calculate": 1, "analytically": 1, "follow": 1}, {"p": 3, "": 4, "state": 1, "transition": 2, "matrix": 1, "induce": 1, "mdps": 1, "function": 1, "s0": 2, "tabular": 1, "policy": 1, "elements": 1, "give": 1, "x": 1, "pss": 1}, {"10": 1, "0": 1, "": 2, "let": 1, "p0": 1, "initial": 1, "state": 1, "distribution": 1, "vector": 1}, {"probability": 1, "distribution": 1, "state": 1, "time": 1, "vector": 1, "pst": 1, "": 3, "p": 1, "p0": 1}, {"mean": 1, "reward": 2, "time": 1, "rt": 2, "": 2, "pst": 1, "r": 1, "vector": 1, "perstate": 1}, {"finally": 1, "v": 1, "": 15, "x": 2, "rt": 3, "t0": 2, "p": 2, "p0": 2, "1": 1}, {"11": 1, "": 3, "v": 1, "differentiable": 1, "wrt": 1, "may": 1, "easily": 1, "compute": 1, "automatic": 1, "differentiation": 1, "package": 1}, {"detail": 1, "code": 1, "find": 1, "supplementary": 1, "material": 1}, {"lowvariance": 1, "unbiased": 1, "anyorder": 1, "estimator": 1}, {"figure": 1, "2": 1, "show": 1, "correlation": 1, "estimate": 1, "true": 1, "derivatives": 1, "change": 1, "function": 1, "batch": 1, "size": 1, "third": 1, "order": 1}, {"compare": 1, "original": 1, "dice": 2, "estimator": 1, "load": 1, "objective": 1, "propose": 1, "mao": 1, "et": 1, "al": 1}, {"2019": 1, "incorporate": 1, "baseline": 1}, {"load": 1, "dice": 1, "use": 1, "agae": 1, "": 4, "0": 1, "exact": 1, "value": 1, "function": 1, "1": 1, "remain": 1, "unbiased": 1}, {"unbiased": 1, "estimators": 1, "converge": 1, "true": 1, "derivatives": 1, "sufficiently": 1, "large": 1, "batch": 1, "size": 1}, {"however": 1, "use": 1, "advantage": 1, "estimator": 1, "exact": 1, "value": 1, "function": 1, "variance": 1, "may": 1, "dramatically": 1, "reduce": 1, "estimate": 1, "converge": 1, "much": 1, "rapidly": 1}, {"also": 1, "show": 1, "performance": 1, "lvc": 1, "rothfuss": 1, "et": 1, "al": 1, "2018": 1}, {"first": 1, "order": 1, "match": 1, "exactly": 1, "estimator": 1, "mao": 1, "et": 1, "al": 1}, {"2019": 1, "underperform": 1, "load": 1, "dice": 1, "use": 1, "advantage": 1}, {"higher": 1, "order": 1, "low": 1, "variance": 1, "bias": 1, "expect": 1}, {"7": 1, "": 2, "low": 2, "produce": 1, "variance": 1, "estimate": 1, "cost": 1, "high": 1, "bias": 1}, {"effect": 1, "hold": 1, "order": 1, "derivatives": 1}, {"b": 1, "high": 1, "": 2, "consider": 1, "full": 1, "past": 2, "produce": 1, "lowbias": 1, "highvariance": 1, "estimators": 1, "low": 1, "discount": 1}, {"first": 1, "order": 1, "gradients": 1, "unaffected": 1}, {"figure": 1, "3": 1, "trade": 1, "bias": 1, "variance": 1, "": 2, "small": 1, "mdp": 1}, {"trade": 1, "bias": 1, "variance": 1, "advantage": 1, "estimation": 1}, {"figure": 1, "3a": 1, "show": 1, "bias": 1, "standard": 1, "deviation": 1, "estimate": 1, "derivatives": 1, "use": 1, "range": 1, "": 2, "inexact": 1, "value": 2, "function": 3, "perturb": 1, "true": 1, "gaussian": 1, "noise": 1, "state": 1, "emulate": 1, "approximation": 1}, {"effect": 1, "choice": 1, "advantage": 1, "estimator": 1, "trade": 1, "bias": 1, "variance": 1, "first": 1, "order": 1, "anyorder": 1, "derivatives": 1}, {"trade": 1, "bias": 1, "variance": 1, "discount": 1, "cause": 1}, {"figure": 1, "3b": 1, "show": 1, "bias": 1, "standard": 1, "deviation": 1, "estimate": 1, "derivatives": 1, "use": 1, "range": 1, "": 1}, {"isolate": 1, "effect": 1, "": 3, "use": 1, "exact": 1, "value": 1, "function": 1, "0": 1, "absolute": 1, "bias": 1, "variance": 1, "lower": 1, "figure": 1, "3a": 1}, {"firstorder": 1, "derivatives": 1, "unaffected": 1, "": 1, "expect": 1}, {"however": 1, "higherorder": 1, "derivatives": 1, "": 1, "strongly": 1, "affect": 1, "bias": 1, "variance": 1, "result": 1, "estimator": 1}, {"outlier": 1, "": 3, "075": 1, "third": 2, "order": 2, "derivatives": 1, "guarantee": 1, "monotonicity": 1, "bias": 1, "variance": 1, "find": 1, "outliers": 1, "rarer": 1, "second": 1, "appear": 1, "artefacts": 1, "particular": 1, "mdps": 1}, {"42": 1, "": 2, "meta": 1, "reinforcement": 1, "learn": 1, "maml": 1, "load": 1, "dice": 1, "apply": 1, "new": 1, "family": 1, "estimators": 1, "pair": 1, "challenge": 1, "metareinforcementlearning": 1, "problems": 1, "continuous": 1, "control": 1, "follow": 1, "work": 1, "finn": 1, "et": 1, "al": 1}, {"2017": 1}, {"aim": 1, "modelagnostic": 1, "metalearning": 1, "maml": 1, "learn": 1, "good": 2, "initialisation": 1, "neural": 1, "network": 1, "policy": 3, "single": 1, "small": 1, "number": 1, "gradient": 1, "update": 1, "batch": 1, "train": 1, "episodes": 1, "achieve": 1, "performance": 1, "task": 1, "sample": 1, "distribution": 1}, {"metatesting": 1, "policy": 1, "able": 1, "adapt": 1, "new": 1, "task": 1, "distribution": 1}, {"maml": 1, "theoretically": 1, "sound": 1, "original": 1, "implementation": 1, "neglect": 1, "higher": 1, "order": 1, "dependencies": 1, "induce": 1, "rl": 1, "set": 1, "rothfuss": 1, "et": 2, "al": 2, "2018": 2, "stadie": 1}, {"approach": 1, "sample": 1, "number": 1, "task": 1, "adapt": 1, "policy": 1, "innerloop": 1, "policygradient": 1, "optimisation": 1, "step": 1}, {"outer": 1, "loop": 1, "initial": 1, "parameters": 1, "update": 1, "maximise": 1, "return": 1, "postadaptation": 1, "policies": 1}, {"outer": 1, "loop": 2, "optimisation": 1, "depend": 2, "postadaptation": 1, "parameters": 1, "gradients": 1, "estimate": 1, "inner": 1}, {"result": 1, "important": 1, "higherorder": 1, "term": 1, "outer": 1, "loop": 1, "optimisation": 1}, {"use": 1, "correct": 1, "estimator": 1, "inner": 1, "loop": 1, "optimisation": 1, "therefore": 1, "impact": 1, "efficiency": 1, "overall": 1, "metatraining": 1, "procedure": 1, "well": 1, "quality": 1, "final": 1, "solution": 1}, {"innerloop": 1, "optimisation": 1, "use": 1, "novel": 1, "objective": 1, "range": 1, "value": 1, "": 2}, {"sweep": 2, "range": 2, "": 6, "fix": 1, "0": 1, "use": 1, "best": 1, "value": 1, "find": 1}, {"outerloop": 1, "optimisation": 1, "use": 1, "vanilla": 1, "policy": 1, "gradient": 1, "baseline": 1}, {"outerloop": 1, "could": 1, "use": 1, "gradientbased": 1, "policy": 1, "optimisation": 1, "algorithm": 1, "choose": 1, "simple": 1, "version": 1, "isolate": 1, "extent": 1, "impact": 1, "inner": 1, "loop": 1, "estimator": 1}, {"figure": 1, "4": 1, "show": 1, "result": 1}, {"cheetahdir": 1, "task": 1, "": 1, "high": 2, "estimator": 1, "variance": 1, "performance": 1, "bad": 1}, {"": 1, "less": 1, "impactful": 1, "cheetahvel": 1, "task": 1}, {"note": 1, "task": 1, "episodes": 1, "short": 1, "": 1, "low": 1, "value": 1, "function": 2, "simple": 1, "linear": 1, "fit": 1, "batch": 1, "data": 1, "finn": 1, "et": 1, "al": 1}, {"2017": 1}, {"factor": 1, "would": 1, "favor": 1, "high": 1, "": 2}, {"higher": 1, "variance": 1, "return": 1, "better": 1, "value": 2, "function": 2, "rely": 1, "heavily": 1, "learn": 1, "use": 1, "lower": 1, "": 2, "may": 1, "effective": 1}, {"8": 1, "": 3, "figure": 1, "4": 1, "trade": 1, "bias": 1, "variance": 1, "metareinforcementlearning": 1}, {"report": 1, "mean": 1, "standard": 1, "error": 1, "run": 1, "postadaptation": 1, "return": 1, "smooth": 1, "move": 1, "average": 1, "10": 1, "outerloop": 1, "optimisations": 1}, {"environments": 1, "": 2, "10": 1, "lead": 1, "high": 1, "variance": 1}, {"unbiased": 1, "": 2, "10": 1, "version": 1, "objective": 1, "may": 1, "also": 1, "valuable": 1, "value": 1, "function": 1, "better": 1, "use": 1, "effectively": 1, "mitigate": 1, "variance": 1}, {"cheetahvel": 1, "noticeably": 1, "faster": 1, "learn": 1, "achieve": 1, "low": 1, "nonzero": 1, "": 1}, {"analysis": 1, "furmston": 1, "et": 1, "al": 1}, {"2016": 1, "indicate": 1, "magnitude": 1, "higherorder": 1, "term": 1, "discount": 1, "": 1, "many": 1, "case": 1, "become": 1, "small": 1, "policy": 1, "approach": 1, "local": 1, "optimum": 1}, {"consistent": 1, "empirical": 1, "find": 1, "nonzero": 1, "": 1, "may": 1, "learn": 1, "faster": 1, "plateaus": 1, "similar": 1, "level": 1}, {"figure": 1, "5": 1, "appendix": 1, "show": 1, "result": 1, "antvel": 1, "task": 1, "": 3, "important": 1, "factor": 1}, {"conclude": 1, "load": 1, "dice": 1, "provide": 1, "meaningful": 1, "control": 1, "higherorder": 1, "estimator": 1, "significant": 1, "impact": 1, "realistic": 1, "usecase": 1}, {"5": 1, "": 2, "conclusion": 1, "work": 1, "derive": 1, "theoretically": 1, "sound": 1, "objective": 1, "apply": 1, "general": 1, "advantage": 1, "function": 1, "estimation": 1, "anyorder": 1, "derivatives": 1, "reinforcementlearning": 1, "type": 1, "sequential": 1, "problems": 1}, {"context": 1, "function": 1, "approximation": 1, "objective": 1, "unlock": 1, "ability": 1, "trade": 1, "bias": 1, "variance": 1, "higher": 1, "order": 1, "derivatives": 1}, {"importantly": 1, "like": 1, "underlie": 1, "dice": 1, "objective": 2, "single": 1, "generate": 1, "estimators": 1, "anyorder": 1, "derivatives": 1, "repeat": 1, "automatic": 1, "differentiation": 1}, {"propose": 1, "simple": 1, "method": 1, "discount": 1, "impact": 1, "distant": 1, "causal": 1, "dependencies": 1, "estimation": 1, "higher": 1, "order": 1, "derivatives": 1, "allow": 1, "another": 1, "axis": 1, "tradeoff": 1, "bias": 1, "variance": 1}, {"empirically": 1, "use": 1, "small": 1, "random": 1, "mdps": 1, "demonstrate": 1, "behaviour": 1, "bias": 1, "variance": 1, "higherorder": 1, "derivative": 1, "estimate": 1, "show": 1, "utility": 1, "metareinforcementlearning": 1}, {"excite": 1, "applications": 1, "metalearning": 1, "multiagent": 1, "learn": 1, "higherorder": 1, "optimisation": 1, "may": 1, "make": 1, "possible": 1, "use": 1, "new": 1, "objective": 1}, {"future": 1, "work": 1, "also": 1, "wish": 1, "revisit": 1, "choice": 1, "discount": 1, "heuristic": 1, "method": 1, "limit": 1, "impact": 1, "highvariance": 1, "term": 1}, {"theoretical": 1, "analysis": 1, "may": 1, "also": 1, "help": 1, "identify": 1, "contexts": 1, "higherorder": 1, "dependencies": 1, "important": 1, "optimisation": 1}, {"finally": 1, "may": 1, "even": 1, "possible": 1, "metalearn": 1, "hyperparameters": 1, "": 2}, {"acknowledgments": 1, "thank": 1, "maruan": 1, "alshedivat": 1, "minqi": 1, "jiang": 1, "valuable": 1, "discussions": 1}, {"work": 1, "support": 1, "uk": 1, "epsrc": 1, "cdt": 1, "autonomous": 1, "intelligent": 1, "machine": 1, "systems": 1}, {"project": 1, "receive": 1, "fund": 1, "european": 2, "research": 2, "council": 1, "erc": 1, "unions": 1, "horizon": 1, "2020": 1, "innovation": 1, "programme": 1, "grant": 1, "agreement": 1, "number": 1, "637713": 1}, {"9": 1, "": 1, "reference": 1, "chelsea": 1, "finn": 1, "pieter": 1, "abbeel": 1, "sergey": 1, "levine": 1}, {"modelagnostic": 1, "metalearning": 1, "fast": 1, "adaptation": 1, "deep": 1, "network": 1}, {"proceed": 1, "34th": 1, "international": 1, "conference": 1, "machine": 1, "learningvolume": 1, "70": 1, "page": 1, "11261135": 1}, {"jmlr": 1}, {"org": 1, "2017": 1}, {"jakob": 1, "foerster": 1, "richard": 1, "chen": 1, "maruan": 1, "alshedivat": 1, "shimon": 1, "whiteson": 1, "pieter": 1, "abbeel": 1, "igor": 1, "mordatch": 1}, {"learn": 1, "opponentlearning": 1, "awareness": 1}, {"proceed": 1, "17th": 1, "international": 1, "conference": 1, "autonomous": 1, "agents": 1, "multiagent": 1, "systems": 1, "page": 1, "122130": 1}, {"international": 1, "foundation": 1, "autonomous": 1, "agents": 1, "multiagent": 1, "systems": 1, "2018a": 1}, {"jakob": 1, "foerster": 1, "gregory": 1, "farquhar": 1, "maruan": 1, "alshedivat": 1, "tim": 1, "rocktschel": 1, "eric": 1, "xing": 1, "shimon": 1, "whiteson": 1}, {"dice": 1, "infinitely": 1, "differentiable": 1, "monte": 1, "carlo": 1, "estimator": 1}, {"international": 1, "conference": 1, "machine": 1, "learn": 1, "page": 1, "15241533": 1, "2018b": 1}, {"jakob": 1, "n": 1, "foerster": 1, "gregory": 1, "farquhar": 1, "triantafyllos": 1, "afouras": 1, "nantas": 1, "nardelli": 1, "shimon": 1, "whiteson": 1}, {"counterfactual": 1, "multiagent": 1, "policy": 1, "gradients": 1}, {"thirtysecond": 1, "aaai": 1, "conference": 1, "artificial": 1, "intelligence": 1, "2018c": 1}, {"vincent": 1, "franoislavet": 1, "peter": 1, "henderson": 1, "riashat": 1, "islam": 1, "marc": 1, "g": 1, "bellemare": 1, "joelle": 1, "pineau": 1, "et": 1, "al": 1}, {"introduction": 1, "deep": 1, "reinforcement": 1, "learn": 1}, {"foundations": 1, "trend": 1, "r": 1, "machine": 1, "learn": 1, "1134219354": 1, "2018": 1}, {"michael": 1, "c": 1, "fu": 1}, {"gradient": 1, "estimation": 1}, {"handbooks": 1, "operations": 1, "research": 1, "management": 1, "science": 1, "13575616": 1, "2006": 1}, {"thomas": 1, "furmston": 1, "guy": 1, "lever": 1, "david": 1, "barber": 1}, {"approximate": 1, "newton": 1, "methods": 1, "policy": 1, "search": 1, "markov": 1, "decision": 1, "process": 1}, {"journal": 1, "machine": 1, "learn": 1, "research": 1, "17180558105": 1, "2016": 1}, {"hao": 1, "liu": 1, "richard": 1, "socher": 1, "caiming": 1, "xiong": 1}, {"tame": 1, "maml": 1, "efficient": 1, "unbiased": 1, "metareinforcement": 1, "learn": 1}, {"international": 1, "conference": 1, "machine": 1, "learn": 1, "page": 1, "40614071": 1, "2019": 1}, {"jingkai": 1, "mao": 1, "jakob": 1, "foerster": 1, "tim": 1, "rocktschel": 1, "maruan": 1, "alshedivat": 1, "gregory": 1, "farquhar": 1, "shimon": 1, "whiteson": 1}, {"baseline": 1, "order": 1, "gradient": 1, "estimation": 1, "stochastic": 1, "computation": 1, "graph": 1}, {"international": 1, "conference": 1, "machine": 1, "learn": 1, "page": 1, "43434351": 1, "2019": 1}, {"shakir": 1, "mohamed": 1, "mihaela": 1, "rosca": 1, "michael": 1, "figurnov": 1, "andriy": 1, "mnih": 1}, {"monte": 1, "carlo": 1, "gradient": 1, "estimation": 1, "machine": 1, "learn": 1}, {"arxiv": 1, "preprint": 1, "arxiv190610652": 1, "2019": 1}, {"jonas": 1, "rothfuss": 1, "dennis": 1, "lee": 1, "ignasi": 1, "clavera": 1, "tamim": 1, "asfour": 1, "pieter": 1, "abbeel": 1}, {"promp": 1, "proximal": 1, "metapolicy": 1, "search": 1}, {"arxiv": 1, "preprint": 1, "arxiv181006784": 1, "2018": 1}, {"john": 1, "schulman": 1, "nicolas": 1, "heess": 1, "theophane": 1, "weber": 1, "pieter": 1, "abbeel": 1}, {"gradient": 1, "estimation": 1, "use": 1, "stochastic": 1, "computation": 1, "graph": 1}, {"advance": 1, "neural": 1, "information": 1, "process": 1, "systems": 1, "page": 1, "35283536": 1, "2015a": 1}, {"john": 1, "schulman": 1, "philipp": 1, "moritz": 1, "sergey": 1, "levine": 1, "michael": 1, "jordan": 1, "pieter": 1, "abbeel": 1}, {"highdimensional": 1, "continuous": 1, "control": 1, "use": 1, "generalize": 1, "advantage": 1, "estimation": 1}, {"arxiv": 1, "preprint": 1, "arxiv150602438": 1, "2015b": 1}, {"bradly": 1, "c": 1, "stadie": 1, "ge": 1, "yang": 1, "rein": 1, "houthooft": 1, "xi": 1, "chen": 1, "yan": 1, "duan": 1, "yuhuai": 1, "wu": 1, "pieter": 1, "abbeel": 1, "ilya": 1, "sutskever": 1}, {"considerations": 1, "learn": 2, "explore": 1, "via": 1, "metareinforcement": 1}, {"arxiv": 1, "preprint": 1, "arxiv180301118": 1, "2018": 1}, {"philip": 1, "thomas": 1}, {"bias": 1, "natural": 1, "actorcritic": 1, "algorithms": 1}, {"international": 1, "conference": 1, "machine": 1, "learn": 1, "page": 1, "441448": 1, "2014": 1}, {"lex": 1, "weaver": 1, "nigel": 1, "tao": 1}, {"optimal": 1, "reward": 1, "baseline": 1, "gradientbased": 1, "reinforcement": 1, "learn": 1}, {"proceed": 1, "seventeenth": 1, "conference": 1, "uncertainty": 1, "artificial": 1, "intelligence": 1, "page": 1, "538545": 1}, {"morgan": 1, "kaufmann": 1, "publishers": 1, "inc": 1, "2001": 1}, {"thophane": 1, "weber": 1, "nicolas": 1, "heess": 1, "lars": 1, "buesing": 1, "david": 1, "silver": 1}, {"credit": 1, "assignment": 1, "techniques": 1, "stochastic": 1, "computation": 1, "graph": 1}, {"arxiv": 1, "preprint": 1, "arxiv190101761": 1, "2019": 1}, {"luisa": 1, "zintgraf": 1, "kyriacos": 1, "shiarlis": 1, "vitaly": 1, "kurin": 1, "katja": 1, "hofmann": 1, "shimon": 1, "whiteson": 1}, {"caml": 1, "fast": 1, "context": 1, "adaptation": 1, "via": 1, "metalearning": 1}, {"international": 1, "conference": 1, "machine": 1, "learn": 1, "2019": 1}, {"10": 1, "": 14, "6": 1, "derivation": 1, "value": 1, "function": 1, "formulation": 1, "start": 1, "j": 2, "objective": 1, "x": 1, "rt": 1}, {"12": 1, "": 4, "t0": 1, "evaluate": 1, "objective": 1, "take": 1, "expectation": 1, "trajectories": 1, "induce": 1, "policy": 1}, {"": 9, "complete": 1, "sequence": 1, "state": 1, "action": 1, "reward": 1, "s0": 1, "a0": 1, "r1": 1, "st": 1}, {"convenience": 1, "follow": 1, "derivation": 1, "define": 1, "reward": 1, "rt1": 1, "": 1, "index": 1, "next": 1, "time": 1, "step": 1, "action": 1, "take": 1}, {"ensure": 1, "partial": 1, "trajectories": 1, "eg": 1}, {"": 1, "correctly": 1, "keep": 1, "reward": 1, "action": 1, "cause": 1}, {"note": 1, "p": 1, "k": 1, "rt": 1, "": 3, "tk0": 1, "rtk1": 1, "depend": 1}, {"expectation": 1, "objective": 1, "give": 1, "e": 1, "j": 2, "": 74, "x": 7, "p": 4, "13": 1, "rt": 3, "14": 1, "t0": 3, "15": 1, "jt": 3, "16": 1, "note": 1, "time": 1, "step": 1, "term": 1, "form": 1, "f": 2, "gt": 2, "17": 1}, {"next": 1, "use": 2, "p": 5, "": 7, "st": 1, "last": 1, "step": 1, "markov": 1, "property": 1}, {"substitute": 2, "obtain": 3, "x": 8, "jt": 2, "": 77, "p": 8, "st": 4, "f": 3, "gt": 2, "18": 1, "19": 1, "20": 1, "back": 1, "g": 1, "21": 1, "rt": 1, "22": 1, "ert": 1, "23": 1, "qst": 2, "24": 1, "25": 1, "put": 1, "together": 1, "final": 1, "form": 1, "e": 2, "j": 1, "t0": 1, "11": 1, "26": 1, "7": 1, "71": 1, "experimental": 1, "detail": 1, "random": 2, "mdps": 1, "use": 1, "mdptoolboxexamplerand": 1, "function": 2, "pymdptoolbox": 1, "generate": 1, "mdp": 1, "transition": 1, "five": 1, "state": 2, "four": 1, "action": 1, "per": 1}, {"reward": 1, "function": 1, "state": 1, "sample": 1, "n": 1, "5": 1, "10": 1}, {"use": 1, "": 2, "095": 1}, {"sample": 1, "stochastic": 1, "estimators": 1, "use": 1, "batch": 2, "512": 1, "rollouts": 1, "length": 1, "50": 1, "step": 1, "unless": 1, "size": 1, "otherwise": 1, "specify": 1}, {"compute": 1, "higher": 1, "order": 2, "derivatives": 1, "derivative": 1, "first": 1, "parameter": 1, "save": 1, "computation": 1}, {"sweep": 1, "": 5, "use": 1, "200": 1, "batch": 1, "value": 1}, {"simulate": 1, "function": 2, "approximation": 1, "error": 1, "analysis": 1, "impact": 1, "": 2, "add": 1, "gaussian": 1, "noise": 1, "standard": 1, "deviation": 1, "10": 1, "true": 1, "value": 1}, {"72": 1, "": 7, "maml": 2, "experiment": 2, "use": 1, "follow": 1, "hyperparameters": 1, "parameter": 1, "hide": 1, "layer": 2, "size": 3, "number": 1, "task": 3, "batch": 3, "meta": 1, "inner": 1, "loop": 4, "learn": 2, "rate": 2, "outer": 3, "optimiser": 1, "reward": 1, "noise": 1, "value": 1, "097": 1, "100": 1, "2": 1, "20": 1, "trajectories": 1, "40": 1, "01": 1, "adam": 1, "00005": 1, "10": 1, "uniform001": 1, "001": 1, "timestep": 1, "also": 1, "normalise": 1, "advantage": 1, "per": 1}, {"figure": 1, "5": 1, "show": 1, "additional": 1, "experiment": 1, "antvel": 1, "mujoco": 1, "task": 1}, {"domain": 1, "": 3, "important": 1, "factor": 1}, {"figure": 1, "5": 1, "trade": 1, "bias": 1, "variance": 1, "": 2, "antvelocity": 1, "task": 1}, {"report": 1, "mean": 1, "standard": 1, "error": 1, "run": 1, "postadaptation": 1, "return": 1, "smooth": 1, "move": 1, "average": 1, "10": 1, "outerloop": 1, "optimisations": 1, "": 1, "12": 1}]