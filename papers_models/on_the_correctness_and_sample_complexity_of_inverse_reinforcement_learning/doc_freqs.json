[{"correctness": 1, "sample": 1, "complexity": 1, "inverse": 2, "reinforcement": 2, "learn": 2, "": 3, "abi": 1, "komanduru": 1, "purdue": 2, "university": 2, "west": 2, "lafayette": 2, "47906": 2, "akomandupurdueedu": 1, "jean": 1, "honorio": 1, "jhonoriopurdueedu": 1, "abstract": 1, "irl": 1, "problem": 1, "find": 1, "reward": 1, "function": 1, "generate": 1, "give": 2, "optimal": 1, "policy": 1, "markov": 1, "decision": 1, "process": 1}, {"paper": 1, "look": 1, "algorithmicindependent": 1, "geometric": 1, "analysis": 1, "irl": 1, "problem": 1, "finite": 1, "state": 1, "action": 1}, {"l1regularized": 1, "support": 1, "vector": 1, "machine": 1, "formulation": 1, "irl": 1, "problem": 2, "motivate": 1, "geometric": 1, "analysis": 1, "propose": 1, "basic": 1, "objective": 1, "inverse": 1, "reinforcement": 1, "mind": 1, "find": 1, "reward": 1, "function": 1, "generate": 1, "specify": 1, "optimal": 1, "policy": 1}, {"paper": 1, "analyze": 1, "propose": 1, "formulation": 1, "inverse": 1, "reinforcement": 1, "learn": 1, "n": 1, "state": 1, "k": 1, "action": 1, "show": 1, "sample": 1, "complexity": 1, "od2": 1, "lognk": 1, "transition": 2, "probability": 1, "matrices": 1, "nonzeros": 1, "per": 1, "row": 1, "recover": 1, "reward": 1, "function": 1, "generate": 1, "policy": 1, "satisfy": 1, "bellmans": 1, "optimality": 1, "condition": 1, "respect": 1, "true": 1, "probabilities": 1}, {"1": 1, "": 2, "introduction": 1, "reinforcement": 1, "learn": 1, "process": 2, "generate": 1, "optimal": 1, "policy": 1, "give": 1, "markov": 1, "decision": 1, "mdp": 1, "along": 1, "reward": 1, "function": 1}, {"often": 1, "situations": 1, "include": 1, "apprenticeship": 1, "learn": 1, "reward": 1, "function": 1, "unknown": 1, "optimal": 1, "policy": 1, "observe": 1, "action": 1, "expert": 1}, {"case": 1, "desirable": 1, "learn": 1, "reward": 1, "function": 1, "generate": 1, "observe": 1, "optimal": 1, "policy": 1}, {"problem": 1, "refer": 1, "inverse": 1, "reinforcement": 1, "learn": 1, "irl": 1, "ng": 1, "": 1, "russel": 1, "2000": 1}, {"well": 1, "know": 1, "reward": 1, "function": 1, "necessarily": 1, "unique": 1}, {"irl": 1, "problem": 1, "formulate": 1, "two": 1, "different": 1, "ways": 1}, {"first": 1, "form": 1, "consider": 2, "ng": 1, "": 1, "russel": 1, "2000": 1, "well": 1, "paper": 1, "standard": 1, "mdp": 1}, {"several": 1, "approach": 1, "instead": 1, "consider": 1, "linearlysolvable": 1, "mdp": 1, "lmdp": 1, "formulation": 1, "present": 1, "dvijotham": 1, "": 1, "todorov": 1, "2010": 1}, {"various": 1, "algorithms": 1, "solve": 1, "irl": 2, "problem": 1, "propose": 1, "include": 1, "linear": 1, "program": 1, "ng": 1, "": 2, "russel": 1, "2000": 1, "hybrid": 1, "neu": 1, "szepesvri": 1, "2007": 1, "maximum": 1, "margin": 1, "plan": 1, "ratliff": 1, "et": 1, "al": 1}, {"2006": 1, "multiplicative": 1, "weight": 1, "apprenticeship": 1, "learn": 1, "syed": 1, "et": 1, "al": 1}, {"2008": 1, "bayesian": 1, "estimation": 1, "ramachandran": 1, "": 1, "amir": 1, "2007": 1}, {"approach": 1, "lmdp": 1, "formulation": 1, "irl": 2, "include": 1, "maximum": 1, "entropy": 1, "ziebart": 1, "et": 1, "al": 1}, {"gaussian": 1, "process": 1, "irl": 1, "levine": 1, "et": 1, "al": 1}, {"2011": 1}, {"methods": 1, "abbeel": 1, "": 1, "ng": 1, "2004": 1, "look": 1, "use": 1, "irl": 1, "solve": 1, "apprenticeship": 1, "learn": 1, "problem": 1, "try": 1, "find": 1, "reward": 1, "function": 1, "maximize": 1, "margin": 1, "experts": 1, "policy": 1}, {"however": 1, "none": 1, "prior": 1, "work": 1, "provide": 1, "formal": 1, "guarantee": 1, "reward": 1, "function": 1, "obtain": 1, "empirical": 1, "data": 1, "optimal": 1, "true": 1, "transition": 1, "probabilities": 1, "inverse": 1, "reinforcement": 1, "learn": 1}, {"note": 1, "objective": 1, "lmdp": 1, "formulation": 2, "irl": 1, "different": 1, "standard": 1, "mdp": 1}, {"indeed": 1, "give": 1, "true": 1, "transition": 1, "probabilities": 2, "although": 1, "practice": 1, "access": 1, "estimate": 1, "methods": 2, "use": 2, "standard": 1, "mdp": 1, "formulation": 2, "recover": 1, "policy": 1, "bellman": 1, "optimal": 1, "may": 1, "case": 1, "lmdp": 1}, {"33rd": 1, "conference": 1, "neural": 1, "information": 1, "process": 1, "systems": 1, "neurips": 1, "2019": 1, "vancouver": 1, "canada": 1}, {"paper": 1, "look": 1, "formulate": 1, "irl": 1, "problem": 1, "use": 1, "basic": 1, "objective": 1, "inverse": 1, "reinforcement": 1, "find": 1, "reward": 1, "function": 1, "generate": 1, "specify": 1, "optimal": 1, "policy": 1}, {"paper": 1, "also": 1, "look": 1, "establish": 1, "sample": 1, "complexity": 1, "meet": 1, "basic": 1, "goal": 1, "transition": 1, "probabilities": 1, "estimate": 1, "observe": 1, "trajectories": 1}, {"achieve": 1, "algorithmicindependent": 1, "geometric": 1, "analysis": 1, "irl": 1, "problem": 1, "finite": 1, "state": 1, "action": 1, "provide": 1}, {"l1regularized": 1, "support": 1, "vector": 1, "machine": 1, "svm": 1, "formulation": 1, "irl": 1, "problem": 1, "motivate": 1, "geometric": 1, "analysis": 1, "propose": 1}, {"formulation": 1, "provide": 1, "nonparametric": 1, "approach": 2, "compare": 1, "use": 1, "feature": 1, "derive": 1, "state": 1, "neu": 1, "": 1, "szepesvri": 1, "2007": 1, "ziebart": 1, "et": 1, "al": 1}, {"theoretical": 1, "analysis": 1, "sample": 1, "complexity": 1, "l1": 1, "svm": 1, "formulation": 1, "perform": 1}, {"finally": 1, "experimental": 1, "result": 1, "compare": 1, "l1": 2, "svm": 2, "formulation": 2, "linearprogramming": 1, "method": 1, "present": 2, "ng": 1, "": 1, "russel": 1, "2000": 1, "well": 1, "several": 1, "standard": 1, "lmdp": 1, "methods": 1, "show": 1, "improve": 1, "performance": 1, "respect": 2, "basic": 1, "objective": 1, "ie": 1, "bellman": 1, "optimality": 1, "true": 1, "transition": 1, "probabilities": 1}, {"best": 1, "knowledge": 1, "first": 1, "provide": 1, "algorithm": 1, "formal": 1, "guarantee": 1, "inverse": 1, "reinforcement": 1, "learn": 1}, {"2": 1, "": 5, "preliminaries": 1, "formulation": 1, "irl": 1, "problem": 1, "base": 1, "standard": 1, "markov": 1, "decision": 1, "process": 1, "mdp": 1, "psa": 1, "r": 1, "finite": 1, "set": 1, "n": 1, "state": 1}, {"": 4, "a1": 1}, {"": 1}, {"": 1}, {"": 2, "ak": 1, "set": 1, "k": 1, "action": 1}, {"n": 1, "": 2, "nn": 1, "state": 1, "transition": 1, "probabilities": 1, "action": 1}, {"use": 1, "pa": 3, "": 5, "0": 4, "1": 4, "n": 1, "psa": 1, "represent": 2, "state": 4, "transition": 1, "probabilities": 1, "action": 2, "j": 2, "probability": 1, "go": 1, "take": 1}, {"": 3, "0": 1, "1": 1, "discount": 1, "factor": 1}, {"": 3, "r": 2, "reinforcement": 1, "reward": 1, "function": 1}, {"important": 1, "note": 1, "state": 1, "transition": 1, "probability": 1, "matrices": 1, "right": 1, "stochastic": 1}, {"mathematically": 1, "p": 1, "state": 3, "pa": 2, "j": 4, "": 3, "0": 1, "1": 1, "paper": 1, "reward": 1, "function": 2, "assume": 1, "purely": 1, "instead": 1, "action": 1}, {"assumption": 1, "also": 1, "make": 1, "initial": 1, "result": 1, "ng": 1, "": 1, "russel": 1, "2000": 1}, {"policy": 1, "define": 1, "map": 1, "": 3}, {"give": 1, "policy": 1, "": 1, "define": 1, "two": 1, "function": 1}, {"value": 1, "function": 1, "state": 1, "s1": 2, "define": 1, "": 13, "v": 1, "e": 1, "rs1": 3, "2": 1}, {"": 1}, {"": 1}, {"": 3, "represent": 1, "trajectory": 1, "policy": 1}, {"q": 3, "function": 1, "define": 1, "": 22, "rs": 1, "es0": 1, "pa": 2, "v": 1, "s0": 1, "bellman": 2, "optimality": 2, "equation": 2, "state": 1, "policy": 2, "optimal": 1, "mdp": 2, "arg": 1, "max": 1, "aa": 1, "show": 1, "ng": 1, "russel": 1, "2000": 1, "finitestate": 1, "reward": 1, "r": 2, "a1": 1, "equivalent": 1, "follow": 1, "condition": 1, "pa1": 2, "ii": 1, "1": 2, "0": 1}, {"": 1}, {"": 1}, {"": 4, "n": 1, "6": 1, "a1": 2, "also": 1, "show": 1, "unique": 1, "optimal": 1, "policy": 1, "inequality": 1, "strict": 1}, {"note": 1, "condition": 1, "necessary": 1, "sufficient": 1, "policy": 1, "optimal": 1, "reward": 1}, {"thus": 1, "2": 1, "": 1, "condition": 1, "result": 1, "fundamental": 1, "constraint": 1, "standard": 1, "mdp": 1, "irl": 1, "problems": 1}, {"analysis": 1, "condition": 1, "present": 1, "follow": 1, "section": 1}, {"subsequent": 1, "section": 1, "use": 2, "notation": 2, "fai": 2, "": 11, "pa1": 4, "pa": 3, "ii": 2, "1": 2, "empirical": 1, "maximum": 1, "likelihood": 1, "estimate": 1, "transition": 1, "probabilities": 1, "sample": 1, "trajectories": 1, "denote": 1, "similar": 1, "fashion": 1, "enforce": 1, "bellman": 1, "optimality": 1, "policy": 1, "linear": 1, "constraints": 1, "reward": 1, "function": 1, "form": 1, "irl": 1, "problem": 1}, {"lead": 1, "different": 1, "formulations": 1, "irl": 1, "problem": 1, "include": 1, "linear": 1, "program": 1, "bayesian": 1, "estimation": 1, "maximum": 2, "weight": 1, "apprenticeship": 1, "learn": 1, "margin": 1, "plan": 1}, {"irl": 1, "problem": 2, "form": 1, "optimization": 1, "minimize": 1, "loss": 1, "function": 1}, {"instance": 1, "one": 1, "formulation": 1, "present": 1, "ng": 1, "": 17, "russel": 1, "2000": 1, "follow": 1, "maximize": 1, "r": 3, "n": 1, "x": 1, "i1": 1, "subject": 1, "min": 1, "aa2": 1, "ak": 1, "fai": 2, "krk1": 1, "0": 1, "a1": 1, "1": 1}, {"": 1}, {"": 1}, {"": 4, "n": 1, "krk": 1, "rmax": 1, "21": 1, "follow": 1, "norms": 1, "use": 1, "throughout": 1, "paper": 1}, {"infinity": 1, "norm": 1, "ap": 1, "matrix": 1, "": 4, "aij": 2, "define": 1, "kak": 1, "supij": 1}, {"l1": 1, "norm": 1, "vector": 1, "define": 1, "kbk1": 1, "": 2, "bi": 1}, {"induce": 1, "matrix": 2, "norm": 1, "define": 1, "": 1, "supj": 1, "kaj": 1, "k1": 1, "aj": 1, "jth": 1, "row": 1}, {"note": 1, "right": 1, "stochastic": 1, "matrix": 1, "p": 2, "": 4, "see": 1, "1": 2, "kp": 1, "k": 1}, {"3": 1, "": 2, "geometric": 1, "analysis": 1, "irl": 1, "problem": 2, "objective": 1, "inverse": 1, "reinforcement": 1, "learn": 1, "find": 1, "reward": 1, "function": 1, "generate": 1, "optimal": 1, "policy": 1}, {"state": 2, "necessary": 1, "sufficient": 1, "condition": 1, "policy": 1, "": 13, "without": 1, "loss": 1, "generality": 1, "a1": 2, "optimal": 1, "give": 1, "bellman": 1, "optimality": 1, "principle": 1, "mathematically": 1, "fai": 1, "r": 1, "0": 1, "1": 1}, {"": 1}, {"": 1}, {"": 3, "n": 1, "clearly": 1, "r": 1, "0": 1, "always": 1, "solution": 1}, {"however": 1, "solution": 1, "degenerate": 1, "sense": 1, "also": 1, "allow": 1, "every": 1, "policy": 1, "optimal": 1, "result": 1, "practical": 1, "use": 1}, {"constraint": 1, "r": 1, "6": 1, "0": 1, "consider": 1, "notice": 1, "point": 2, "fai": 2, "": 3, "rn": 1, "set": 2, "reward": 1, "function": 1, "generate": 1, "optimal": 1, "policy": 1, "1": 1, "hyperplanes": 1, "pass": 1, "origin": 1, "entire": 1, "collection": 1, "lie": 1, "one": 1, "half": 1, "space": 1}, {"problem": 2, "inverse": 1, "reinforcement": 1, "learn": 1, "equivalent": 1, "find": 1, "separate": 1, "hyperplane": 1, "pass": 1, "origin": 1, "point": 1, "fai": 1, "": 1}, {"also": 1, "assume": 1, "none": 1, "fai": 1, "": 5, "0": 1, "would": 1, "mean": 1, "distinction": 1, "policies": 1, "1": 1, "a1": 1}, {"geometric": 1, "perspective": 1, "irl": 2, "problem": 1, "allow": 1, "classification": 1, "finite": 2, "state": 1, "action": 1, "problems": 1, "3": 2, "regimes": 1, "graphically": 1, "visualize": 1, "figure": 2, "1": 3, "": 5, "fai": 4, "leave": 1, "example": 1, "graphical": 1, "visualization": 1, "regime": 1, "origin": 1, "lie": 1, "inside": 1, "convex": 1, "hull": 1}, {"hyperplane": 1, "pass": 1, "origin": 1, "exist": 1, "point": 1, "fai": 1, "": 1, "lie": 1, "one": 1, "half": 1, "space": 1}, {"center": 1, "example": 1, "graphical": 1, "visualization": 1, "regime": 1, "2": 1, "origin": 1, "lie": 1, "boundary": 1, "convex": 1, "hull": 1, "fai": 1, "": 1}, {"one": 2, "hyperplane": 1, "pass": 1, "origin": 1, "exist": 1, "point": 1, "fai": 1, "": 1, "lie": 1, "half": 1, "space": 1}, {"right": 1, "example": 1, "graphical": 1, "visualization": 1, "regime": 1, "3": 1, "origin": 1, "lie": 1, "outside": 1, "convex": 1, "hull": 1, "fai": 1, "": 1}, {"infinitely": 1, "many": 1, "hyperplanes": 1, "pass": 1, "origin": 1, "exist": 1, "point": 1, "fai": 1, "": 1, "lie": 1, "one": 1, "half": 1, "space": 1}, {"regime": 2, "1": 1, "hyperplane": 1, "pass": 1, "origin": 1, "point": 1, "fai": 1, "": 1, "lie": 1, "one": 1, "half": 1, "space": 1}, {"equivalent": 1, "say": 1, "origin": 1, "interior": 1, "convex": 1, "hull": 1, "point": 1, "fai": 1, "": 1}, {"case": 1, "independent": 1, "algorithm": 1, "nonzero": 1, "reward": 1, "function": 1, "policy": 1, "1": 1, "optimal": 1}, {"regime": 2, "2": 1, "scale": 1, "constant": 1, "one": 3, "hyperplanes": 2, "pass": 1, "origin": 1, "point": 2, "fai": 2, "": 2, "lie": 1, "half": 1, "space": 1, "however": 1, "always": 1, "contain": 1}, {"equivalent": 1, "say": 1, "origin": 1, "boundary": 1, "convex": 1, "hull": 1, "point": 1, "fai": 2, "": 1, "one": 1, "vertices": 1, "since": 1, "assumption": 1, "6": 1, "0": 1}, {"case": 1, "constant": 1, "scale": 1, "one": 1, "nonzero": 1, "reward": 1, "function": 1, "generate": 1, "optimal": 1, "policy": 1, "1": 1, "": 1}, {"case": 1, "also": 1, "important": 1, "notice": 1, "policy": 1, "1": 1, "cannot": 1, "strictly": 1, "optimal": 1, "reward": 1, "function": 1}, {"regime": 2, "3": 1, "scale": 1, "constant": 1, "infinitely": 1, "many": 1, "hyperplanes": 1, "pass": 1, "origin": 1, "point": 1, "fai": 1, "": 1, "lie": 1, "one": 1, "half": 1, "space": 1}, {"equivalent": 1, "say": 1, "origin": 1, "outside": 1, "convex": 1, "hull": 1, "point": 1, "fai": 1, "": 1}, {"case": 1, "constant": 1, "scale": 1, "infinitely": 1, "many": 1, "nonzero": 1, "reward": 2, "function": 2, "generate": 1, "optimal": 2, "policy": 2, "1": 2, "possible": 1, "find": 1, "strictly": 1}, {"geometric": 1, "regimes": 1, "implication": 1, "finite": 2, "state": 1, "action": 1, "inverse": 1, "reinforcement": 1, "learn": 1, "problem": 1, "sum": 1, "follow": 1, "theorem": 1}, {"theorem": 1, "31": 1}, {"exist": 1, "hyperplane": 3, "pass": 1, "origin": 1, "point": 1, "fai": 1, "": 5, "lie": 1, "one": 1, "side": 1, "nonzero": 1, "reward": 1, "function": 1, "r": 1, "6": 1, "0": 1, "generate": 1, "optimal": 1, "policy": 1, "a1": 1, "inverse": 1, "reinforcement": 1, "learn": 1, "problem": 1, "pa": 1}, {"ie": 1, "r": 2, "fai": 1, "": 1, "0": 1}, {"remark": 1, "31": 1}, {"notice": 1, "extension": 1, "theorem": 1, "31": 1, "r": 1, "policy": 1, "": 3, "a1": 1, "strictly": 2, "optimal": 1, "iff": 1, "exist": 1, "hyperplane": 1, "point": 1, "fai": 1, "one": 1, "side": 1}, {"remark": 1, "32": 1}, {"note": 1, "possible": 1, "find": 1, "separate": 1, "hyperplane": 1, "origin": 1, "collection": 1, "point": 1, "fai": 1, "": 1, "problem": 1, "regime": 1, "3": 1}, {"therefore": 1, "problem": 2, "inverse": 1, "reinforcement": 1, "learn": 1, "view": 1, "one": 1, "class": 3, "support": 2, "vector": 2, "machine": 2, "two": 1, "origin": 1, "negative": 1, "regime": 1}, {"along": 1, "objective": 1, "determine": 1, "sample": 1, "complexity": 1, "lead": 1, "formulation": 1, "problem": 1, "discuss": 1, "next": 1, "section": 1}, {"4": 2, "": 4, "formulation": 2, "optimization": 1, "problem": 2, "objective": 1, "function": 2, "inverse": 1, "reinforcement": 1, "describe": 1, "ng": 1, "russel": 1, "2000": 1, "form": 1, "impose": 1, "condition": 1, "value": 1, "optimal": 1, "policy": 1, "far": 1, "possible": 1, "next": 1, "best": 1, "action": 1, "state": 1, "well": 1, "sparseness": 1, "reward": 1}, {"choices": 1, "make": 1, "author": 1, "enable": 1, "unique": 1, "solution": 1, "propose": 1, "linear": 1, "program": 1, "problem": 1}, {"propose": 1, "different": 1, "formulation": 1, "term": 1, "1": 1, "class": 1, "l1regularized": 1, "support": 1, "vector": 1, "machine": 1, "allow": 1, "geometric": 1, "interpretation": 1, "well": 1, "provide": 1, "efficient": 1, "sample": 1, "complexity": 1}, {"inverse": 1, "reinforcement": 1, "learn": 1, "problem": 1, "consider": 1, "regime": 1, "3": 1}, {"know": 1, "separate": 1, "hyperplane": 1, "origin": 1, "fai": 3, "": 2, "strict": 1, "inequality": 1, "r0": 1, "scale": 1, "r": 2, "equivalent": 1, "1": 1}, {"formally": 1, "assumption": 1, "state": 1, "follow": 1, "definition": 1, "41": 1, "strict": 1, "separability": 1}, {"inverse": 1, "reinforcement": 1, "learn": 1, "problem": 1, "pa": 1, "": 14, "satisfy": 1, "strict": 1, "separability": 1, "exist": 1, "r": 2, "kr": 1, "k1": 1, "1": 2, "fai": 1, "0": 1, "a1": 1}, {"": 1}, {"": 1}, {"": 3, "n": 1, "notice": 1, "irl": 1, "problem": 1, "regime": 1, "3": 1, "ie": 1, "w": 1, "wt": 1, "fai": 1, "0": 1, "strict": 1, "separability": 1, "assumption": 1, "satisfy": 1}, {"strict": 1, "nonzero": 1, "assumptions": 1, "wellaccepted": 1, "statistical": 1, "learn": 1, "theory": 1, "community": 1, "use": 1, "instance": 1, "compress": 1, "sense": 1, "wainwright": 1, "2009": 1, "markov": 1, "random": 1, "field": 1, "ravikumar": 1, "et": 1, "al": 1}, {"2010": 1, "nonparametric": 1, "regression": 1, "liu": 1, "et": 1, "al": 1}, {"2008": 1, "diffusion": 1, "network": 1, "daneshmand": 1, "et": 1, "al": 1}, {"2014": 1}, {"fai": 3, "": 2, "figure": 1, "2": 2, "example": 1, "graphical": 1, "visualization": 1, "regime": 1, "origin": 1, "lie": 1, "boundary": 1, "convex": 1, "hull": 1}, {"perturbation": 1, "statistical": 1, "estimation": 1, "transition": 1, "probability": 1, "matrices": 1, "empirical": 1, "data": 1, "solid": 1, "red": 1, "make": 1, "problem": 1, "easily": 1, "tip": 1, "regime": 2, "1": 1, "show": 1, "3": 1}, {"infinite": 1, "number": 1, "sample": 1, "would": 1, "require": 1, "solve": 1, "irl": 1, "problems": 1, "fall": 1, "regime": 1, "2": 1}, {"problems": 1, "regime": 3, "2": 2, "avoid": 1, "since": 1, "base": 1, "statistical": 1, "estimation": 1, "transition": 1, "probability": 1, "matrices": 1, "empirical": 1, "data": 1, "problem": 1, "easily": 1, "tip": 1, "1": 1, "3": 1, "show": 1, "figure": 1}, {"solve": 2, "problems": 2, "regime": 2, "2": 1, "infinite": 1, "number": 2, "sample": 2, "would": 1, "require": 1, "3": 1, "large": 1, "enough": 1}, {"give": 1, "strict": 1, "separability": 1, "assumption": 1, "optimization": 1, "problem": 1, "propose": 1, "follow": 1, "minimize": 1, "r": 2, "": 7, "krk1": 1, "subject": 1, "fai": 1, "1": 2, "a1": 1}, {"": 1}, {"": 1}, {"": 3, "n": 1, "41": 1, "problem": 1, "form": 1, "one": 1, "class": 1, "l1regularized": 1, "support": 1, "vector": 1, "machine": 1, "zhu": 1, "et": 1, "al": 1}, {"2004": 1, "except": 1, "use": 1, "hard": 1, "margins": 2, "instead": 1, "soft": 1}, {"minimization": 1, "l1": 1, "norm": 1, "play": 1, "two": 1, "fold": 1, "role": 1, "formulation": 1}, {"first": 1, "promote": 1, "sparse": 1, "reward": 1, "function": 1, "keep": 1, "line": 1, "idea": 1, "simplicity": 1}, {"second": 1, "also": 1, "play": 1, "role": 1, "establish": 1, "sample": 1, "complexity": 1, "bound": 1, "inverse": 1, "reinforcement": 1, "learn": 1, "problem": 1, "well": 1, "show": 1, "subsequent": 1, "section": 1}, {"constraints": 1, "derive": 1, "strict": 1, "bellman": 1, "optimality": 1, "separable": 1, "case": 1, "regime": 1, "3": 1, "inverse": 1, "reinforcement": 1, "learn": 1, "help": 1, "avoid": 1, "degenerate": 1, "solution": 1, "r": 1, "": 1, "0": 1}, {"use": 1, "optimization": 1, "problem": 2, "along": 1, "objective": 1, "find": 1, "reward": 1, "function": 1, "policy": 1, "": 2, "a1": 1, "optimal": 1, "establish": 1, "correctness": 1, "sample": 1, "complexity": 1, "inverse": 1, "reinforcement": 1, "learn": 1}, {"5": 2, "": 3, "correctness": 1, "sample": 1, "complexity": 1, "inverse": 2, "reinforcement": 2, "learn": 2, "consider": 1, "problem": 1, "strictly": 1, "separable": 1, "case": 1, "regime": 1, "3": 1}, {"": 11, "r": 2, "fai": 1, "0": 1, "a1": 1, "1": 1}, {"": 1}, {"": 1}, {"": 5, "n": 1, "let": 1, "kfai": 1, "fai": 1, "k": 1}, {"let": 1, "r": 1, "solution": 1, "optimization": 1, "problem": 1, "41": 1, "fai": 1, "": 1}, {"desire": 1, "fai": 1, "r": 1, "": 6, "0": 1, "a1": 1, "1": 1}, {"": 1}, {"": 1}, {"": 3, "n": 1, "ie": 1, "reward": 1, "obtain": 1, "problem": 2, "use": 1, "estimate": 1, "transition": 2, "probability": 1, "matrices": 1, "also": 1, "generate": 1, "a1": 1, "optimal": 1, "true": 1, "probabilities": 1}, {"do": 1, "reduce": 1, "": 1, "ie": 1, "use": 1, "sample": 1}, {"result": 1, "strictly": 1, "separable": 1, "case": 1, "follow": 2, "theorem": 1}, {"theorem": 1, "51": 1}, {"let": 1, "pa": 1, "": 3, "inverse": 1, "reinforcement": 1, "learn": 1, "problem": 1, "strictly": 1, "separable": 1}, {"let": 1, "fai": 3, "value": 1, "use": 1, "estimate": 1, "transition": 1, "probability": 1, "matrices": 1, "kfai": 1, "": 3, "k": 1}, {"let": 1, "r": 1, "solution": 1, "optimization": 1, "problem": 1, "41": 1, "fai": 1, "": 1}, {"let": 1, "1": 2, "": 12, "c": 2, "0": 1, "1c": 1, "2c": 1, "fai": 1, "r": 1, "a1": 1}, {"": 1}, {"": 1}, {"": 2, "n": 1, "remark": 1, "51": 1}, {"important": 1, "note": 1, "since": 1, "k": 2, "": 12, "0": 3, "c": 2, "1": 2, "equality": 1, "hold": 1, "ie": 1, "infinitely": 1, "many": 1, "sample": 1}, {"show": 1, "equivalence": 1, "problems": 1, "true": 1, "estimate": 1, "transition": 1, "probabilities": 1, "case": 1, "infinite": 1, "sample": 1}, {"desire": 1, "result": 1, "follow": 1, "corollary": 1, "theorem": 1}, {"corollary": 1, "51": 1}, {"let": 1, "pa": 1, "": 3, "inverse": 1, "reinforcement": 1, "learn": 1, "problem": 1, "strictly": 1, "separable": 1}, {"let": 1, "fai": 3, "value": 1, "use": 1, "estimate": 1, "transition": 1, "probability": 1, "matrices": 1, "kfai": 1, "": 3, "k": 1}, {"let": 1, "r": 1, "solution": 1, "optimization": 1, "problem": 1, "41": 1, "fai": 1, "": 1}, {"": 10, "1": 2, "2": 1, "fai": 1, "r": 1, "0": 1, "a1": 1}, {"": 1}, {"": 1}, {"": 2, "n": 1, "proof": 1}, {"straightforwardly": 1, "set": 1, "c": 1, "": 1, "0": 1, "theorem": 1, "51": 1}, {"theorem": 1, "52": 1}, {"let": 1, "pa": 1, "": 3, "inverse": 1, "reinforcement": 1, "learn": 1, "problem": 1, "strictly": 1, "separable": 1}, {"let": 1, "transition": 1, "matrices": 1, "pa": 1, "": 2, "1": 1}, {"": 1}, {"": 1}, {"": 1, "n": 1, "nonzero": 1, "elements": 1, "per": 1, "row": 1}, {"let": 1, "every": 1, "state": 2, "reachable": 1, "start": 1, "one": 1, "step": 1, "probability": 1, "least": 1, "": 1}, {"let": 1, "r": 2, "solution": 1, "optimization": 1, "problem": 1, "41": 1, "fai": 2, "transition": 1, "probability": 2, "matrices": 1, "pa": 2, "maximum": 1, "likelihood": 1, "estimate": 1, "form": 1, "sample": 1, "": 14, "2": 3, "64": 1, "1": 5, "4nk": 1, "log": 1, "least": 1, "0": 1, "a1": 1}, {"": 1}, {"": 1}, {"": 2, "n": 1, "theorem": 1, "follow": 2, "concentration": 1, "inequalities": 1, "estimation": 1, "transition": 1, "probabilities": 1, "detail": 1, "section": 1}, {"miss": 1, "proof": 1, "include": 1, "supplementary": 1, "material": 1}, {"6": 1, "": 2, "concentration": 2, "inequalities": 1, "section": 1, "look": 1, "propagation": 1, "empirical": 1, "estimate": 1, "transition": 1, "probabilities": 1, "around": 1, "true": 1, "value": 1}, {"6": 1, "": 1, "lemma": 1, "61": 1}, {"let": 1, "b": 1, "two": 1, "matrices": 1, "kabk": 1, "": 1, "kbk": 1, "next": 1, "look": 1, "propagation": 1, "concentration": 2, "right": 1, "stochastic": 1, "matrix": 1, "p": 1, "kth": 1, "power": 1}, {"lemma": 1, "62": 1}, {"let": 1, "p": 1, "n": 2, "": 3, "right": 1, "stochastic": 1, "matrix": 1, "1": 1}, {"": 1}, {"": 1}, {"": 12, "n": 1, "nonzero": 1, "elements": 1, "per": 1, "row": 1, "let": 1, "p": 4, "estimate": 1, "kp": 2, "k": 5, "1d": 1, "1": 2, "consider": 1, "concentration": 1, "expression": 1, "fai": 1, "pa1": 2, "pa": 1, "ii": 1}, {"notice": 1, "since": 1, "p": 2, "right": 1, "stochastic": 1, "matrix": 1, "": 17, "1": 4, "expand": 1, "pa1": 7, "j": 2, "j0": 2, "therefore": 1, "pa": 2, "ii": 1, "x": 1, "theorem": 1, "61": 1}, {"let": 1, "pa": 1, "pa1": 1, "n": 2, "": 3, "right": 1, "stochastic": 1, "matrices": 1, "1": 1}, {"": 1}, {"": 1}, {"": 3, "n": 1, "nonzero": 1, "elements": 1, "per": 1, "row": 1, "correspond": 1, "action": 1, "a1": 1, "let": 1, "1": 1}, {"let": 1, "pa": 5, "pa1": 7, "estimate": 1, "kpa": 1, "": 21, "k": 2, "kpa1": 1, "a1": 1, "1": 5, "2": 2, "note": 1, "result": 1, "action": 1}, {"concentration": 1, "action": 2, "find": 1, "use": 1, "union": 1, "bind": 1, "set": 1}, {"estimate": 1, "value": 1, "": 7, "estimation": 1, "do": 1, "use": 2, "sample": 1, "show": 1, "dvoretzkykieferwolfowitz": 1, "inequality": 1, "dvoretzky": 1, "wolfowitz": 1, "1956": 1, "order": 1, "q": 1, "2": 1, "log": 1, "2n": 1}, {"result": 1, "show": 1, "follow": 1, "theorem": 1, "62": 1}, {"theorem": 1, "62": 1}, {"let": 2, "pa": 3, "n": 2, "": 2, "right": 1, "stochastic": 1, "matrix": 1, "action": 1, "maximum": 1, "likelihood": 1, "estimate": 1, "form": 1, "sample": 1}, {"": 7, "22": 1, "log": 1, "2n": 1, "h": 1, "p": 1, "pa": 2, "1": 1, "theorem": 1, "assume": 1, "possible": 1, "start": 1, "give": 1, "state": 1}, {"however": 1, "may": 1, "always": 1, "case": 1}, {"case": 1, "long": 1, "every": 1, "state": 2, "reachable": 1, "initial": 1, "probability": 1, "least": 1, "": 1, "result": 1, "present": 1, "theorem": 3, "52": 1, "modify": 1, "use": 1, "63": 1, "instead": 1, "62": 1}, {"theorem": 1, "63": 1}, {"let": 2, "pa": 3, "n": 2, "": 2, "right": 1, "stochastic": 1, "matrix": 1, "action": 1, "maximum": 1, "likelihood": 1, "estimate": 1, "form": 1, "sample": 1}, {"let": 1, "every": 1, "state": 2, "reachable": 1, "start": 1, "one": 1, "step": 1, "probability": 1, "least": 1, "": 1}, {"": 22, "4": 1, "2": 3, "log": 2, "4nk": 1, "h": 1, "p": 1, "pa": 2, "1": 2, "0": 1, "1a": 1, "7": 2, "discussion": 1, "result": 1, "theorem": 1, "52": 1, "show": 1, "number": 1, "sample": 1, "require": 1, "solve": 1, "strict": 1, "separable": 1, "inverse": 1, "reinforcement": 1, "learn": 1, "obtain": 1, "reward": 1, "generate": 1, "desire": 1, "optimal": 1, "policy": 1, "problem": 1, "order": 1, "nk": 1, "transition": 1, "probability": 1, "matrices": 1}, {"": 1}, {"": 1}, {"": 1, "n": 1, "nonzero": 1, "elements": 1, "per": 1, "row": 1}, {"notice": 1, "number": 1, "sample": 1, "inversely": 1, "proportional": 1, "": 2, "2": 1}, {"thus": 1, "view": 1, "case": 2, "regime": 2, "2": 1, "lim": 1, "": 2, "0": 1, "strict": 1, "separable": 1, "3": 1, "easy": 1, "see": 1, "infinite": 1, "number": 1, "sample": 1, "require": 1, "guarantee": 1, "reward": 1, "obtain": 1, "generate": 1, "optimal": 1, "policy": 1, "mdp": 1, "true": 1, "transition": 1, "probability": 1, "matrices": 1}, {"practical": 1, "applications": 1, "however": 1, "may": 1, "difficult": 1, "determine": 1, "inverse": 1, "reinforcement": 1, "learn": 1, "problem": 1, "strict": 1, "separable": 1, "regime": 1, "3": 1}, {"case": 1, "result": 1, "equation": 1, "a1": 1, "use": 1, "witness": 1, "determine": 1, "obtain": 1, "r": 1, "satisfy": 1, "bellmans": 1, "optimality": 1, "condition": 1, "respect": 1, "true": 1, "transition": 1, "probability": 2, "matrices": 1, "high": 1, "show": 1, "follow": 1, "remark": 1}, {"remark": 1, "71": 1}, {"let": 1, "pa": 1, "": 2, "inverse": 1, "reinforcement": 1, "learn": 1, "problem": 1}, {"let": 1, "transition": 1, "probability": 1, "matrices": 1, "pa": 1, "": 2, "1": 1}, {"": 1}, {"": 1}, {"": 1, "n": 1, "nonzero": 1, "elements": 1, "per": 1, "row": 1}, {"let": 1, "every": 1, "state": 2, "reachable": 1, "start": 1, "one": 1, "step": 1, "probability": 1, "least": 1, "": 1}, {"let": 2, "r": 3, "solution": 1, "optimization": 1, "problem": 1, "41": 1, "fai": 2, "transition": 1, "probability": 2, "matrices": 1, "pa": 2, "maximum": 1, "likelihood": 1, "estimate": 1, "form": 1, "sample": 1, "": 18, "2": 2, "4nk": 1, "1": 6, "4": 1, "log": 1, "krk1": 1, "least": 1, "0": 1, "a1": 1}, {"": 1}, {"": 1}, {"": 9, "n": 3, "8": 1, "experimental": 1, "result": 1, "figure": 1, "3": 1, "empirical": 1, "probability": 1, "success": 1, "versus": 1, "number": 1, "sample": 1, "inverse": 1, "reinforcement": 1, "learn": 1, "problem": 1, "perform": 1, "5": 2, "state": 2, "k": 2, "action": 2, "leave": 1, "7": 2, "right": 1, "use": 1, "l1regularized": 1, "support": 1, "vector": 1, "machine": 1, "formulation": 2, "linear": 1, "program": 1, "propose": 1, "ng": 1, "russel": 1, "2000": 1}, {"vertical": 1, "blue": 1, "line": 1, "represent": 1, "sample": 2, "complexity": 1, "method": 1, "state": 2, "theorem": 1, "52": 1, "8": 1, "": 4, "figure": 1, "4": 1, "empirical": 1, "probability": 1, "success": 1, "versus": 1, "number": 1, "inverse": 1, "reinforcement": 1, "learn": 2, "problem": 1, "perform": 1, "n": 1, "7": 2, "k": 1, "action": 1, "use": 1, "l1regularized": 1, "support": 1, "vector": 1, "machine": 1, "formulation": 2, "linear": 1, "program": 1, "propose": 1, "ng": 1, "russel": 1, "2000": 1, "multiplicative": 1, "weight": 1, "apprenticeship": 1, "syed": 1, "et": 1, "al": 1}, {"2008": 1, "": 2, "bayesian": 1, "irl": 2, "laplacian": 1, "prior": 1, "ramachandran": 1, "amir": 1, "2007": 1, "gaussian": 1, "process": 1, "levine": 1, "et": 1, "al": 1}, {"2011": 1}, {"vertical": 1, "blue": 1, "line": 1, "represent": 1, "sample": 1, "complexity": 1, "method": 1, "state": 3, "theorem": 1, "52": 1, "experiment": 1, "perform": 1, "use": 1, "randomly": 1, "generate": 1, "transition": 1, "probability": 1, "matrices": 1, "": 9, "n": 3, "nonzero": 1, "elements": 1, "per": 1, "row": 1, "strictly": 1, "separable": 1, "mdps": 1, "5": 2, "k": 2, "action": 2, "01": 2, "7": 2}, {"experiment": 1, "do": 1, "pa1": 1, "optimal": 1, "policy": 1}, {"thirty": 1, "randomly": 1, "generate": 1, "mdps": 1, "consider": 1, "case": 1, "vary": 1, "number": 1, "sample": 1, "use": 1, "find": 1, "estimate": 1, "transition": 1, "probability": 1, "matrices": 1, "trial": 1}, {"reward": 1, "function": 1, "r": 1, "find": 1, "solve": 2, "problem": 2, "41": 1, "l1regularized": 1, "svm": 1, "formulation": 1, "21": 1, "method": 1, "ng": 1, "": 2, "russel": 1, "2000": 1, "along": 1, "code": 1, "available": 1, "httpsgraphicsstanfordeduprojectsgpirl": 1, "multiplicative": 1, "weight": 1, "apprenticeship": 1, "learn": 1, "bayesian": 1, "irl": 2, "laplacian": 1, "prior": 1, "gaussian": 1, "process": 1, "use": 1, "set": 1, "estimate": 1, "transition": 1, "probabilities": 1, "ie": 1, "fai": 1}, {"result": 1, "reward": 1, "function": 1, "test": 1, "use": 1, "true": 1, "transition": 1, "probabilities": 1, "fai": 1, "r": 1, "": 1, "0": 1}, {"percentage": 1, "trials": 1, "fai": 1, "r": 1, "": 1, "0": 1, "hold": 1, "true": 1, "show": 1, "figure": 2, "3": 1, "4": 1, "different": 1, "number": 1, "sample": 1, "use": 1}, {"prescribe": 1, "theorem": 1, "52": 1, "": 6, "00032": 1, "sufficient": 1, "number": 1, "sample": 1, "success": 1, "2": 2, "n": 1, "method": 1, "log": 1, "nk": 1}, {"observe": 1, "success": 1, "rate": 1, "increase": 1, "number": 1, "sample": 1, "expect": 1}, {"l1regularized": 1, "support": 1, "vector": 1, "machine": 1, "however": 1, "significantly": 1, "outperform": 1, "linear": 1, "program": 1, "formulation": 1, "propose": 1, "ng": 1, "": 1, "russel": 1, "2000": 1, "multiplicative": 1, "weight": 1, "apprenticeship": 1, "learn": 1, "syed": 1, "et": 1, "al": 1}, {"2008": 1, "bayesian": 1, "irl": 2, "laplacian": 1, "prior": 1, "ramachandran": 1, "": 1, "amir": 1, "2007": 1, "gaussian": 1, "process": 1, "levine": 1, "et": 1, "al": 1}, {"2011": 1, "reach": 1, "100": 1, "success": 1, "shortly": 1, "sufficient": 1, "number": 1, "sample": 1, "methods": 1, "fall": 1, "far": 1, "behind": 1}, {"result": 1, "reward": 2, "function": 2, "give": 2, "l1regularized": 1, "support": 1, "vector": 1, "machine": 1, "": 4, "formulation": 1, "successfully": 1, "generate": 2, "n2": 1, "optimal": 2, "policy": 2, "a1": 1, "almost": 1, "100": 1, "trials": 1, "2": 1, "log": 1, "nk": 1, "sample": 1, "estimate": 1, "methods": 1, "fail": 1, "desire": 1}, {"9": 1, "": 2, "conclude": 1, "remark": 1, "l1regularized": 1, "support": 1, "vector": 1, "formulation": 1, "along": 1, "geometric": 1, "interpretation": 1, "provide": 1, "useful": 1, "way": 1, "look": 1, "inverse": 1, "reinforcement": 1, "learn": 1, "problem": 1, "strong": 1, "formal": 1, "guarantee": 1}, {"possible": 1, "future": 1, "work": 1, "problem": 2, "include": 1, "extension": 1, "inverse": 1, "reinforcement": 1, "learn": 1, "continuous": 1, "state": 1, "use": 1, "set": 1, "basis": 1, "function": 1, "present": 1, "ng": 1, "": 1, "russel": 1, "2000": 1}, {"reference": 1, "dvoretzky": 1, "j": 2, "k": 1, "wolfowitz": 1, "asymptotic": 1, "minimax": 1, "character": 1, "sample": 1, "distribution": 1, "function": 1, "classical": 1, "multinomial": 1, "estimator": 1}, {"annals": 1, "mathematical": 1, "statistics": 1, "pp": 1}, {"642669": 1, "1956": 1}, {"9": 1, "": 1, "abbeel": 1, "p": 1, "ng": 1, "apprenticeship": 1, "learn": 2, "via": 1, "inverse": 1, "reinforcement": 1}, {"icml": 1, "04": 1, "pp": 1}, {"1": 1, "new": 1, "york": 1, "ny": 1, "usa": 1, "2004": 1}, {"acm": 1}, {"doi": 1, "10114510153301015430": 1}, {"daneshmand": 1, "h": 1, "gomezrodriguez": 1, "song": 1, "l": 1, "scholkopf": 1, "b": 1, "estimate": 1, "diffusion": 1, "network": 1, "structure": 1, "recovery": 1, "condition": 1, "sample": 1, "complexity": 1, "": 1, "softthresholding": 1, "algorithm": 1}, {"international": 1, "conference": 1, "machine": 1, "learn": 1, "pp": 1}, {"793801": 1, "2014": 1}, {"dvijotham": 1, "k": 1, "todorov": 1, "e": 1, "inverse": 1, "optimal": 1, "control": 1, "linearlysolvable": 1, "mdps": 1}, {"icml": 1, "2010": 1, "pp": 1}, {"335342": 1, "2010": 1}, {"levine": 1, "popovic": 1, "z": 1, "koltun": 1, "v": 1, "nonlinear": 1, "inverse": 1, "reinforcement": 1, "learn": 1, "gaussian": 1, "process": 1}, {"neurips": 1, "2011": 1, "pp": 1}, {"1927": 1, "2011": 1}, {"liu": 1, "h": 1, "wasserman": 1, "l": 1, "lafferty": 1, "j": 1, "ravikumar": 1, "p": 1, "k": 1, "spam": 1, "sparse": 1, "additive": 1, "model": 1}, {"advance": 1, "neural": 1, "information": 1, "process": 1, "systems": 1, "pp": 1}, {"12011208": 1, "2008": 1}, {"neu": 1, "g": 1, "szepesvri": 1, "c": 1, "apprenticeship": 1, "learn": 2, "use": 1, "inverse": 1, "reinforcement": 1, "gradient": 1, "methods": 1}, {"uai": 1, "2007": 1, "pp": 1}, {"295302": 1}, {"auai": 1, "press": 1, "2007": 1}, {"ng": 1, "russel": 1, "algorithms": 1, "inverse": 1, "reinforcement": 1, "learn": 1}, {"icml": 1, "2000": 1, "pp": 1}, {"663": 1, "": 1, "670": 1, "2000": 1}, {"ramachandran": 1, "amir": 1, "e": 1, "bayesian": 1, "inverse": 1, "reinforcement": 1, "learn": 1}, {"ijcai": 1, "2007": 2, "5161801": 1, "14": 1}, {"ratliff": 1, "n": 1, "bagnell": 1, "j": 1}, {"zinkevich": 1}, {"maximum": 1, "margin": 1, "plan": 1}, {"icml": 1, "2006": 1, "pp": 1}, {"729736": 1}, {"acm": 1, "2006": 1}, {"ravikumar": 1, "p": 1, "wainwright": 1, "j": 2, "lafferty": 1, "et": 1, "al": 1}, {"highdimensional": 1, "ising": 1, "model": 1, "selection": 1, "use": 1, "l1regularized": 1, "logistic": 1, "regression": 1}, {"annals": 1, "statistics": 1, "38312871319": 1, "2010": 1}, {"syed": 1, "u": 1, "bowl": 1, "schapire": 1, "r": 1, "apprenticeship": 1, "learn": 1, "use": 1, "linear": 1, "program": 1}, {"icml": 1, "2008": 1, "pp": 1}, {"10321039": 1}, {"acm": 1, "2008": 1}, {"wainwright": 1, "j": 1}, {"sharp": 1, "thresholds": 1, "highdimensional": 1, "noisy": 1, "sparsity": 1, "recovery": 1, "use": 1, "l1constrained": 1, "quadratic": 1, "program": 1, "lasso": 1}, {"ieee": 1, "transactions": 1, "information": 1, "theory": 1, "555": 1, "21832202": 1, "2009": 1}, {"zhu": 1, "j": 2, "rosset": 1, "tibshirani": 1, "r": 1, "hastie": 1}, {"1norm": 1, "support": 1, "vector": 1, "machine": 1}, {"advance": 1, "neural": 1, "information": 1, "process": 1, "systems": 1, "pp": 1}, {"4956": 1, "2004": 1}, {"ziebart": 1, "b": 1, "maas": 1, "bagnell": 1, "j": 1}, {"dey": 1, "k": 1, "maximum": 1, "entropy": 1, "inverse": 1, "reinforcement": 1, "learn": 1}, {"aaai": 1, "2008": 1}, {"10": 1}]