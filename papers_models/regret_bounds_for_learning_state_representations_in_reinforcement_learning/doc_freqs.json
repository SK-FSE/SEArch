[{"regret": 1, "bound": 1, "learn": 4, "state": 3, "representations": 2, "reinforcement": 2, "": 7, "ronald": 1, "ortner": 1, "montanuniversitt": 1, "leoben": 1, "rortnerunileobenacat": 1, "alessandro": 1, "lazaric": 1, "facebook": 2, "ai": 2, "research": 2, "lazaricfbcom": 1, "matteo": 1, "pirotta": 1, "pirottafbcom": 1, "ronan": 1, "fruit": 1, "sequel": 2, "team": 2, "inria": 2, "lille": 2, "ronanfruitinriafr": 1, "odalricambrym": 1, "maillard": 1, "odalricmaillardinriafr": 1, "abstract": 1, "consider": 1, "problem": 1, "online": 1, "several": 1, "map": 1, "histories": 1, "discrete": 1, "space": 1, "available": 1, "agent": 1}, {"least": 1, "one": 1, "representations": 1, "assume": 1, "induce": 1, "markov": 1, "decision": 1, "process": 1, "mdp": 2, "performance": 1, "agent": 1, "measure": 1, "term": 1, "cumulative": 1, "regret": 2, "optimal": 1, "policy": 1, "give": 1, "highest": 1, "averagereward": 1, "e": 1, "": 1, "representation": 1}, {"propose": 1, "algorithm": 1, "u": 1, "cb": 1, "communicate": 1, "mdp": 1}, {"regret": 1, "bind": 2, "show": 1, "u": 1, "cb": 1, "automatically": 1, "adapt": 1, "markov": 1, "model": 1, "improve": 1, "currently": 1, "know": 1, "best": 1, "e": 1, "23": 1, "": 1}, {"order": 1, "ot": 1, "": 3, "1": 1, "introduction": 1, "reinforcement": 1, "learn": 2, "agent": 1, "aim": 1, "task": 1, "interact": 1, "unknown": 1, "environment": 1}, {"consider": 1, "online": 1, "learn": 1, "ie": 1, "nonepisodic": 1, "problems": 1, "agent": 1, "trade": 1, "exploration": 1, "need": 1, "collect": 1, "information": 2, "reward": 1, "dynamics": 1, "exploitation": 1, "gather": 1, "far": 1}, {"set": 1, "commonly": 1, "assume": 1, "agent": 1, "know": 1, "suitable": 1, "state": 2, "representation": 1, "make": 1, "process": 1, "space": 1, "markovian": 1}, {"however": 1, "design": 1, "representation": 1, "often": 1, "highly": 1, "nontrivial": 1, "since": 1, "many": 1, "reasonable": 1, "representations": 1, "may": 1, "lead": 1, "nonmarkovian": 1, "model": 1}, {"task": 1, "select": 1, "design": 1, "suitable": 1, "compact": 1, "state": 1, "representation": 1, "dynamical": 1, "system": 1, "wellknown": 1, "problem": 1, "engineer": 1, "especially": 1, "robotics": 1}, {"set": 1, "receive": 1, "lot": 1, "attention": 1, "recent": 1, "years": 1, "due": 1, "grow": 1, "number": 1, "applications": 1, "use": 1, "image": 1, "videos": 1, "observations": 1, "eg": 1, "1": 1, "2": 1, "3": 1}, {"possible": 1, "come": 1, "different": 1, "approach": 1, "extract": 1, "feature": 1, "highdimensional": 1, "observation": 1, "space": 1, "describe": 1, "problem": 1, "well": 1, "exhibit": 1, "markovian": 1, "dynamics": 1}, {"indeed": 1, "markovian": 1, "assumption": 1, "transition": 1, "reward": 1, "independent": 1, "history": 1, "frequently": 1, "violate": 1, "realworld": 1, "applications": 1, "often": 1, "rather": 1, "dependence": 1, "last": 1, "k": 1, "": 1, "1": 1, "observations": 1}, {"deal": 1, "scenario": 1, "markov": 1, "model": 3, "extend": 1, "firstorder": 1, "kthorder": 1}, {"problem": 1, "select": 1, "right": 1, "order": 1, "model": 1, "special": 1, "case": 1, "selection": 1, "correct": 1, "state": 1, "representation": 1}, {"case": 1, "goal": 1, "perform": 1, "well": 1, "true": 1, "order": 1, "compact": 1, "feature": 1, "markov": 1, "model": 1, "know": 1}, {"detail": 1, "examples": 1, "refer": 1, "4": 1, "5": 1, "6": 1}, {"consider": 1, "follow": 1, "set": 1, "introduce": 1, "hutter": 1, "7": 1, "call": 1, "feature": 1, "reinforcement": 1, "learn": 1}, {"agent": 1, "provide": 1, "finite": 2, "set": 2, "": 4, "representations": 1, "map": 1, "histories": 1, "sequence": 1, "action": 1, "observations": 1, "reward": 1, "state": 1, "least": 1, "one": 1, "model": 1, "induce": 1, "markov": 1, "decision": 1, "process": 1, "mdp": 1, "8": 1}, {"goal": 1, "agent": 1, "learn": 1, "solve": 1, "33rd": 1, "conference": 1, "neural": 1, "information": 1, "process": 1, "systems": 1, "neurips": 1, "2019": 1, "vancouver": 1, "canada": 1}, {"task": 1, "appropriate": 1, "representation": 1}, {"ability": 1, "test": 1, "quickly": 1, "discard": 1, "nonmarkovian": 1, "representations": 1, "compatible": 1, "observe": 1, "dynamics": 1, "fundamental": 1, "learn": 1, "efficiently": 1}, {"efficiency": 1, "measure": 1, "term": 1, "cumulative": 1, "regret": 1, "compare": 1, "reward": 2, "collect": 1, "learner": 1, "one": 1, "agent": 1, "know": 1, "markovian": 1, "representation": 1, "play": 1, "associate": 1, "optimal": 1, "policy": 2, "ie": 1, "give": 1, "highest": 1, "average": 1}, {"problem": 1, "initially": 1, "study": 1, "maillard": 1, "et": 1, "al": 1}, {"4": 1}, {"give": 1, "finite": 1, "set": 1, "representations": 1, "": 1, "step": 1, "regret": 1, "best": 1, "lower": 1, "bind": 1, "p": 1, "blb": 1, "algorithm": 1, "wrt": 1}, {"optimal": 1, "policy": 1, "associate": 1, "e": 1, "23": 1, "": 1}, {"blb": 1, "algorithm": 2, "base": 1, "random": 1, "markov": 1, "model": 3, "upper": 1, "bound": 1, "exploration": 1, "use": 1, "properties": 1, "ucrl2": 1, "9": 1, "efficient": 1, "explorationexploitation": 1, "communicate": 1, "mdps": 1, "control": 1, "amount": 1, "time": 1, "spend": 1, "nonmarkovian": 1}, {"blb": 1, "require": 1, "estimate": 1, "diameter": 2, "9": 1, "true": 2, "mdp": 1, "lead": 1, "additional": 1, "additive": 1, "term": 1, "regret": 1, "bind": 1, "may": 1, "exponential": 1}, {"blb": 1, "successively": 1, "extend": 1, "nguyen": 1, "et": 1, "al": 1}, {"6": 1, "case": 1, "countably": 1, "infinite": 1, "set": 1, "model": 1}, {"suggest": 1, "iblb": 1, "algorithm": 1, "remove": 1, "guess": 1, "diameter": 1, "thus": 1, "avoid": 1, "additional": 1, "exponential": 1, "term": 1, "regret": 2, "bind": 1, "isp": 1, "still": 1, "order": 1, "23": 1, "": 1}, {"optimistic": 1, "model": 1, "selection": 1, "oms": 1, "e": 1, "": 2, "claim": 1, "match": 1, "optimal": 1, "dependence": 1, "algorithm": 1, "5": 1, "regret": 1, "bind": 1, "term": 1}, {"however": 1, "algorithm": 2, "analysis": 1, "base": 1, "regald": 2, "10": 1, "recently": 1, "point": 1, "proof": 1, "regret": 1, "bind": 1, "contain": 1, "mistake": 1, "invalidate": 1, "also": 1, "result": 1, "oms": 1, "see": 1, "app": 1}, {"11": 1}, {"accordingly": 1, "still": 1, "open": 1, "": 1, "question": 1, "whether": 1, "possible": 1, "achieve": 1, "regret": 1, "bound": 1, "order": 1, "consider": 1, "set": 1}, {"paper": 1, "introduce": 1, "u": 1, "cb": 1, "optimistic": 1, "elimination": 1, "algorithm": 1, "perform": 1, "p": 1, "efficient": 1, "e": 1, "": 1}, {"exploration": 1, "representations": 1}, {"algorithm": 3, "prove": 1, "regret": 2, "bind": 1, "order": 1, "well": 1, "result": 1, "base": 1, "generalize": 1, "bound": 1, "achieve": 1, "ucrl2": 1, "9": 1}, {"particular": 1, "": 1, "consist": 1, "single": 1, "markov": 1, "model": 1, "obtain": 1, "regret": 1, "bind": 1, "ucrl2": 1}, {"u": 1, "cb": 1, "employ": 1, "optimism": 1, "choose": 1, "model": 1, "": 1}, {"avoid": 1, "suffer": 1, "large": 1, "regret": 2, "choose": 1, "nonmarkov": 1, "model": 2, "collect": 1, "reward": 1, "compare": 1, "bound": 1, "know": 1, "hold": 1, "markov": 1}, {"model": 1, "fail": 1, "give": 1, "sufficiently": 1, "high": 1, "reward": 1, "eliminate": 1}, {"hand": 1, "u": 1, "cb": 1, "happy": 1, "employ": 1, "nonmarkov": 1, "model": 2, "long": 1, "give": 1, "much": 1, "reward": 1, "would": 1, "expect": 1, "correspond": 1, "markov": 1}, {"u": 1, "cb": 1, "share": 1, "basic": 1, "ideas": 1, "blb": 1, "oms": 3, "simpler": 1, "however": 1, "recover": 1, "regret": 1, "bound": 1, "claim": 1}, {"blb": 1, "u": 1, "cb": 1, "guess": 2, "diameter": 1, "however": 1, "scheme": 1, "employ": 1, "come": 1, "little": 1, "cost": 1, "wrt": 1}, {"regret": 1, "particular": 1, "cause": 1, "additive": 1, "constants": 1, "bound": 1, "exponential": 1, "diameter": 1}, {"also": 1, "show": 1, "modify": 1, "guess": 2, "scheme": 1, "diameter": 1, "size": 1, "state": 1, "space": 1, "markov": 1, "model": 1, "": 1, "time": 1}, {"last": 1, "least": 1, "introduce": 1, "notion": 1, "effective": 1, "size": 1, "state": 1, "space": 1, "induce": 1, "model": 1, "set": 1, "": 2, "give": 1, "regret": 1, "bound": 1, "term": 1}, {"yield": 1, "improvements": 1, "depend": 1, "structure": 1, "": 1, "like": 1, "hierarchical": 1, "model": 1}, {"overview": 1}, {"start": 1, "detail": 1, "description": 1, "learn": 1, "set": 1, "follow": 1, "section": 1}, {"section": 1, "3": 1, "give": 1, "preliminaries": 1, "concern": 1, "ucrl2": 1, "algorithm": 1}, {"u": 1, "cb": 1, "algorithm": 1, "introduce": 1, "section": 1, "4": 1, "also": 1, "give": 1, "regret": 1, "analysis": 1, "case": 1, "diameter": 1, "underlie": 1, "markov": 1, "model": 1, "know": 1}, {"follow": 1, "section": 1, "5": 1, "show": 1, "guess": 1, "diameter": 1, "otherwise": 1}, {"section": 1, "6": 1, "give": 1, "improvements": 1, "also": 1, "introduce": 1, "notion": 1, "effective": 1, "state": 1, "space": 1}, {"2": 1, "": 2, "set": 2, "detail": 1, "consider": 1, "learn": 1, "follow": 1}, {"time": 1, "step": 1, "": 2, "1": 1, "2": 1}, {"": 1}, {"": 1, "learner": 1, "receive": 1, "initial": 1, "observation": 1, "ot": 1, "choose": 1, "action": 2, "finite": 1, "set": 1}, {"return": 1, "learner": 1, "receive": 1, "reward": 1, "rt": 1, "take": 1, "r": 1, "": 2, "0": 1, "1": 1, "next": 1, "observation": 1, "ot1": 1}, {"denote": 1, "set": 1, "observations": 1, "define": 1, "history": 1, "ht": 1, "step": 1, "sequence": 1, "o1": 1, "": 5, "a1": 1, "r1": 1, "o2": 1}, {"": 1}, {"": 1}, {"": 3, "rt": 1, "ot1": 1, "observations": 1, "action": 1, "reward": 1}, {"set": 3, "ht": 2, "": 5, "r": 1, "ot1": 1, "contain": 1, "possible": 2, "histories": 2, "step": 1, "h": 1, "t1": 1}, {"21": 1, "": 7, "model": 3, "mdps": 1, "staterepresentation": 1, "follow": 1, "short": 1, "function": 1, "map": 1, "histories": 1, "state": 1, "h": 1}, {"model": 2, "": 2, "induce": 1, "markov": 2, "decision": 1, "process": 1, "mdp": 1, "call": 1, "2": 1}, {"mdp": 1, "markov": 1, "property": 1, "time": 1, "probability": 1, "reward": 1, "rt": 3, "next": 1, "state": 2, "st1": 3, "": 13, "ht1": 1, "give": 1, "past": 1, "history": 1, "ht": 3, "depend": 1, "current": 1, "st": 2, "choose": 1, "action": 1, "ie": 1, "p": 2}, {"assume": 1, "mdps": 2, "probability": 3, "also": 1, "independent": 1, "usually": 1, "mdp": 1, "state": 4, "space": 2, "action": 3, "denote": 1, "tuple": 1, "": 4, "r": 1, "p": 1, "rs": 1, "mean": 1, "reward": 1, "ps0": 1, "transition": 1, "s0": 3, "choose": 2, "call": 1, "communicate": 1, "two": 1, "possible": 1, "reach": 1, "positive": 1, "appropriate": 1}, {"smallest": 1, "expect": 1, "time": 1, "take": 1, "connect": 1, "two": 1, "state": 1, "call": 1, "diameter": 1, "mdp": 1, "cf": 1}, {"9": 1}, {"communicate": 1, "mdps": 1, "optimal": 1, "average": 1, "reward": 1, "": 4, "independent": 1, "initial": 1, "state": 2, "achieve": 1, "stationary": 1, "deterministic": 1, "policy": 1, "sd": 1, "map": 1, "action": 1}, {"markov": 1, "model": 1, "": 2, "write": 1, "induce": 1, "mdp": 1}, {"diameter": 1, "optimal": 1, "average": 1, "reward": 1, "denote": 1, "": 2, "respectively": 1}, {"model": 1, "": 3, "abbreviate": 1}, {"22": 1, "": 2, "problem": 1, "set": 2, "learn": 1, "consider": 1, "follow": 1}, {"already": 1, "describe": 1, "learner": 1, "choose": 1, "action": 1, "obtain": 1, "reward": 1, "rt": 1, "observation": 1, "ot1": 1, "return": 1}, {"assume": 1, "learner": 1, "finite": 1, "set": 1, "": 3, "model": 3, "disposal": 1, "least": 1, "one": 1, "markov": 1}, {"goal": 1, "provide": 1, "algorithms": 1, "perform": 1, "well": 1, "respect": 1, "optimal": 2, "policy": 1, "": 4, "mdp": 2, "strategy": 1, "markov": 1, "model": 1, "induce": 1, "underlie": 1, "completely": 1, "know": 1}, {"accordingly": 1, "performance": 1, "learn": 1, "algorithm": 1, "measure": 1, "consider": 1, "regret": 1, "step": 1, "define": 1, "cf": 1}, {"9": 2, "10": 1, "4": 1, "": 11, "x": 1, "rt": 2, "t1": 1, "reward": 1, "receive": 1, "learn": 1, "algorithm": 3, "step": 1, "3": 1, "ucrl2": 2, "preliminaries": 1, "propose": 1, "base": 1}, {"accordingly": 1, "start": 1, "respective": 1, "preliminaries": 1}, {"ucrl2": 1, "algorithm": 1, "generalize": 1, "optimism": 1, "face": 1, "uncertainty": 1, "idea": 1, "ucb": 1, "12": 1, "bandit": 1, "set": 1, "reinforcement": 1, "learn": 1, "mdps": 1}, {"follow": 1, "assume": 1, "underlie": 1, "mdp": 2, "state": 1, "action": 1, "diameter": 1, "ucrl2": 2, "algorithm": 1, "use": 1, "confidence": 1, "intervals": 1, "define": 1, "set": 1, "plausible": 1, "mdps": 1, "act": 1, "unknown": 1, "": 1, "maintain": 1, "estimate": 1, "rs": 1, "ps": 1, "reward": 1, "transition": 1, "probabilities": 1, "respectively": 1}, {"set": 2, "mt": 1, "plausible": 1, "mdps": 2, "step": 1, "contain": 1, "reward": 1, "res": 2, "transition": 1, "probabilities": 1, "pes": 2, "satisfying1": 1, "r": 2, "rs": 1, "": 17, "ps": 1, "1": 3, "7": 1, "log4sat3": 1, "2n": 2, "sa": 2, "14s": 1, "log4at3": 1, "2": 1, "n": 1, "denote": 1, "number": 1, "time": 1, "choose": 2, "far": 1}, {"true": 1, "mdp": 1, "high": 1, "probability": 1}, {"lemma": 2, "1": 1, "17": 1, "appendix": 1, "92": 1, "": 1}, {"probability": 1, "least": 1, "1": 1, "": 2, "mdp": 1, "contain": 1, "set": 1, "mt": 1}, {"": 6, "30t8": 1, "step": 1, "true": 1, "ucrl2": 1, "algorithm": 1, "proceed": 1, "episodes": 1, "k": 1, "1": 1, "2": 1}, {"": 1}, {"": 1}, {"episode": 1, "k": 1, "start": 1, "step": 1, "tk": 1, "algorithm": 1, "play": 1, "fix": 1, "policy": 1, "": 4, "ek": 1, "choose": 1, "maximize": 1, "optimal": 1, "average": 1, "reward": 1, "mdp": 1, "mk": 1, "mtk": 1}, {"write": 1, "": 3, "average": 1, "reward": 1, "policy": 1, "mdp": 1, "1": 1, "confidence": 2, "intervals": 2, "show": 1, "ones": 1, "use": 1, "follow": 1, "slightly": 1, "differ": 1, "give": 1, "ucrl2": 1, "9": 1}, {"confidence": 1, "": 1, "original": 1, "value": 1, "replace": 1, "2t2": 1, "guarantee": 1, "smaller": 1, "error": 1, "probability": 1, "need": 1, "analysis": 1}, {"2": 1, "note": 1, "error": 1, "probability": 1, "": 2, "change": 1, "2t2": 1}, {"3": 1, "": 8, "fk": 2, "optimistic": 1, "mdp": 1, "choose": 1, "mk": 2, "set": 1, "ek": 2, "maxm": 1, "e": 1, "k": 1, "maximize": 1}, {"true": 1, "mdp": 1, "mk": 1, "high": 1, "probability": 1, "also": 1, "ek": 1, "": 3}, {"let": 1, "vk": 1, "denote": 2, "number": 2, "time": 2, "choose": 2, "episode": 2, "k": 3, "nk": 1, "ie": 1, "episodes": 1, "1": 2, "": 1}, {"visit": 1, "episode": 1, "k": 1, "nk": 1, "set": 1, "1": 1}, {"episode": 1, "k": 1, "terminate": 1, "ucrl2": 1, "state": 1, "reach": 1, "vk": 1, "": 3, "ek": 2, "nk": 1}, {"one": 1, "show": 1, "follow": 1, "upper": 1, "bind": 1, "regret": 1, "ucrl2": 1}, {"theorem": 2, "2": 2, "9": 1}, {"probability": 1, "1": 1, "": 3, "regret": 1, "ucrl2": 1, "step": 1, "bound": 1, "q": 1, "3": 1, "34ds": 1, "log": 1, "2t": 1}, {"bind": 1, "base": 1, "episodewise": 1, "decomposition": 1, "regret": 1, "use": 1, "algorithm": 1}, {"let": 1, "tk": 2, "current": 2, "length": 1, "episode": 3, "k": 1, "follow": 1, "abuse": 1, "notation": 2, "well": 2, "vk": 1, "use": 1, "number": 2, "step": 2, "terminate": 1, "ongoing": 1}, {"recall": 1, "tk": 1, "denote": 1, "time": 1, "step": 1, "episode": 1, "k": 1, "start": 1}, {"regret": 1, "ucrl2": 1, "episode": 1, "k": 1, "bound": 1, "follow": 1}, {"lemma": 1, "3": 1}, {"consider": 1, "arbitrary": 1, "episode": 1, "k": 1, "start": 1, "step": 1, "tk": 1, "": 1}, {"probability": 1, "1": 1, "": 12, "2t2": 1, "regret": 1, "k": 1, "ucrl2": 1, "step": 1, "tk": 3, "episode": 1, "bound": 1, "q": 2, "x": 1, "4at3k": 1, "16t2k": 1, "vk": 1, "sa": 3, "4d": 1, "log": 2, "2d": 1, "14s": 1, "2": 1, "nk": 1, "proof": 1}, {"bind": 1, "lemma": 1, "3": 1, "explicitly": 1, "state": 1, "single": 1, "episodes": 1, "9": 2, "easily": 1, "follow": 1, "equations": 1, "8": 1, "1517": 1, "argument": 1, "give": 1, "equation": 1, "18": 1, "choose": 1, "confidence": 1, "t2": 1, "instead": 1, "": 1}, {"sake": 1, "completeness": 1, "give": 1, "brief": 1, "proof": 1, "sketch": 1}, {"first": 1, "replace": 1, "random": 1, "reward": 2, "mean": 1, "rs": 1, "regret": 1, "k": 2, "episode": 1, "bound": 1, "cf": 1}, {"eq": 1}, {"8": 1, "9": 1, "q": 1, "x": 1, "16t2k": 1, "tk": 2, "": 4, "vk": 1, "rs": 1, "58": 1, "log": 1}, {"3": 1, "k": 1, "": 4, "sa": 1, "fk": 1}, {"let": 1, "r": 1, "p": 2, "denote": 1, "reward": 1, "transition": 1, "probabilities": 1, "optimistic": 1, "mdp": 1, "difference": 1, "sum": 1, "3": 1, "bound": 1, "split": 1, "": 10, "rs": 5, "ek": 1, "e": 1, "k": 1, "4": 1, "last": 1, "term": 1, "control": 1, "confidence": 1, "intervals": 1, "1": 1, "cf": 1}, {"eq": 1}, {"15": 1, "9": 1}, {"term": 1, "write": 1, "ek": 1, "": 4, "rs": 1, "s0": 1, "ps0": 1, "aws0": 1, "ws": 1, "shift": 1, "value": 1, "vector": 1, "w": 1, "cf": 1}, {"p": 1, "1576": 1, "9": 1, "split": 1, "one": 1, "cf": 1}, {"eq": 1}, {"16": 1, "9": 1, "x": 2, "": 4, "ps0": 1, "ws": 1}, {"5": 1, "ek": 1, "": 8, "rs": 1, "ps0": 2, "ws0": 1, "s0": 2, "first": 1, "term": 1, "handle": 1, "confidence": 1, "intervals": 1, "2": 1, "fact": 1, "ws": 1, "cf": 1}, {"eq": 1}, {"17": 1, "q": 1, "9": 1, "second": 1, "term": 1, "write": 1, "martingale": 1, "difference": 1, "sequence": 1, "bound": 1, "16t2k": 1, "tk": 2, "": 2, "52": 1, "log": 1, "use": 1, "azumahoeffding": 1, "cf": 1}, {"eq": 1}, {"18": 1, "9": 1}, {"finally": 1, "take": 1, "account": 1, "": 2, "additional": 1, "regret": 1, "term": 1, "tk": 1, "cause": 1, "fail": 1, "confidence": 1, "intervals": 1, "cf": 1}, {"eq": 1}, {"9": 2, "combine": 1, "35": 1, "give": 1, "claim": 1, "bind": 1, "first": 1, "term": 1, "stem": 1, "confidence": 1, "intervals": 1, "1": 1, "2": 1}, {"4": 1, "": 2, "u": 1, "cb": 1, "algorithm": 1, "let": 1, "us": 1, "turn": 1, "state": 1, "representation": 1, "learn": 1, "set": 1, "introduce": 1, "section": 1, "2": 1}, {"start": 1, "simpler": 1, "case": 1, "upper": 1, "bind": 1, "diameter": 1, "": 4, "markov": 1, "model": 1, "know": 1, "ie": 1}, {"case": 1, "bind": 1, "diameter": 1, "know": 1, "deal": 1, "section": 1, "5": 1}, {"4": 1, "": 5, "algorithm": 1, "1": 3, "ucbmodel": 1, "selection": 1, "u": 1, "cb": 1, "input": 1, "set": 1, "model": 1, "confidence": 1, "parameter": 1, "0": 1, "upper": 1, "bind": 1, "diameter": 1, "initialization": 1, "let": 1, "current": 1, "time": 1, "step": 1}, {"episodes": 1, "k": 1, "": 2, "1": 1, "2": 1}, {"": 1}, {"": 1}, {"let": 2, "tk": 1, "": 1, "initial": 1, "step": 1, "current": 1, "episode": 1, "k": 1, "mt": 1, "set": 1, "plausible": 1, "mdps": 1, "define": 1, "via": 1, "confidence": 1, "intervals": 1, "1": 1, "2": 1, "estimate": 1, "far": 1}, {"fk": 1, "b": 1, "": 5, "use": 1, "extend": 1, "value": 1, "iteration": 1, "evi": 1, "compute": 1, "optimistic": 1, "mdp": 1, "f": 1, "mt": 1, "nearoptimal": 1, "policy": 1, "ek": 2, "mk": 1, "approximate": 1, "average": 1, "reward": 1}, {"b": 1, "choose": 1, "model": 1, "k": 2, "": 17, "argmax": 1, "ek": 3, "8": 1, "set": 1, "ekk": 2, "sk": 2}, {"b": 1, "repeat": 1, "till": 1, "termination": 1, "current": 1, "episode": 1, "k": 2, "": 5, "choose": 1, "action": 1, "st": 1, "get": 1, "reward": 1, "rt": 1, "observe": 1, "next": 1, "state": 1, "st1": 1, "sk": 1}, {"": 3, "set": 1, "1": 1}, {"": 6, "vk": 1, "st": 2, "ntk": 1, "terminate": 1, "current": 1, "episode": 1}, {"": 14, "x": 1, "r": 1, "tk": 2, "1e": 1, "k": 2, "9": 1, "set": 1, "terminate": 1, "current": 1, "episode": 1}, {"end": 1, "u": 1, "cb": 1, "algorithm": 1, "propose": 1, "show": 1, "alg": 1}, {"1": 1, "basically": 1, "perform": 1, "policy": 1, "computation": 1, "ucrl2": 1, "model": 1, "": 1}, {"episodes": 1, "k": 1, "": 2, "1": 1, "2": 1}, {"": 1}, {"": 8, "u": 1, "cb": 1, "construct": 1, "state": 1, "representation": 1, "set": 1, "plausible": 1, "mdps": 1, "mk": 1, "compute": 1, "optimistic": 1, "average": 1, "reward": 1, "ek": 1}, {"argmax": 1, "": 4, "6": 1, "sd": 1, "mk": 1, "problem": 1, "solve": 1, "use": 1, "extend": 1, "value": 1, "iteration": 1, "evi": 1, "9": 1, "arbitrary": 1, "accuracy3": 1, "among": 1, "model": 1, "u": 1, "cb": 1, "select": 1, "one": 1, "highest": 1, "average": 1, "reward": 1, "ek": 1, "cf": 1}, {"eq": 1}, {"8": 1}, {"associate": 1, "optimistic": 1, "policy": 2, "": 1, "ek": 1, "execute": 1, "number": 1, "visit": 1, "double": 1, "least": 1, "one": 1, "stateaction": 1, "pair": 1, "ucrl2": 1, "stop": 1, "condition": 1, "provide": 1, "sufficiently": 1, "high": 1, "average": 1, "reward": 1, "see": 1, "eq": 1}, {"9": 1, "case": 1, "model": 1, "k": 1, "eliminate": 1}, {"function": 1, "eq": 1}, {"9": 1, "define": 1, "allow": 1, "deviation": 1, "promise": 1, "optimistic": 1, "average": 1, "reward": 1, "ek": 1, "": 1}, {"define": 1, "accord": 1, "lemma": 1, "3": 1, "": 1}, {"r": 2, "": 13, "4at3": 1, "16t2": 1, "x": 1, "v": 1, "sa": 3, "kt": 6, "2d": 1, "14st": 1, "log": 2, "2": 1, "4d": 1, "nkt": 1, "7": 1, "denote": 1, "episode": 1, "step": 1, "occur": 1}, {"eq": 1}, {"9": 1, "exploit": 1, "prior": 1, "knowledge": 1, "": 1, "order": 1, "properly": 1, "define": 1, "condition": 1, "model": 1, "elimination": 1}, {"see": 1, "section": 1, "5": 1, "easy": 1, "adapt": 1, "algorithm": 1, "case": 1, "unknown": 1, "diameter": 1}, {"set": 1, "": 1, "consist": 1, "single": 2, "markov": 1, "model": 2, "u": 1, "cb": 1, "basically": 1, "coincide": 1, "ucrl": 1, "additional": 1, "check": 1, "step": 1, "result": 1, "discard": 1, "small": 1, "probability": 1}, {"note": 1, "u": 1, "cb": 1, "share": 1, "optimistic": 1, "model": 2, "selection": 1, "idea": 1, "eliminate": 1, "underachieve": 1, "oms": 1, "however": 1, "structure": 1, "much": 1, "simpler": 1}, {"concern": 1, "computational": 2, "complexity": 2, "algorithm": 1, "note": 1, "evi": 1, "subroutine": 1, "use": 1, "policy": 1, "computation": 1, "work": 1, "ordinary": 1, "value": 1, "iteration": 2, "convergence": 1, "properties": 1, "additional": 1, "overhead": 1, "os": 1, "2": 1, "per": 1, "step": 1, "cf": 1}, {"9": 1}, {"policy": 1, "computation": 1, "perform": 1, "model": 1, "": 3, "log": 1, "time": 1, "cf": 1}, {"lemma": 1, "5": 1, "c": 1}, {"3": 1, "": 3, "ucrl2": 1, "set": 1, "accuracy": 1, "episode": 1, "k": 1, "1": 1, "tk": 1}, {"5": 1, "": 4, "first": 1, "result": 1, "follow": 1, "regret": 1, "bind": 1, "pu": 1, "cb": 1, "smax": 1, "max": 1, "denote": 1, "size": 2, "state": 2, "space": 2, "largest": 1, "model": 2, "total": 1}, {"theorem": 1, "4": 1}, {"probability": 1, "1": 1, "": 6, "regret": 1, "u": 1, "cb": 1, "use": 1, "bound": 1, "p": 1, "const": 1, "smax": 1, "log": 1}, {"note": 1, "bind": 1, "theorem": 1, "4": 1, "hold": 1, "markov": 1, "model": 1, "": 1}, {"thus": 1, "case": 1, "markov": 1, "model": 2, "smaller": 1, "state": 1, "space": 1, "regret": 1, "bind": 1, "show": 1, "u": 1, "cb": 1, "automatically": 1, "adapt": 1, "preferable": 1}, {"": 1, "consist": 1, "single": 1, "markov": 1, "model": 1, "reestablish": 1, "bound": 1, "ucrl2": 2, "however": 1, "algorithm": 1, "unlike": 1, "need": 1, "diameter": 1, "input": 1}, {"importantly": 1, "bind": 2, "theorem": 1, "4": 1, "improve": 1, "currently": 1, "best": 1, "know": 1, "blb": 1, "e": 1, "23": 1, "order": 1, "p": 1, "ot": 1, "": 1}, {"model": 1, "induce": 1, "state": 1, "space": 1, "equal": 1, "size": 1, "bind": 2, "theorem": 1, "4": 1, "e": 2, "ods": 2, "": 2, "also": 1, "improve": 1, "claim": 1, "regret": 1, "oms": 1, "order": 1, "p": 1, "32": 1}, {"note": 1, "however": 1, "case": 1, "state": 1, "space": 1, "dependence": 1, "oms": 1, "bind": 1, "may": 1, "better": 1}, {"section": 1, "6": 1, "show": 1, "regain": 1, "oms": 1, "bind": 1, "algorithm": 1, "bound": 1, "replace": 1, "effective": 1, "size": 1, "state": 1, "space": 1, "case": 1, "like": 1, "hierarchical": 1, "model": 1, "considerably": 1, "smaller": 1}, {"": 2, "adependence": 1, "optimal": 2, "ucrl2": 1, "use": 1, "refine": 1, "analysis": 1, "see": 1, "13": 1, "also": 1, "possible": 1, "obtain": 1, "ddependence": 1}, {"hand": 1, "optimality": 1, "": 1, "still": 1, "open": 1, "question": 1}, {"sdependence": 1, "reduce": 1, "use": 1, "bernstein": 1, "inequality": 1, "aware": 1, "lower": 1, "bind": 1, "": 1, "set": 1}, {"closest": 1, "result": 1, "know": 1, "aggregation": 1, "techniques": 1, "full": 1, "information": 1, "possible": 1, "obtain": 1, "bound": 1, "order": 1, "log": 1}, {"obviously": 1, "set": 1, "less": 1, "information": 1, "clear": 1, "possible": 1, "obtain": 1, "logarithmic": 1, "dependence": 1}, {"note": 1, "regret": 1, "measure": 1, "wrt": 1}, {"true": 1, "markov": 1, "model": 1, "": 3, "actually": 1, "necessary": 1, "identify": 1, "obtain": 1, "regret": 1, "bind": 1, "theorem": 1, "4": 1}, {"long": 1, "nonmarkov": 1, "model": 2, "give": 1, "least": 1, "reward": 1, "would": 1, "expect": 1, "markov": 1, "need": 1, "discard": 1}, {"model": 1, "could": 1, "example": 1, "good": 1, "nonmarkovian": 1, "approximation": 1}, {"41": 1, "": 2, "analysis": 1, "proof": 1, "theorem": 1, "4": 1, "follow": 1, "lemma": 2, "collect": 1, "basic": 1, "facts": 1, "u": 1, "cb": 1, "5": 1}, {"probability": 1, "1": 3, "": 5, "follow": 1, "statements": 1, "hold": 2, "confidence": 1, "intervals": 1, "2": 1, "markov": 1, "model": 1, "time": 1, "step": 1}, {"": 1}, {"": 1}, {"": 2}, {"b": 1, "markov": 1, "model": 1, "discard": 1, "9": 1}, {"c": 1, "number": 1, "episodes": 1, "u": 1, "cb": 1, "bound": 1, "": 3, "log": 1}, {"proof": 1}, {"follow": 1, "lemma": 1, "1": 1, "sum": 1, "error": 2, "probabilities": 1, "give": 1, "total": 1, "p": 1, "": 3, "probability": 1, "30t": 1, "8": 1, "6": 1}, {"b": 1, "u": 1, "cb": 1, "choose": 1, "markov": 1, "model": 1, "regret": 1, "respective": 1, "episode": 1, "bound": 1, "accord": 1, "lemma": 1, "3": 1}, {"sum": 1, "respective": 1, "error": 1, "probabilities": 1, "2t2k": 1, "episodes": 1, "bound": 1, "5": 1, "6": 1, "": 1, "prove": 1, "b": 1}, {"b": 1, "hold": 1, "": 2, "1": 1, "episodes": 1, "model": 1, "discard": 1}, {"episodes": 1, "terminate": 1, "double": 1, "number": 1, "visit": 1, "use": 1, "proposition": 1, "18": 1, "9": 1, "episode": 1, "termination": 1, "criterion": 1, "u": 1, "cb": 1, "ucrl2": 1}, {"since": 1, "take": 1, "account": 1, "state": 3, "model": 2, "size": 2, "space": 2, "consider": 1, "sum": 1, "individual": 1}, {"bind": 1, "number": 1, "episodes": 1, "worst": 1, "case": 1, "depend": 1, "": 1}, {"assumptions": 1, "give": 1, "model": 2, "": 1, "like": 1, "hierarchical": 1, "reduce": 1, "see": 1, "section": 1, "6": 1, "detail": 1}, {"proof": 1, "theorem": 1, "4": 1}, {"assume": 1, "statements": 1, "lemma": 1, "5": 1, "hold": 1, "case": 1, "probability": 1, "1": 1, "": 2}, {"let": 1, "": 7, "markov": 1, "model": 1, "consider": 1, "episode": 1, "k": 1, "lemma": 1, "5": 1, "6": 1, "optimistic": 1, "estimate": 1, "ek": 1}, {"optimism": 1, "algorithm": 1, "ek": 2, "": 2}, {"hence": 1, "regret": 1, "k": 3, "episode": 1, "bound": 1, "": 15, "tk": 5, "tkx": 2, "r": 2, "ek": 1}, {"": 4, "tk": 1, "definition": 1, "algorithm": 1, "condition": 1, "9": 1, "hold": 1, "least": 1, "final": 1, "step": 1, "episode": 1, "obtain": 1, "reward": 1, "upper": 1, "bound": 1, "1": 2, "k": 1, "tkd": 1}, {"use": 1, "definition": 1, "7": 1, "sum": 1, "k": 6, "episodes": 1, "obtain": 1, "regret": 1, "bind": 1, "x": 4, "": 22, "tkd": 1, "1": 1, "q": 2, "2d": 1, "14smax": 1, "log": 2, "4at": 1, "3": 2, "2": 1, "sa": 3, "vk": 1, "4d": 1, "nk": 1, "16t": 1, "xp": 1, "tk": 1}, {"k": 3, "": 6, "p": 2, "use": 1, "tk": 2, "together": 1, "jensens": 1, "inequality": 1, "kt": 1}, {"analysis": 1, "ucrl2": 1, "cf": 1}, {"eq": 1}, {"20": 1, "9": 1, "x": 2, "v": 1, "sa": 1, "": 3, "p": 1, "k": 1, "2": 1, "1": 1}, {"": 14, "k": 1, "sa": 2, "nk": 1, "summarize": 1, "obtain": 1, "use": 1, "bound": 1, "number": 1, "episodes": 1, "lemma": 1, "5": 1, "c": 1, "note": 1, "simplifications": 1, "regret": 1, "bind": 1, "q": 2, "const1": 1, "smax": 1, "log": 4, "const2": 1, "const3": 1, "ds": 1, "complete": 1, "proof": 1, "theorem": 1}, {"5": 1, "": 2, "unknown": 2, "diameter": 2, "suggest": 1, "follow": 1, "guess": 1, "scheme": 1}, {"run": 1, "u": 1, "cb": 1, "initial": 1, "value": 1, "": 1, "1": 1}, {"step": 1, "model": 2, "eliminate": 1, "double": 1, "value": 1, "restart": 1, "algorithm": 1, "start": 1, "new": 1, "episode": 1, "consider": 1}, {"one": 1, "show": 1, "regret": 1, "double": 1, "scheme": 1, "basically": 1, "bound": 1, "unless": 1, "large": 1, "compare": 1, "": 1}, {"theorem": 1, "6": 1}, {"probability": 1, "1": 1, "": 8, "regret": 1, "u": 1, "cb": 1, "guess": 1, "double": 1, "bound": 1, "q": 1, "const": 1, "smax": 1, "log": 2}, {"proof": 1}, {"let": 1, "dk": 2, "denote": 1, "parameter": 1, "use": 1, "episode": 1, "k": 1, "estimate": 1, "proof": 1, "theorem": 1, "4": 1, "markov": 1, "model": 2, "eliminate": 1, "high": 1, "probability": 1, "": 1, "hence": 1, "total": 1, "cannot": 1, "log2": 1, "de": 1, "episodes": 1, "terminate": 1, "discard": 1}, {"let": 1, "define": 1, "7": 1}, {"argument": 1, "proof": 1, "theorem": 1, "4": 1, "show": 1, "regret": 1, "episode": 1, "k": 1, "bound": 1, "tkdk": 1, "": 2, "1": 1}, {"rest": 1, "proof": 1, "rewrite": 1, "theorem": 1, "4": 1, "use": 1, "dk": 1, "": 1, "2d": 1, "k": 1, "high": 1, "probability": 1}, {"difference": 1, "bind": 3, "number": 1, "episodes": 1, "additional": 1, "term": 2, "log2": 1, "de": 1, "one": 1, "obtain": 1, "regret": 1, "r": 1, "q": 1, "": 14, "const1": 1, "smax": 1, "log": 5, "const2": 1, "alog": 1, "const3": 1, "ds": 1, "summarize": 1, "give": 1, "claim": 1}, {"theorem": 1, "6": 1, "show": 1, "cost": 1, "guess": 1, "scheme": 1, "wrt": 1}, {"regret": 1, "small": 1, "particular": 1, "result": 1, "additive": 1, "constant": 1, "bind": 2, "exponential": 1, "diameter": 1, "contrast": 1, "blb": 1, "4": 1}, {"thus": 1, "improvements": 1, "oms": 1, "discuss": 1, "theorem": 1, "4": 1, "hold": 1, "also": 1, "u": 1, "cb": 1, "guess": 1, "diameter": 1}, {"7": 1, "": 4, "6": 1, "improve": 1, "bound": 2, "section": 1, "consider": 1, "improvements": 1, "introduce": 1, "notion": 1, "effective": 1, "size": 1, "state": 1, "space": 1, "set": 1, "model": 1}, {"61": 1, "": 2, "improve": 1, "number": 1, "episodes": 1, "regret": 1, "bound": 1, "obtain": 1, "u": 1, "cb": 1, "basically": 1, "order": 1, "standard": 1, "reinforcement": 1, "learn": 1, "mdps": 1, "ie": 1}, {"give": 1, "markov": 1, "model": 1, "achieve": 1, "eg": 1}, {"9": 1}, {"however": 1, "state": 3, "space": 3, "dependence": 1, "seem": 1, "completely": 1, "satisfactory": 1, "bound": 1, "depend": 1, "size": 2, "markov": 1, "model": 2, "total": 1}, {"appearance": 1, "parameter": 1, "bound": 1, "due": 1, "bind": 1, "number": 1, "episodes": 1, "lemma": 1, "5": 1, "c": 1}, {"worst": 1, "case": 1, "bind": 1, "cannot": 1, "improve": 1}, {"without": 1, "assumptions": 1, "way": 1, "model": 3, "": 3, "aggregate": 1, "histories": 1, "one": 1, "cannot": 1, "say": 1, "visit": 2, "state": 2, "translate": 1, "0": 1}, {"example": 1, "model": 2, "": 2, "state": 2, "visit": 1, "far": 1, "respective": 1, "histories": 1, "may": 1, "map": 1, "single": 1, "0": 1}, {"consequently": 1, "one": 1, "basically": 1, "assume": 1, "state": 1, "different": 1, "model": 1, "": 1, "0": 1, "completely": 1, "independent": 1, "lead": 1, "bind": 1, "lemma": 1, "5": 1, "c": 1}, {"however": 1, "particular": 1, "structure": 1, "set": 1, "give": 1, "model": 1, "": 2, "bind": 1, "number": 2, "episodes": 1, "improve": 1, "depend": 1, "total": 1, "state": 1}, {"definition": 1, "7": 1}, {"let": 1, "": 1, "set": 1, "state": 1, "representation": 1, "model": 1}, {"define": 1, "effective": 1, "size": 1, "state": 5, "space": 1, "": 2, "number": 1, "sufficient": 1, "cover": 2, "sense": 1, "visit": 2, "induce": 1}, {"simple": 1, "example": 1, "model": 1, "hierarchical": 1}, {"model": 3, "": 11, "0": 3, "aggregate": 2, "state": 2, "ie": 1, "hold": 1, "h": 4, "h0": 3, "histories": 1, "case": 1, "could": 1, "order": 1, "2s": 1, "subset": 1, "may": 1, "correspond": 1}, {"note": 1, "consider": 1, "different": 1, "order": 1, "mdp": 1, "also": 1, "result": 1, "hierarchical": 1, "model": 1, "set": 1}, {"general": 1, "obviously": 1, "": 1, "bind": 1, "number": 1, "episodes": 1, "lemma": 1, "5": 1, "c": 1, "improve": 1, "depend": 1, "instead": 1, "proof": 1}, {"lemma": 1, "8": 1}, {"number": 1, "episodes": 1, "u": 1, "cb": 1, "terminate": 1, "double": 1, "criterion": 1, "bound": 1, "log": 1, "": 1}, {"accordingly": 1, "strengthen": 1, "result": 1, "theorems": 1, "4": 1, "6": 1, "follow": 1}, {"theorem": 1, "9": 1}, {"regret": 1, "bound": 1, "theorems": 1, "4": 1, "6": 1, "hold": 1, "replace": 1, "": 1}, {"62": 1, "": 3, "improve": 1, "state": 2, "space": 2, "dependence": 1, "even": 1, "replace": 1, "still": 1, "room": 1, "improvement": 1, "bound": 1, "respect": 1, "size": 1}, {"principle": 1, "one": 1, "would": 1, "like": 1, "dependence": 1, "size": 1, "state": 1, "space": 1, "markov": 1, "model": 1, "": 2}, {"see": 1, "current": 1, "analysis": 1, "dependence": 1, "effective": 1, "number": 1, "state": 1, "unavoidable": 1}, {"however": 1, "improve": 1, "second": 1, "appear": 1, "state": 2, "space": 2, "term": 1, "smax": 1, "guess": 1, "right": 1, "size": 1, "ie": 1, "": 1}, {"distinguish": 1, "two": 1, "case": 1, "depend": 1, "whether": 1, "bind": 1, "diameter": 1, "know": 1}, {"621": 1, "": 2, "diameter": 3, "know": 2, "bind": 1, "guess": 2, "size": 1, "state": 1, "space": 1, "scheme": 1, "suggest": 1, "section": 1, "5": 1}, {"start": 1, "": 2, "1": 1, "min": 1, "compare": 1, "collect": 1, "reward": 2, "optimistic": 1, "average": 1, "ek": 1, "current": 1, "episode": 1, "k": 1, "eliminate": 1, "underachieve": 1, "model": 1}, {"comparison": 1, "term": 1, "choose": 1, "accordance": 1, "regret": 1, "bind": 1, "ucrl2": 1, "theorem": 1, "2": 1, "q": 1, "3": 1, "": 4, "34ds": 1, "tk": 1, "1": 1, "log": 1, "2t": 1}, {"10": 1, "guess": 1, "scheme": 1, "one": 1, "show": 1, "follow": 1, "regret": 1, "bind": 1}, {"theorem": 1, "10": 1}, {"probability": 1, "1": 1, "": 8, "regret": 1, "u": 1, "cb": 1, "guess": 1, "double": 1, "bound": 1, "q": 1, "const": 1, "ds": 1, "log": 3}, {"8": 1, "": 1, "proof": 1}, {"proof": 1, "like": 1, "theorem": 1, "6": 1, "instead": 1, "guess": 1, "comparison": 1, "term": 1, "different": 1}, {"markov": 1, "model": 1, "": 3, "discard": 1, "high": 1, "probability": 1}, {"therefore": 1, "log2": 1, "e": 1, "episodes": 1, "terminate": 1, "discard": 1, "model": 1}, {"let": 1, "sk": 1, "guess": 1, "size": 1, "state": 1, "space": 1, "episode": 2, "k": 2, "similar": 1, "proof": 1, "theorems": 1, "4": 1, "6": 1, "regret": 1, "bound": 1, "tksk": 1, "": 2, "1": 1}, {"sk": 1, "": 3, "2s": 1, "whp": 1, "sum": 1, "log2": 1, "e": 1, "log": 1, "episodes": 1, "jensens": 1, "inequality": 1, "give": 1, "claim": 1, "regret": 1, "bind": 1}, {"see": 1, "replace": 1, "smax": 1, "come": 1, "cost": 1, "worse": 1, "dependence": 1, "number": 1, "state": 1, "action": 1, "sum": 1, "episodes": 1, "proof": 1, "do": 1, "differently": 1}, {"still": 1, "smax": 1, "quite": 1, "large": 1, "bind": 1, "theorem": 1, "10": 1, "improvement": 1, "previously": 1, "present": 1, "bound": 1}, {"622": 1, "": 2, "unknown": 1, "diameter": 2, "know": 1, "one": 1, "guess": 1, "time": 1}, {"precisely": 1, "comparison": 1, "term": 1, "one": 1, "guess": 1, "separately": 1, "factor": 1, "ds": 1, "instead": 1}, {"g": 4, "": 7, "1": 2, "fix": 1, "value": 1, "like": 1, "ds": 2, "min": 1, "define": 1, "one": 1, "start": 1, "set": 1, "comparison": 1, "term": 1, "q": 1, "34ds": 1, "tk": 1, "log": 1, "2t3": 1}, {"ds": 1, "11": 1, "": 2, "lead": 1, "follow": 1, "regret": 1, "bind": 2, "basically": 1, "correspond": 1, "claim": 1, "oms": 1, "replace": 1, "potentially": 1, "smaller": 1}, {"theorem": 1, "11": 1}, {"probability": 1, "1": 1, "": 8, "regret": 1, "u": 1, "cb": 1, "guess": 1, "double": 1, "bound": 1, "q": 1, "const": 1, "ds": 1, "log": 2, "logds": 1}, {"proof": 1}, {"proof": 1, "like": 1, "theorem": 1, "10": 1}, {"whp": 1}, {"log2": 1, "ds": 3, "e": 1, "episodes": 2, "terminate": 1, "eliminate": 1, "model": 1, "regret": 1, "episode": 2, "k": 4, "bound": 1, "g": 2, "": 3, "1": 1, "2ds": 1, "guess": 1, "sum": 1, "give": 1, "tk": 1, "claim": 1, "bind": 1}, {"7": 1, "": 2, "discussion": 1, "decide": 1, "use": 1, "ucrl2": 1, "reference": 1, "algorithm": 2, "definition": 1, "u": 1, "cb": 1, "strategy": 1, "approach": 1, "actually": 1, "serve": 1, "blueprint": 1, "adapt": 1, "optimistic": 1, "know": 1, "regret": 1, "bound": 1, "state": 1, "representation": 1, "set": 1, "consider": 1, "paper": 1}, {"particular": 1, "improve": 1, "regret": 1, "bound": 1, "possible": 1, "wrt": 1}, {"parameters": 1, "cf": 1}, {"9": 1, "ucrl2": 1, "variation": 1, "recent": 1, "13": 1, "automatically": 1, "result": 1, "improve": 1, "bound": 1, "correspond": 1, "variant": 1, "u": 1, "cb": 1, "oms": 1, "algorithm": 1, "5": 1, "employ": 1, "form": 1, "regularization": 1, "model": 1, "large": 1, "state": 1, "space": 1, "less": 1, "appeal": 1}, {"however": 1, "avoid": 1, "dependence": 1, "claim": 1, "bound": 1, "5": 1, "": 1}, {"interest": 1, "question": 1, "whether": 1, "improve": 1, "regularization": 1, "approach": 1, "give": 1, "bound": 1, "depend": 1, "": 1}, {"general": 1, "right": 1, "dependence": 1, "regret": 1, "bound": 1, "size": 1, "model": 1, "set": 1, "": 1, "also": 1, "open": 1, "problem": 1}, {"another": 1, "question": 1, "still": 1, "open": 1, "also": 1, "mdp": 1, "set": 1, "whether": 1, "diameter": 1, "replace": 1, "bias": 1, "span": 1, "": 1, "optimal": 1, "policy": 1, "10": 1, "14": 1}, {"upper": 1, "bind": 1, "": 2, "one": 1, "could": 1, "replace": 1, "ucrl2": 1, "scal": 1, "algorithm": 1, "14": 1}, {"however": 1, "guess": 2, "scheme": 1, "employ": 1, "diameter": 1, "work": 1, "scal": 1, "choose": 1, "policies": 1, "may": 1, "optimistic": 1, "anymore": 1, "": 1, "small": 1}, {"another": 1, "direction": 1, "future": 1, "research": 1, "generalizations": 1, "infinite": 1, "model": 1, "set": 2, "case": 1, "discrete": 1, "already": 1, "do": 1, "blb": 1, "algorithm": 1, "6": 1}, {"parametric": 1, "set": 1, "model": 1, "would": 1, "interest": 1, "next": 1, "step": 1}, {"context": 1, "also": 1, "make": 1, "sense": 1, "consider": 1, "approximate": 1, "markov": 2, "model": 2, "assumption": 1, "drop": 1}, {"result": 1, "give": 1, "15": 1, "set": 1, "also": 1, "affect": 1, "mention": 1, "error": 1, "proof": 1, "oms": 1, "regret": 1, "bind": 1}, {"think": 1, "approach": 1, "adapt": 1, "however": 1, "detail": 1, "still": 1, "work": 1}, {"9": 1, "": 1, "acknowledgments": 1, "work": 1, "support": 1, "austrian": 1, "science": 1, "fund": 1, "fwf": 1, "3437n33": 1, "framework": 1, "chistera": 1, "eranet": 1, "delta": 1, "project": 1}, {"odalricambrym": 1, "maillard": 1, "support": 1, "cper": 1, "nordpas": 1, "de": 2, "calaisfeder": 1, "data": 2, "advance": 1, "science": 1, "technologies": 1, "20152020": 1, "french": 2, "ministry": 1, "higher": 1, "education": 1, "research": 1, "inria": 1, "lille": 1, "": 1, "nord": 1, "europe": 1, "cristal": 1, "agence": 1, "nationale": 1, "la": 1, "recherche": 1, "grant": 1, "anr16ce400002": 1, "project": 1, "badass": 1}, {"reference": 1, "1": 1, "rico": 1, "jonschkowski": 1, "oliver": 1, "brock": 1}, {"state": 1, "representation": 1, "learn": 1, "robotics": 1, "use": 1, "prior": 1, "knowledge": 1, "physical": 1, "interaction": 1}, {"robotics": 1, "science": 1, "systems": 1, "2014": 1}, {"2": 1, "timothe": 1, "lesort": 1, "natalia": 1, "dazrodrguez": 1, "jeanfranois": 1, "goudou": 1, "david": 1, "filliat": 1}, {"state": 1, "representation": 1, "learn": 1, "control": 1, "overview": 1}, {"neural": 1, "network": 1, "2018": 1}, {"3": 1, "tim": 1, "de": 1, "bruin": 1, "jens": 1, "kober": 1, "karl": 1, "tuyls": 1, "robert": 1, "babuska": 1}, {"integrate": 1, "state": 1, "representation": 1, "learn": 2, "deep": 1, "reinforcement": 1}, {"ieee": 1, "robotics": 1, "automation": 1, "letter": 1, "331394": 1, "1401": 1, "2018": 1}, {"4": 1, "odalricambrym": 1, "maillard": 1, "rmi": 1, "munos": 1, "daniil": 1, "ryabko": 1}, {"select": 1, "staterepresentation": 1, "reinforcement": 1, "learn": 1}, {"advance": 1, "neural": 1, "process": 1, "systems": 1, "24": 1, "nip": 1, "2011": 1, "page": 1, "26272635": 1, "2012": 1}, {"5": 1, "odalricambrym": 1, "maillard": 1, "phuong": 1, "nguyen": 1, "ronald": 1, "ortner": 1, "daniil": 1, "ryabko": 1}, {"optimal": 1, "regret": 1, "bound": 1, "select": 1, "state": 1, "representation": 1, "reinforcement": 1, "learn": 1}, {"proceed": 2, "30th": 1, "international": 1, "conference": 2, "machine": 1, "learn": 1, "icml": 1, "2013": 2, "volume": 1, "28": 1, "jmlr": 1, "workshop": 1, "page": 1, "543": 1, "": 1, "551": 1}, {"6": 1, "phuong": 1, "nguyen": 1, "odalricambrym": 1, "maillard": 1, "daniil": 1, "ryabko": 1, "ronald": 1, "ortner": 1}, {"compete": 1, "infinite": 1, "set": 1, "model": 1, "reinforcement": 1, "learn": 1}, {"proceed": 2, "16th": 1, "international": 1, "conference": 2, "artificial": 1, "intelligence": 1, "statistics": 1, "aistats": 1, "2013": 2, "volume": 1, "31": 1, "jmlr": 1, "workshop": 1, "page": 1, "463471": 1}, {"7": 1, "marcus": 1, "hutter": 1}, {"feature": 1, "reinforcement": 1, "learn": 1, "part": 1, "unstructured": 1, "mdps": 1}, {"j": 1}, {"artificial": 1, "general": 1, "intelligence": 1, "11324": 1, "2009": 1}, {"8": 1, "martin": 1, "l": 1, "puterman": 1}, {"markov": 1, "decision": 1, "process": 1, "discrete": 1, "stochastic": 1, "dynamic": 1, "program": 1}, {"john": 1, "wiley": 1, "": 1, "sons": 1, "inc": 1, "new": 1, "york": 1, "ny": 1, "usa": 1, "1994": 1}, {"9": 1, "thomas": 1, "jaksch": 1, "ronald": 1, "ortner": 1, "peter": 1, "auer": 1}, {"nearoptimal": 1, "regret": 1, "bound": 1, "reinforcement": 1, "learn": 1}, {"journal": 1, "machine": 1, "learn": 1, "research": 1, "1115631600": 1, "2010": 1}, {"10": 1, "peter": 1, "l": 1, "bartlett": 1, "ambuj": 1, "tewari": 1}, {"regal": 1, "regularization": 1, "base": 1, "algorithm": 1, "reinforcement": 1, "learn": 1, "weakly": 1, "communicate": 1, "mdps": 1}, {"proceed": 1, "25th": 1, "conference": 1, "uncertainty": 1, "artificial": 1, "intelligence": 1, "uai": 1, "2009": 2, "page": 1, "2542": 1}, {"11": 1, "ronan": 1, "fruit": 1, "matteo": 1, "pirotta": 1, "alessandro": 1, "lazaric": 1}, {"near": 1, "optimal": 1, "explorationexploitation": 1, "noncommunicating": 1, "markov": 1, "decision": 1, "process": 1}, {"advance": 1, "neural": 1, "information": 1, "process": 1, "systems": 1, "31": 1, "neurips": 1, "2018": 2, "page": 1, "29983008": 1}, {"12": 1, "peter": 1, "auer": 1, "nicol": 1, "cesabianchi": 1, "paul": 1, "fischer": 1}, {"finitetime": 1, "analysis": 1, "multiarmed": 1, "bandit": 1, "problem": 1}, {"machine": 1, "learn": 1, "47235256": 1, "2002": 1}, {"13": 1, "ronan": 1, "fruit": 1, "alessandro": 1, "lazaric": 1, "matteo": 1, "pirotta": 1}, {"regret": 1, "minimization": 1, "infinitehorizon": 1, "finite": 1, "markov": 1, "decision": 1, "process": 1}, {"tutorial": 1, "alt19": 1, "2019": 1}, {"url": 1, "httpsrlgammazero": 1}, {"githubio": 1}, {"14": 1, "ronan": 1, "fruit": 1, "matteo": 1, "pirotta": 1, "alessandro": 1, "lazaric": 1, "ronald": 1, "ortner": 1}, {"efficient": 1, "biasspanconstrained": 1, "explorationexploitation": 1, "reinforcement": 1, "learn": 1}, {"proceed": 2, "35th": 1, "international": 1, "conference": 2, "machine": 1, "learn": 1, "icml": 1, "2018": 2, "volume": 1, "80": 1, "jmlr": 1, "workshop": 1, "page": 1, "15731581": 1}, {"10": 1, "": 1, "15": 1, "ronald": 1, "ortner": 1, "odalricambrym": 1, "maillard": 1, "daniil": 1, "ryabko": 1}, {"select": 1, "nearoptimal": 1, "approximate": 1, "state": 1, "representations": 1, "reinforcement": 1, "learn": 1}, {"algorithmic": 1, "learn": 1, "theory": 1, "": 1, "25th": 1, "international": 1, "conference": 1, "alt": 1, "2014": 2, "page": 1, "140154": 1}, {"11": 1}]