[{"maven": 1, "multiagent": 2, "variational": 1, "exploration": 1, "anuj": 1, "mahajan": 1, "": 4, "tabish": 1, "rashid": 1, "mikayel": 1, "samvelyan": 1, "shimon": 1, "whiteson": 1, "abstract": 1, "centralise": 1, "train": 2, "decentralise": 1, "execution": 2, "important": 1, "set": 1, "cooperative": 1, "deep": 1, "reinforcement": 1, "learn": 1, "due": 1, "communication": 1, "constraints": 1, "computational": 1, "tractability": 1}, {"paper": 1, "analyse": 1, "valuebased": 1, "methods": 1, "know": 1, "superior": 1, "performance": 1, "complex": 1, "environments": 1, "43": 1}, {"specifically": 1, "focus": 1, "qmix": 1, "40": 1, "current": 1, "stateoftheart": 1, "domain": 1}, {"show": 1, "representational": 1, "constraints": 1, "joint": 1, "actionvalues": 1, "introduce": 1, "qmix": 1, "similar": 1, "methods": 1, "lead": 1, "provably": 1, "poor": 1, "exploration": 1, "suboptimality": 1}, {"furthermore": 1, "propose": 1, "novel": 1, "approach": 1, "call": 1, "maven": 1, "hybridise": 1, "value": 1, "policybased": 1, "methods": 1, "introduce": 1, "latent": 1, "space": 1, "hierarchical": 1, "control": 1}, {"valuebased": 1, "agents": 1, "condition": 1, "behaviour": 1, "share": 1, "latent": 1, "variable": 1, "control": 1, "hierarchical": 1, "policy": 1}, {"allow": 1, "maven": 1, "achieve": 1, "commit": 1, "temporally": 1, "extend": 1, "exploration": 1, "key": 1, "solve": 1, "complex": 1, "multiagent": 1, "task": 1}, {"experimental": 1, "result": 1, "show": 1, "maven": 1, "achieve": 1, "significant": 1, "performance": 1, "improvements": 1, "challenge": 1, "smac": 1, "domain": 1, "43": 1}, {"1": 1, "": 2, "introduction": 1, "cooperative": 1, "multiagent": 1, "reinforcement": 1, "learn": 1, "marl": 1, "key": 1, "tool": 1, "address": 1, "many": 1, "realworld": 1, "problems": 1, "coordination": 1, "robot": 1, "swarm": 1, "22": 1, "autonomous": 1, "cars": 1, "6": 1}, {"however": 1, "two": 1, "key": 1, "challenge": 1, "stand": 1, "cooperative": 1, "marl": 1, "realworld": 1, "applications": 1}, {"first": 1, "scalability": 1, "limit": 1, "fact": 1, "size": 1, "joint": 1, "action": 1, "space": 1, "grow": 1, "exponentially": 1, "number": 1, "agents": 1}, {"second": 1, "train": 2, "process": 1, "typically": 1, "centralise": 2, "partial": 1, "observability": 1, "communication": 1, "constraints": 1, "often": 1, "mean": 1, "execution": 2, "must": 1, "decentralise": 2, "ie": 1, "agent": 1, "condition": 1, "action": 1, "local": 1, "actionobservation": 1, "history": 1, "set": 1, "know": 1, "ctde": 1}, {"policybased": 1, "13": 1, "valuebased": 2, "40": 2, "48": 1, "46": 1, "methods": 1, "develop": 1, "ctde": 1, "current": 1, "state": 1, "art": 1, "measure": 1, "smac": 1, "suite": 1, "starcraft": 1, "ii": 1, "micromanagement": 1, "benchmark": 1, "task": 1, "43": 1, "method": 1, "call": 1, "qmix": 1}, {"qmix": 1, "try": 1, "address": 1, "challenge": 1, "mention": 1, "learn": 1, "factor": 1, "value": 1, "function": 1}, {"decompose": 1, "joint": 2, "value": 1, "function": 1, "factor": 1, "depend": 1, "individual": 1, "agents": 1, "qmix": 1, "cope": 1, "large": 1, "action": 1, "space": 1}, {"furthermore": 1, "factor": 2, "combine": 1, "way": 1, "respect": 1, "monotonicity": 1, "constraint": 1, "agent": 1, "select": 1, "action": 1, "base": 1, "enable": 1, "decentralise": 1, "execution": 1}, {"however": 1, "decentralisation": 1, "come": 1, "price": 1, "monotonicity": 1, "constraint": 1, "restrict": 1, "qmix": 1, "suboptimal": 1, "value": 1, "approximations": 1}, {"qtran44": 1, "another": 1, "recent": 1, "method": 1, "perform": 1, "tradeoff": 1, "differently": 1, "formulate": 1, "multiagent": 1, "learn": 1, "optimisation": 1, "problem": 1, "linear": 1, "constraints": 1, "relax": 1, "l2": 1, "penalties": 1, "tractability": 1}, {"paper": 1, "shed": 1, "light": 1, "problem": 1, "unique": 1, "decentralise": 1, "marl": 1, "arise": 1, "due": 1, "inefficient": 1, "exploration": 1}, {"inefficient": 1, "exploration": 1, "hurt": 2, "decentralise": 1, "marl": 1, "way": 1, "single": 1, "agent": 1, "": 2, "correspondence": 1, "anujmahajancsoxacuk": 1, "dept": 1}, {"computer": 1, "science": 1, "university": 2, "oxford": 1, "": 3, "russianarmenian": 1, "33rd": 1, "conference": 1, "neural": 1, "information": 1, "process": 1, "systems": 1, "neurips": 1, "2019": 1, "vancouver": 1, "canada": 1}, {"rl33": 1, "increase": 1, "sample": 1, "inefficiency31": 1, "30": 1, "also": 1, "interact": 1, "representational": 1, "constraints": 1, "necessary": 1, "decentralisation": 1, "push": 1, "algorithm": 1, "towards": 1, "suboptimal": 1, "policies": 1}, {"single": 1, "agent": 1, "rl": 1, "avoid": 1, "convergence": 1, "suboptimal": 1, "policies": 1, "use": 1, "various": 1, "strategies": 1, "like": 1, "increase": 1, "exploration": 1, "rate": 1, "": 1, "policy": 1, "variance": 1, "ensure": 1, "optimality": 1, "limit": 1}, {"however": 1, "show": 1, "theoretically": 1, "empirically": 1, "possible": 1, "decentralise": 1, "marl": 1}, {"furthermore": 1, "show": 1, "commit": 1, "exploration": 1, "use": 1, "solve": 1, "problem": 1}, {"commit": 1, "exploration": 1, "36": 1, "exploratory": 1, "action": 1, "perform": 1, "extend": 1, "time": 1, "step": 1, "coordinate": 1, "manner": 1}, {"commit": 1, "exploration": 3, "key": 1, "even": 1, "singleagent": 1, "especially": 1, "important": 1, "marl": 1, "many": 1, "problems": 1, "involve": 1, "longterm": 1, "coordination": 1, "require": 1, "discover": 1, "temporally": 1, "extend": 1, "joint": 1, "strategies": 1, "maximise": 1, "reward": 1}, {"unfortunately": 1, "none": 1, "exist": 1, "methods": 1, "ctde": 1, "equip": 1, "commit": 1, "exploration": 1}, {"address": 1, "limitations": 1, "propose": 1, "novel": 1, "approach": 1, "call": 1, "multiagent": 1, "variational": 1, "exploration": 1, "maven": 1, "hybridise": 1, "value": 1, "policybased": 1, "methods": 1, "introduce": 1, "latent": 1, "space": 1, "hierarchical": 1, "control": 1}, {"mavens": 1, "valuebased": 1, "agents": 1, "condition": 1, "behaviour": 1, "share": 1, "latent": 1, "variable": 1, "control": 1, "hierarchical": 1, "policy": 1}, {"thus": 1, "fix": 1, "latent": 1, "variable": 1, "joint": 2, "actionvalue": 1, "function": 1, "think": 1, "mode": 1, "exploratory": 1, "behaviour": 1, "persist": 1, "entire": 1, "episode": 1}, {"furthermore": 1, "maven": 1, "use": 1, "mutual": 1, "information": 1, "maximisation": 1, "trajectories": 1, "latent": 1, "variables": 1, "learn": 1, "diverse": 1, "set": 1, "behaviours": 1}, {"allow": 1, "maven": 1, "achieve": 1, "commit": 1, "exploration": 1, "respect": 1, "representational": 1, "constraints": 1}, {"demonstrate": 1, "efficacy": 1, "approach": 1, "show": 1, "significant": 1, "performance": 1, "improvements": 1, "challenge": 1, "smac": 1, "domain": 1}, {"2": 1, "": 3, "background": 1, "model": 1, "fully": 1, "cooperative": 1, "multiagent": 1, "task": 1, "decpomdp": 1, "34": 1, "formally": 1, "define": 1, "tuple": 1, "g": 1, "hs": 1, "u": 1, "p": 1, "r": 1, "z": 1, "n": 1}, {"state": 1, "space": 1, "environment": 1}, {"time": 1, "step": 1, "every": 1, "agent": 1, "2": 3, "": 4, "1": 1, "n": 2, "choose": 1, "action": 2, "ui": 1, "u": 4, "form": 1, "joint": 1}, {"p": 1, "s0": 1, "u": 2, "": 4}, {"0": 1, "1": 1, "state": 1, "transition": 1, "function": 1}, {"rs": 1, "u": 2, "": 3}, {"r": 1, "reward": 1, "function": 1, "share": 1, "agents": 1, "2": 1, "0": 1, "1": 1, "discount": 1, "factor": 1}, {"consider": 1, "partially": 1, "observable": 1, "settings": 1, "agent": 1, "access": 1, "full": 1, "state": 1, "figure": 1, "1": 1, "classification": 1, "instead": 1, "sample": 1, "observations": 1, "z": 2, "2": 1, "accord": 1, "observation": 1, "function": 1, "marl": 1, "problems": 1}, {"os": 1, "": 3}, {"z": 1}, {"actionobservation": 1, "history": 1, "agent": 1, "": 10, "2": 1, "z": 1, "u": 2, "condition": 1, "policy": 1, "ui": 1}, {"0": 1, "1": 1}, {"use": 1, "u": 1, "denote": 1, "action": 1, "agents": 1, "follow": 1, "similar": 1, "convention": 1, "forp": 1, "policies": 1, "": 2}, {"joint": 1, "policy": 1, "": 7, "base": 1, "1": 1, "k": 1, "actionvalue": 1, "function": 1, "q": 1, "st": 2, "ut": 2, "est11": 1, "ut11": 1, "rtk": 1}, {"goal": 1, "problem": 1, "k0": 1, "": 2, "find": 1, "optimal": 1, "action": 1, "value": 1, "function": 1, "q": 1}, {"centralise": 1, "train": 1, "learn": 1, "algorithm": 1, "access": 1, "actionobservation": 1, "histories": 1, "agents": 1, "full": 1, "state": 1}, {"however": 1, "agent": 1, "condition": 1, "local": 1, "actionobservation": 1, "history": 1, "": 1, "decentralise": 1, "execution": 1, "hence": 1, "name": 1, "ctde": 1}, {"ctde": 1, "methods": 1, "factor": 1, "action": 1, "value": 1, "agents": 1, "represent": 1, "individual": 1, "agent": 1, "utilities": 1, "qi": 1, "": 1, "2": 1}, {"important": 1, "concept": 1, "methods": 1, "decentralisability": 1, "see": 1, "igm": 1, "44": 1, "assert": 1, "9qi": 1, "": 7, "8s": 1, "u": 2, "0": 1, "arg": 2, "max": 1, "q": 1, "maxu1": 1, "q1": 1, "1": 1, "u1": 1}, {"": 1}, {"": 1}, {"arg": 1, "maxun": 1, "qn": 1, "": 6, "n": 1, "un": 1, "u": 1, "1": 1, "fig": 1}, {"1": 1, "give": 1, "classification": 1, "marl": 1, "problems": 1}, {"containment": 1, "strict": 1, "partially": 1, "observable": 1, "set": 1, "show": 1, "task": 1, "decentralisable": 1, "give": 1, "full": 1, "observability": 1, "sufficient": 1, "representational": 1, "capacity": 1}, {"qmix": 1, "40": 1, "valuebased": 1, "method": 1, "learn": 1, "monotonic": 1, "approximation": 1, "qqmix": 1, "joint": 1, "actionvalue": 1, "function": 1}, {"figure": 1, "8": 1, "appendix": 1, "illustrate": 1, "overall": 1, "setup": 1, "reproduce": 1, "convenience": 1}, {"qmix": 1, "factor": 1, "jointaction": 1, "qqmix": 1, "monotonic": 1, "nonlinear": 1, "combination": 1, "individual": 1, "utilities": 1, "qi": 1, "agent": 1, "learn": 1, "via": 1, "utility": 1, "network": 1}, {"mixer": 1, "network": 1, "nonnegative": 1, "weight": 1, "responsible": 1, "combine": 1, "agents": 1, "utilities": 1, "choose": 1, "action": 1, "ui": 1, "qqmix": 1, "u": 1}, {"q": 1, "su": 1, "nonnegativity": 1, "ensure": 1, "qqmix": 1, "0": 1, "turn": 1, "guarantee": 1, "eq": 1}, {"1": 1}, {"decomposition": 1, "su": 1, "": 3, "allow": 1, "efficient": 1, "tractable": 1, "maximisation": 1, "perform": 1, "onu": 1, "time": 1, "oppose": 1, "ou": 1, "n": 1}, {"additionally": 1, "allow": 1, "easy": 1, "decentralisation": 1, "agent": 1, "independently": 1, "perform": 1, "2": 1, "": 1, "argmax": 1}, {"learn": 1, "qmix": 1, "agents": 1, "use": 1, "greedy": 1, "exploration": 1, "individual": 1, "utilities": 2, "ensure": 1, "sufficient": 1, "explorationpfor": 1, "vdn": 1, "46": 1, "factorization": 1, "restrain": 1, "sum": 1, "qvdn": 1, "u": 1, "": 2, "qi": 1, "ui": 1}, {"qtran": 1, "44": 1, "another": 1, "valuebased": 1, "method": 1}, {"theorem": 1, "1": 1, "qtran": 1, "paper": 1, "guarantee": 1, "optimal": 1, "decentralisation": 1, "use": 1, "linear": 1, "constraints": 2, "agent": 1, "utilities": 1, "joint": 1, "action": 1, "value": 1, "impose": 1, "osu": 1, "n": 1, "": 4, "optimisation": 1, "problem": 1, "involve": 1, "give": 1, "set": 1, "size": 1}, {"computationally": 1, "intractable": 1, "solve": 1, "discrete": 1, "stateaction": 2, "space": 2, "impossible": 1, "give": 1, "continuous": 1}, {"author": 1, "propose": 1, "two": 2, "algorithms": 1, "qtranbase": 1, "qtranalt": 1, "relax": 1, "constraints": 1, "use": 1, "l2": 1, "penalties": 1}, {"qtran": 1, "try": 1, "avoid": 1, "qmixs": 1, "limitations": 1, "find": 1, "perform": 1, "poorly": 1, "practice": 1, "complex": 1, "marl": 1, "domains": 1, "see": 1, "section": 1, "5": 1, "deviate": 1, "exact": 1, "solution": 1, "due": 1, "relaxations": 1}, {"3": 1, "": 2, "analysis": 1, "section": 1, "analyse": 1, "policy": 1, "learn": 1, "qmix": 1, "case": 1, "cannot": 1, "represent": 1, "true": 1, "optimal": 1, "actionvalue": 1, "function": 1}, {"analysis": 1, "restrict": 1, "qmix": 2, "easily": 1, "extend": 1, "similar": 1, "algorithms": 1, "like": 1, "vdn": 1, "46": 1, "whose": 1, "representation": 1, "class": 1, "subset": 1}, {"intuitively": 1, "monotonicity": 1, "imply": 1, "optimal": 1, "action": 2, "agent": 1, "depend": 1, "agents": 1}, {"motivate": 1, "us": 1, "characterise": 1, "class": 1, "qfunctions": 1, "cannot": 1, "represent": 1, "qmix": 1, "call": 1, "nonmonotonic": 1, "q": 1, "function": 1}, {"definition": 1, "1": 1, "nonmonotonicity": 1}, {"state": 1, "2": 3, "agent": 2, "give": 1, "action": 2, "agents": 1, "u": 3, "n": 1, "1": 1, "": 3, "qvalues": 1, "qs": 1, "ui": 1, "form": 1, "order": 1, "space": 1}, {"define": 1, "ci": 1, "u": 3, "": 10, "ui1": 1, "uiu": 1, "qs": 2, "uij": 1, "uij1": 1, "j": 1, "2": 1, "1": 1}, {"": 1}, {"": 1}, {"": 4, "u": 2, "uij": 3, "2": 1, "j": 2, "6": 2, "0": 2, "set": 1, "possible": 1, "order": 1, "actionvalues": 1}, {"jointaction": 1, "value": 1, "function": 1, "nonmonotonic": 1, "9i": 1, "2": 1, "u1": 1, "6": 1, "u2": 1, "st": 1}, {"ci": 2, "u1": 1, "": 5, "u2": 1}, {"simple": 1, "example": 1, "nonmonotonic": 1, "qfunction": 1, "give": 1, "payoff": 1, "matrix": 2, "twoplayer": 1, "threeaction": 1, "game": 1, "show": 1, "table": 1, "1a": 1}, {"table": 1, "1b": 1, "show": 1, "value": 1, "learn": 1, "qmix": 1, "uniform": 1, "visitation": 1, "ie": 1, "stateaction": 1, "pair": 1, "explore": 1, "equally": 1}, {"b": 6, "c": 4, "": 8, "104": 1, "0": 2, "10": 6, "608": 2, "600": 1, "899": 2, "599": 1, "895": 1, "887": 1, "1187": 1, "table": 1, "1": 1, "example": 1, "nonmonotonic": 1, "payoff": 1, "matrix": 1, "qmix": 1, "value": 1, "uniform": 1, "visitation": 1}, {"course": 1, "fact": 1, "qmix": 1, "cannot": 1, "represent": 1, "optimal": 1, "value": 1, "function": 1, "imply": 1, "policy": 1, "learn": 1, "must": 1, "suboptimal": 1}, {"however": 1, "follow": 1, "analysis": 1, "establish": 1, "suboptimality": 1, "policies": 1}, {"theorem": 1, "1": 1, "uniform": 1, "visitation": 1}, {"nplayer": 1, "k": 3, "3action": 1, "matrix": 2, "game": 1, "": 11, "n": 2, "u": 1, "uniform": 1, "visitation": 1, "qqmix": 1, "learn": 1, "suboptimal": 1, "policy": 1, "time": 1, "horizon": 1, "q": 1, "h": 1, "ab1": 1, "0": 3, "r": 2, "1": 3, "payoff": 1, "ndimensional": 1, "give": 1, "template": 1, "ab": 1, "pk": 1, "2": 1, "b": 2, "s1": 1, "nss": 1, "2r": 1, "6": 3}, {"4": 1, "": 1}, {"": 1}, {"r": 1, "": 3, "0": 1}, {"": 2}, {"proof": 1}, {"see": 1, "appendix": 1, "b1": 1, "3": 1, "": 3}, {"": 4, "r3": 1, "7": 3, "5": 1}, {"r": 1, "": 2, "next": 1, "consider": 1, "greedy": 2, "visitation": 1, "agent": 1, "use": 1, "policy": 1, "decrease": 1, "time": 1}, {"provide": 1, "probabilistic": 1, "bind": 1, "maximum": 1, "possible": 1, "value": 1, "qmix": 1, "learn": 1, "suboptimal": 1, "policy": 1, "time": 1, "horizon": 1, "": 1}, {"theorem": 1, "2": 1, "greedy": 1, "visitation": 1}, {"nplayer": 1, "k": 2, "3action": 1, "matrix": 2, "game": 1, "greedy": 1, "visitation": 1, "qqmix": 1, "learn": 1, "suboptimal": 1, "policy": 1, "time": 1, "horizon": 1, "probability": 1, "r": 3, "": 14, "2": 3, "b": 2, "n": 1, "1": 4, "exp": 2, "2kn": 1, "12": 1, "0": 2, "21": 1, "2ab": 1, "payoff": 1, "give": 1, "template": 1}, {"pk": 1, "": 7, "2": 1, "ns": 1, "1": 2, "s1": 1, "kn": 1, "b": 1, "proof": 1}, {"see": 1, "appendix": 1, "b2": 1, "reliance": 1, "qmix": 1, "greedy": 1, "action": 2, "selection": 1, "prevent": 1, "engage": 1, "commit": 1, "exploration": 1, "36": 1, "precise": 1, "sequence": 1, "must": 1, "choose": 1, "order": 1, "reach": 1, "novel": 1, "interest": 1, "part": 1, "state": 1, "space": 1}, {"moreover": 1, "theorems": 1, "1": 1, "2": 1, "imply": 1, "agents": 1, "latch": 1, "onto": 1, "suboptimal": 1, "behaviour": 1, "early": 1, "due": 1, "monotonicity": 1, "constraint": 1}, {"theorem": 1, "2": 1, "particular": 1, "provide": 1, "surprise": 1, "result": 1, "fix": 1, "time": 1, "budget": 1, "": 1, "increase": 1, "qmixs": 1, "exploration": 1, "rate": 1, "lower": 1, "probability": 1, "learn": 1, "optimal": 1, "action": 1, "due": 1, "representational": 1, "limitations": 1}, {"intuitively": 1, "monotonicity": 1, "constraint": 1, "prevent": 1, "qnetwork": 1, "correctly": 1, "remember": 1, "true": 1, "value": 1, "optimal": 1, "action": 1, "currently": 1, "perceive": 1, "suboptimal": 1}, {"hypothesise": 1, "lack": 1, "principled": 1, "exploration": 2, "strategy": 1, "couple": 1, "representational": 1, "limitations": 1, "often": 1, "lead": 1, "catastrophically": 1, "poor": 1, "confirm": 1, "empirically": 1}, {"4": 1, "": 2, "methodology": 1, "section": 1, "propose": 1, "multiagent": 1, "variational": 1, "exploration": 2, "maven": 1, "new": 1, "method": 1, "overcome": 1, "detrimental": 1, "effect": 1, "qmixs": 1, "monotonicity": 1, "constraint": 1}, {"maven": 1, "learn": 1, "diverse": 1, "ensemble": 1, "monotonic": 1, "approximations": 1, "help": 1, "latent": 1, "space": 1}, {"architecture": 1, "consist": 1, "valuebased": 1, "agents": 1, "condition": 1, "behaviour": 1, "share": 1, "latent": 1, "variable": 1, "z": 1, "control": 1, "hierarchical": 1, "policy": 1, "offload": 1, "greedy": 1, "commit": 1, "exploration": 1}, {"thus": 1, "fix": 1, "z": 1, "joint": 1, "actionvalue": 1, "function": 1, "figure": 1, "2": 1, "architecture": 1, "maven": 1}, {"monotonic": 1, "approximation": 1, "optimal": 1, "actionvalue": 1, "function": 1, "learn": 1, "qlearning": 1}, {"furthermore": 1, "approximation": 1, "see": 1, "mode": 1, "commit": 1, "joint": 1, "exploratory": 1, "behaviour": 1}, {"latent": 1, "policy": 2, "z": 1, "see": 1, "explore": 1, "space": 1, "joint": 1, "behaviours": 1, "train": 1, "use": 1, "learn": 1, "method": 1}, {"intuitively": 1, "z": 1, "space": 1, "map": 1, "diverse": 1, "modes": 1, "behaviour": 1}, {"fig": 1}, {"2": 1, "illustrate": 1, "complete": 1, "setup": 1, "maven": 1}, {"first": 1, "focus": 1, "lefthand": 1, "side": 1, "diagram": 1, "describe": 1, "learn": 1, "framework": 1, "latent": 1, "space": 1, "policy": 1, "joint": 1, "action": 1, "value": 1}, {"parametrise": 1, "hierarchical": 1, "policy": 1, "": 4, "agent": 1, "utility": 1, "network": 1, "hypernet": 1, "map": 1, "latent": 1, "variable": 1, "z": 1, "use": 1, "condition": 1, "utilities": 1, "mixer": 1, "net": 1}, {"": 1, "associate": 2, "feature": 1, "extraction": 1, "module": 1, "per": 1, "agent": 1, "task": 1, "modify": 1, "utilities": 1, "particular": 1, "mode": 1, "exploration": 1}, {"model": 1, "hierarchical": 1, "policy": 1, "z": 2, "s0": 3, "": 6, "transformation": 1, "simple": 1, "random": 1, "variable": 1, "x": 2, "px": 1, "neural": 1, "network": 1, "parameterised": 1, "thus": 1, "g": 1, "initial": 1, "state": 1}, {"natural": 1, "choices": 1, "px": 1, "uniform": 2, "discrete": 1, "z": 2, "normal": 1, "continuous": 1}, {"4": 1, "": 1, "next": 1, "provide": 1, "coordinate": 1, "ascent": 1, "scheme": 1, "optimise": 1, "parameters": 1}, {"fix": 1, "z": 3, "give": 1, "joint": 1, "actionvalue": 1, "function": 1, "qu": 1, "": 6, "implicitly": 1, "define": 1, "greedy": 1, "deterministic": 1, "policy": 1, "us": 1, "drop": 1, "parameter": 1, "dependence": 1, "wherever": 1, "inferable": 1, "clarity": 1, "presentation": 1}, {"give": 1, "correspond": 1, "qlearning": 1, "loss": 1, "lql": 1, "": 15, "ea": 1, "qut": 1, "st": 2, "z": 1, "rut": 1, "max": 1, "qut1": 1, "st1": 1, "z2": 1, "ut1": 1, "time": 1, "step": 1}, {"next": 1, "fix": 1, "": 11, "p": 1, "hierarchical": 1, "policy": 1, "z": 2, "s0": 1, "train": 1, "cumulative": 1, "trajectory": 2, "reward": 1, "r": 1, "rt": 1, "joint": 1}, {"algorithm": 1, "1": 1, "maven": 1, "": 48, "initialize": 1, "parameter": 1, "vectors": 1, "learn": 1, "rate": 1, "episodic": 1, "iteration": 1, "s0": 4, "x": 2, "px": 1, "z": 5, "g": 1, "environment": 1, "step": 2, "ut": 4, "ust": 1, "st1": 2, "pst1": 1, "st": 2, "rst": 1, "raux": 1, "end": 3, "gradient": 1, "r": 5, "jv": 4, "ql": 3, "lql": 3, "hypernet": 1, "update": 5, "feature": 1, "mixer": 1, "variational": 1, "jrl": 2, "latent": 1, "space": 1, "thus": 1, "hierarchical": 1, "policy": 1, "objective": 1, "freeze": 1, "parameters": 1, "ra": 1, "zp": 1, "zs0": 1, "dzds0": 1}, {"give": 1, "": 1, "however": 1, "formulation": 1, "far": 1, "encourage": 1, "diverse": 1, "behaviour": 2, "correspond": 1, "different": 1, "value": 2, "z": 2, "could": 1, "collapse": 1, "joint": 1}, {"prevent": 1, "introduce": 1, "mutual": 1, "information": 1, "mi": 1, "objective": 1, "observe": 1, "trajectories": 1, "": 4, "ut": 1, "st": 1, "representative": 1, "joint": 1, "behaviour": 1, "latent": 1, "variable": 1, "z": 1}, {"action": 1, "ut": 1, "trajectory": 1, "represent": 1, "stack": 1, "agent": 1, "utilities": 1, "operator": 1, "return": 1, "peragent": 1, "boltzmann": 1, "policy": 1, "wrt": 1}, {"utilities": 1, "time": 1, "step": 1, "ensure": 1, "mi": 1, "objective": 1, "differentiable": 1, "help": 1, "train": 1, "network": 1, "parameters": 1, "": 4}, {"use": 1, "rnn": 1, "20": 1, "encode": 1, "entire": 1, "trajectory": 1, "maximise": 1, "": 2, "z": 1}, {"intuitively": 1, "mi": 1, "objective": 1, "encourage": 1, "visitation": 1, "diverse": 1, "trajectories": 1, "": 1, "time": 1, "make": 1, "identifiable": 1, "give": 1, "z": 2, "thus": 1, "elegantly": 1, "separate": 1, "space": 1, "different": 1, "exploration": 1, "modes": 1}, {"mi": 1, "objective": 1, "jm": 1, "": 10, "h": 3, "z": 1, "hz": 2, "entropy": 1}, {"however": 1, "neither": 1, "entropy": 1, "": 2, "conditional": 1, "z": 1, "give": 1, "former": 1, "tractable": 1, "nontrivial": 1, "mappings": 1, "make": 1, "directly": 1, "use": 1, "mi": 1, "infeasible": 1}, {"therefore": 1, "introduce": 1, "variational": 1, "distribution": 1, "q": 1, "z": 2, "": 2, "50": 1, "3": 1, "parameterised": 1, "proxy": 1, "posterior": 1, "provide": 1, "lower": 1, "bind": 1, "jm": 1, "see": 1, "appendix": 1, "b3": 1}, {"jm": 1, "": 7, "hz": 1, "e": 1, "z": 2, "logq": 1}, {"refer": 1, "righthand": 1, "side": 1, "inequality": 1, "variational": 1, "mi": 1, "objective": 1, "jv": 1, "": 5}, {"lower": 1, "bind": 1, "match": 1, "exact": 1, "mi": 1, "variational": 1, "distribution": 1, "equal": 1, "pz": 1, "": 2, "true": 1, "posterior": 1, "z": 1}, {"righthand": 1, "side": 1, "fig": 1}, {"2": 1, "give": 1, "network": 1, "architectures": 1, "correspond": 1, "variational": 1, "mi": 1, "loss": 1}, {"since": 1, "e": 2, "z": 3, "logq": 1, "": 6, "klpz": 1, "q": 1, "5": 1, "hz": 1, "nonnegativity": 1, "kl": 1, "divergence": 1, "righthand": 1, "side": 1, "imply": 1, "bad": 1, "variational": 1, "approximation": 1, "hurt": 1, "performance": 1, "induce": 1, "gap": 1, "true": 1, "objective": 1, "lower": 1, "bind": 1, "32": 1, "2": 1}, {"problem": 1, "especially": 1, "important": 1, "z": 2, "choose": 1, "continuous": 1, "discrete": 1, "distributions": 1, "posterior": 1, "represent": 1, "exactly": 1, "long": 1, "dimensionality": 1, "greater": 1, "number": 1, "categories": 1}, {"problem": 1, "address": 1, "various": 1, "stateoftheart": 1, "developments": 1, "amortise": 1, "variational": 1, "inference": 1, "42": 1, "41": 1}, {"variational": 1, "approximation": 1, "also": 1, "see": 1, "z": 2, "discriminatorcritic": 1, "induce": 1, "auxiliary": 1, "reward": 1, "field": 1, "raux": 1, "": 5, "logq": 1, "logpz": 1, "trajectory": 1, "space": 1}, {"thus": 1, "overall": 1, "objective": 1, "become": 1, "max": 1, "jrl": 1, "": 21, "jv": 1, "ql": 2, "lql": 1, "positive": 1, "multipliers": 1}, {"train": 2, "see": 1, "algorithm": 1, "1": 1, "begin": 1, "episode": 1, "sample": 1, "x": 1, "obtain": 1, "z": 1, "unroll": 1, "policy": 2, "termination": 1, "": 3, "qlearning": 1, "loss": 1, "correspond": 1, "greedy": 1, "current": 1, "exploration": 1, "mode": 1, "variational": 1, "mi": 1, "reward": 1}, {"hierarchical": 1, "policy": 2, "parameters": 1, "": 1, "train": 1, "true": 1, "task": 1, "return": 1, "use": 1, "optimisation": 1, "algorithm": 1}, {"test": 1, "time": 1, "sample": 1, "z": 1, "start": 1, "episode": 1, "perform": 1, "decentralise": 1, "argmax": 1, "correspond": 1, "qfunction": 1, "select": 1, "action": 1}, {"thus": 1, "maven": 1, "achieve": 1, "commit": 1, "exploration": 1, "respect": 1, "qmixs": 1, "representational": 1, "constraints": 1}, {"5": 1, "": 2, "experimental": 1, "result": 1, "empirically": 1, "evaluate": 1, "maven": 1, "various": 1, "new": 1, "exist": 1, "domains": 1}, {"51": 1, "mstep": 2, "matrix": 2, "game": 2, "test": 1, "nonmonotonicity": 1, "exploration": 1, "interact": 1, "introduce": 1, "simple": 1}, {"initial": 1, "state": 3, "nonmonotonic": 1, "zero": 1, "reward": 1, "lead": 1, "termination": 1, "differentiate": 1, "locate": 1, "terminal": 1, "end": 1, "2": 1, "intermediate": 1}, {"fig": 1}, {"3a": 1, "illustrate": 1, "mstep": 1, "matrix": 1, "game": 1, "": 1, "10": 1}, {"optimal": 2, "policy": 1, "take": 2, "top": 1, "leave": 1, "joint": 1, "action": 2, "finally": 1, "bottom": 1, "right": 1, "give": 1, "total": 1, "payoff": 1, "": 1, "3": 1}, {"increase": 1, "become": 2, "increasingly": 1, "difficult": 1, "discover": 1, "optimal": 1, "policy": 1, "use": 1, "dither": 1, "commit": 1, "approach": 1, "necessary": 1}, {"additionally": 1, "initial": 1, "state": 1, "nonmonotonicity": 1, "provide": 1, "inertia": 1, "switch": 1, "policy": 1, "direction": 1}, {"fig": 1}, {"3b": 1, "plot": 1, "median": 1, "return": 1, "": 1, "10": 1}, {"qmix": 1, "get": 1, "stick": 1, "suboptimal": 1, "policy": 2, "payoff": 2, "10": 1, "maven": 1, "successfully": 1, "learn": 1, "true": 1, "optimal": 1, "13": 1}, {"example": 1, "show": 1, "representational": 1, "constraints": 1, "hurt": 1, "performance": 1, "leave": 1, "unmoderated": 1}, {"b": 2, "figure": 1, "3": 1, "mstep": 1, "matrix": 2, "game": 2, "": 1, "10": 1, "case": 1, "median": 1, "return": 1, "maven": 1, "qmix": 1, "method": 1, "10step": 1, "100k": 1, "train": 1, "step": 1, "average": 1, "20": 1, "random": 1, "initializations": 1, "2nd": 1, "3rd": 1, "quartile": 1, "shade": 1}, {"52": 1, "": 2, "starcraft": 3, "ii": 2, "multiagent": 1, "challenge": 2, "consider": 1, "set": 1, "cooperative": 1, "map": 1, "smac": 1, "benchmark": 1, "43": 1, "samvelyan": 1, "et": 1, "al": 1}, {"classify": 1, "easy": 1, "hard": 2, "super": 1}, {"evaluation": 1, "procedure": 1, "similar": 1, "40": 1, "43": 1}, {"pause": 1, "train": 1, "every": 1, "100000": 1, "time": 1, "step": 1, "run": 1, "32": 1, "evaluation": 1, "episodes": 1, "decentralise": 1, "greedy": 1, "action": 1, "selection": 1}, {"train": 1, "report": 1, "median": 1, "test": 1, "win": 1, "rate": 1, "percentage": 1, "episodes": 1, "along": 1, "2nd": 1, "3rd": 1, "quartiles": 1, "shade": 1, "plot": 1}, {"use": 1, "grid": 1, "search": 1, "tune": 1, "hyperparameters": 1}, {"appendix": 1, "c1": 1, "contain": 1, "additional": 1, "experimental": 1, "detail": 1}, {"compare": 1, "maven": 1, "qtran": 1, "qmix": 1, "coma": 1, "13": 1, "iql": 1, "48": 1, "several": 1, "smac": 1, "map": 1}, {"present": 1, "result": 1, "two": 1, "super": 1, "hard": 1, "map": 2, "corridor": 1, "": 1, "6hvs8z": 1, "easy": 1, "2s3z": 1}, {"corridor": 1, "map": 1, "6": 1, "zealots": 1, "face": 1, "24": 1, "enemy": 2, "zerglings": 1, "require": 1, "agents": 1, "make": 1, "effective": 1, "use": 1, "terrain": 1, "feature": 1, "block": 1, "attack": 1, "different": 1, "directions": 1}, {"properly": 1, "6": 1, "": 4, "corridor": 1, "super": 2, "hard": 2, "b": 1, "6hvs8z": 1, "c": 1, "2s3z": 1, "easy": 1, "figure": 1, "4": 1, "performance": 1, "various": 1, "algorithms": 1, "three": 1, "smac": 1, "map": 1}, {"coordinate": 1, "exploration": 1, "scheme": 1, "apply": 1, "map": 1, "would": 1, "help": 1, "agents": 1, "discover": 1, "suitable": 1, "unit": 1, "position": 1, "quickly": 1, "improve": 1, "performance": 1}, {"6hvs8z": 1, "require": 1, "fine": 1, "grain": 1, "focus": 1, "fire": 1, "ally": 1, "hydralisks": 1}, {"2s3z": 1, "require": 1, "agents": 1, "learn": 1, "focus": 1, "fire": 1, "interception": 1}, {"figs": 1}, {"4a": 1, "4c": 1, "show": 1, "median": 1, "win": 1, "rat": 1, "different": 1, "algorithms": 1, "map": 1, "additional": 1, "plot": 1, "find": 1, "appendix": 1, "c2": 1}, {"plot": 1, "show": 1, "maven": 2, "perform": 2, "substantially": 1, "better": 2, "alternate": 1, "approach": 1, "super": 1, "hard": 2, "map": 1, "performance": 1, "similar": 1, "qmix": 1, "easy": 1, "mapsthus": 1, "difficulty": 1, "increase": 1}, {"furthermore": 1, "qtran": 1, "yield": 1, "satisfactory": 1, "performance": 1, "smac": 1, "map": 1, "0": 1, "win": 1, "rate": 1}, {"map": 1, "perform": 1, "best": 1, "2s3z": 1, "fig": 1}, {"4c": 1, "easy": 1, "map": 1, "still": 1, "worse": 1, "qmix": 1, "maven": 1}, {"believe": 1, "qtran": 1, "enforce": 1, "decentralisation": 1, "use": 1, "relax": 1, "l2": 1, "penalties": 1, "insufficient": 1, "challenge": 1, "domains": 1}, {"2corridors": 1, "": 6, "c": 1, "zealotcave": 3, "b": 1, "shorter": 1, "corridor": 1, "close": 1, "5mil": 1, "step": 1, "depth": 2, "3": 1, "e": 1, "4": 1, "figure": 1, "5": 1, "state": 1, "exploration": 3, "policy": 1, "robustness": 2, "although": 1, "smac": 1, "domains": 1, "challenge": 1, "specially": 1, "design": 1, "test": 1, "stateaction": 1, "space": 1, "units": 1, "involve": 1, "start": 1, "engage": 1, "immediately": 1, "spawn": 1}, {"thus": 1, "introduce": 1, "new": 1, "smac": 1, "map": 1, "design": 1, "specifically": 1, "assess": 1, "effectiveness": 1, "multiagent": 1, "exploration": 1, "techniques": 1, "ability": 1, "adapt": 1, "change": 1, "environment": 1}, {"2corridors": 1, "map": 1, "feature": 1, "two": 1, "marines": 1, "face": 1, "enemy": 1, "zealot": 1}, {"begin": 1, "train": 1, "agents": 1, "make": 1, "use": 1, "two": 1, "corridors": 1, "attack": 1, "enemy": 1, "see": 1, "fig": 1}, {"5a": 1}, {"halfway": 1, "train": 1, "short": 1, "corridor": 1, "block": 1}, {"require": 1, "agents": 1, "adapt": 1, "accordingly": 1, "use": 1, "long": 1, "corridor": 1, "coordinate": 1, "way": 1, "attack": 1, "enemy": 1}, {"fig": 1}, {"5b": 1, "present": 1, "win": 1, "rate": 1, "maven": 1, "qmix": 1, "2corridors": 1, "gate": 1, "short": 1, "corridor": 1, "close": 1, "5": 1, "million": 1, "step": 1}, {"qmix": 1, "fail": 1, "recover": 1, "closure": 1, "maven": 1, "swiftly": 1, "adapt": 1, "change": 1, "environment": 1, "start": 1, "use": 1, "long": 1, "corridor": 1}, {"mavens": 1, "latent": 1, "space": 1, "allow": 1, "explore": 1, "commit": 1, "manner": 1, "associate": 1, "use": 1, "long": 1, "corridor": 1, "value": 1, "z": 1}, {"furthermore": 1, "facilitate": 1, "recall": 1, "behaviour": 1, "short": 1, "corridor": 1, "become": 1, "unavailable": 1, "qmix": 1, "struggle": 1, "due": 1, "representational": 1, "constraints": 1}, {"also": 1, "introduce": 1, "another": 1, "new": 1, "map": 1, "call": 1, "zealotcave": 1, "test": 1, "state": 1, "exploration": 1, "feature": 1, "treestructured": 1, "cave": 1, "zealot": 1, "leaf": 1, "nod": 1, "see": 1, "fig": 1}, {"5c": 1}, {"agents": 1, "consist": 1, "2": 1, "marines": 1, "need": 1, "learn": 1, "kit": 1, "reach": 1, "way": 1, "leaf": 1, "nod": 1, "get": 1, "extra": 1, "reward": 1, "always": 1, "take": 1, "right": 1, "branch": 1, "except": 1, "final": 1, "intersection": 1}, {"depth": 1, "cave": 1, "offer": 1, "control": 1, "task": 1, "difficulty": 1}, {"figs": 1}, {"5d": 1, "5e": 1, "give": 1, "average": 1, "reward": 1, "receive": 1, "different": 1, "algorithms": 1, "cave": 1, "depths": 1, "3": 1, "4": 1}, {"maven": 1, "outperform": 1, "algorithms": 1, "compare": 1}, {"7": 1, "": 1, "representability": 1, "optimal": 1, "actionvalue": 1, "function": 1, "lie": 1, "outside": 1, "representation": 1, "class": 1, "ctde": 1, "algorithm": 1, "use": 1, "interest": 1, "problems": 1}, {"one": 1, "way": 1, "tackle": 1, "issue": 1, "find": 1, "local": 2, "approximations": 1, "optimal": 1, "value": 1, "function": 1, "choose": 1, "best": 1, "approximation": 1, "give": 1, "observation": 1}, {"hypothesise": 1, "maven": 1, "enable": 1, "application": 1, "figure": 1, "6": 1, "tsne": 1, "plot": 1, "s0": 2, "label": 1, "z": 2, "16": 1, "categories": 1, "initial": 2, "principle": 1, "map": 1, "latent": 1, "space": 1, "leave": 1, "final": 1, "right": 1, "top": 1, "3s5z": 1, "bottom": 1, "microcorridor": 1, "local": 1, "approximations": 1, "use": 1, "hierarchical": 1, "policy": 1, "choose": 1, "best": 1, "approximation": 1, "give": 1, "state": 1, "": 1, "thus": 1, "offer": 1, "better": 1, "representational": 1, "capacity": 1, "respect": 1, "constraints": 1, "require": 1, "decentralization": 1}, {"demonstrate": 1, "plot": 1, "tsne": 1, "29": 1, "initial": 1, "state": 1, "colour": 1, "accord": 1, "latent": 1, "variable": 1, "sample": 1, "use": 1, "hierarchical": 1, "policy": 1, "different": 1, "time": 1, "step": 1, "train": 1}, {"top": 1, "row": 1, "fig": 1}, {"6": 1, "give": 1, "time": 1, "evolution": 1, "plot": 1, "3s5z": 1, "show": 1, "maven": 1, "learn": 1, "associate": 1, "initial": 1, "state": 1, "cluster": 1, "latent": 1, "value": 1, "thus": 1, "partition": 1, "stateaction": 1, "space": 1, "distinct": 1, "joint": 1, "behaviours": 1}, {"another": 1, "interest": 1, "plot": 1, "bottom": 1, "row": 1, "microcorridor": 1, "demonstrate": 1, "mavens": 1, "latent": 1, "space": 1, "allow": 1, "transition": 1, "reward": 1, "joint": 1, "behaviour": 1, "exist": 1, "methods": 1, "would": 1, "struggle": 1, "accomplish": 1}, {"": 3, "b": 2, "c": 1, "figure": 1, "7": 1, "investigate": 1, "uniform": 1, "hierarchical": 1, "policy": 1}, {"c": 1, "": 1, "investigate": 1, "effect": 1, "mi": 1, "loss": 1}, {"ablations": 2, "perform": 1, "several": 1, "microcorridor": 1, "scenario": 1, "z": 1, "": 1, "16": 1, "try": 1, "determine": 1, "importance": 1, "component": 1, "maven": 1}, {"first": 1, "consider": 1, "use": 1, "fix": 1, "uniform": 1, "hierarchical": 1, "policy": 1, "z": 1}, {"fig": 1}, {"7a": 1, "show": 1, "maven": 1, "uniform": 1, "policy": 2, "z": 1, "perform": 1, "worse": 1, "learn": 1}, {"interestingly": 1, "use": 1, "uniform": 1, "hierarchical": 1, "policy": 1, "variational": 1, "mi": 1, "loss": 1, "encourage": 1, "diversity": 1, "result": 1, "drop": 1, "performance": 1, "show": 1, "fig": 1}, {"7b": 1}, {"thus": 1, "sufficient": 1, "diversification": 1, "observe": 1, "trajectories": 1, "via": 1, "explicit": 1, "agency": 1, "important": 1, "find": 1, "good": 1, "policies": 1, "ensure": 1, "sample": 1, "efficiency": 1}, {"fig": 1}, {"7b": 1, "similar": 1, "bootstrappeddqn": 1, "36": 1, "incentive": 1, "produce": 1, "diverse": 1, "behaviour": 1, "differ": 1, "initialisations": 1, "depend": 1, "z": 1}, {"thus": 1, "latent": 1, "variable": 1, "value": 1, "collapse": 1, "joint": 1, "behaviour": 1}, {"able": 1, "learn": 1, "hierarchical": 1, "policy": 1, "z": 1, "focus": 1, "computation": 1, "environmental": 1, "sample": 1, "promise": 1, "variables": 1, "allow": 1, "better": 1, "final": 1, "performance": 1}, {"fig": 1}, {"7c": 1, "show": 1, "improve": 1, "performance": 1, "relative": 1, "fig": 1}, {"7b": 1, "provide": 1, "evidence": 1, "claim": 1}, {"next": 1, "consider": 1, "different": 1, "choices": 1, "variational": 1, "mi": 1, "loss": 1, "per": 2, "time": 1, "step": 1, "trajectory": 1, "affect": 1, "performance": 1, "fig": 1}, {"7d": 1}, {"intuitively": 1, "per": 1, "time": 1, "step": 2, "loss": 1, "promote": 1, "spread": 1, "exploration": 1, "force": 1, "discriminator": 1, "learn": 1, "inverse": 1, "map": 1, "latent": 1, "variable": 1}, {"thus": 1, "tend": 1, "distribute": 1, "exploration": 1, "budget": 1, "step": 2, "uniformly": 1, "whereas": 1, "trajectory": 2, "loss": 1, "allow": 1, "joint": 1, "behaviours": 1, "similar": 1, "extend": 1, "durations": 1, "take": 1, "diversify": 1, "action": 1, "time": 1, "keep": 1, "spread": 1, "fairly": 1, "narrow": 1}, {"however": 1, "find": 1, "scenarios": 1, "two": 1, "losses": 1, "perform": 1, "similarly": 1}, {"see": 1, "appendix": 1, "c2": 1, "additional": 1, "plot": 1, "ablation": 1, "result": 1}, {"8": 1, "": 3, "6": 1, "relate": 1, "work": 2, "recent": 1, "years": 1, "considerable": 1, "extend": 1, "marl": 1, "small": 1, "discrete": 1, "state": 2, "space": 2, "handle": 1, "tabular": 1, "methods": 1, "51": 1, "5": 1, "highdimensional": 1, "continuous": 1, "require": 1, "use": 1, "function": 1, "approximators": 1, "13": 1, "28": 1, "39": 1}, {"tackle": 1, "computational": 1, "intractability": 1, "exponential": 1, "blowup": 1, "stateaction": 1, "space": 1, "guestrin": 1, "et": 1, "al": 1}, {"16": 1, "17": 1, "use": 1, "coordination": 1, "graph": 2, "factor": 1, "large": 1, "mdps": 1, "multiagent": 1, "systems": 1, "propose": 1, "interagent": 1, "communication": 1, "arise": 1, "message": 1, "pass": 1}, {"similarly": 1, "45": 1, "11": 1, "23": 1, "model": 1, "interagent": 1, "communication": 1, "explicitly": 1}, {"ctde": 1, "26": 1, "47": 1, "extend": 1, "independent": 1, "qlearning": 1, "48": 1, "use": 1, "dqn": 1, "learn": 1, "qvalues": 1, "agent": 1, "independently": 1}, {"12": 1, "35": 1, "tackle": 1, "instability": 1, "arise": 1, "train": 1, "agents": 1, "independently": 1}, {"lin": 1, "et": 1, "al": 1}, {"27": 1, "first": 1, "learn": 1, "centralise": 1, "controller": 1, "solve": 1, "task": 1, "train": 1, "agents": 1, "imitate": 1, "behaviour": 1}, {"sunehag": 1, "et": 1, "al": 1}, {"46": 1, "propose": 1, "value": 1, "decomposition": 1, "network": 1, "vdn": 1, "learn": 1, "jointaction": 1, "qvalues": 2, "factor": 1, "sum": 1, "agents": 1}, {"qmix": 1, "40": 1, "extend": 1, "vdn": 1, "allow": 1, "joint": 1, "action": 1, "qvalues": 2, "monotonic": 1, "combination": 1, "agents": 1, "vary": 1, "depend": 1, "state": 1}, {"section": 1, "4": 1, "outline": 1, "maven": 1, "build": 1, "upon": 1, "qmix": 1}, {"qtran": 1, "44": 1, "approach": 1, "suboptimality": 1, "vs": 1, "decentralisation": 1, "tradeoff": 1, "differently": 1, "introduce": 1, "relax": 1, "l2": 1, "penalties": 1, "rl": 1, "objective": 1}, {"15": 1, "maximise": 1, "empowerment": 1, "one": 1, "agents": 1, "action": 1, "others": 1, "future": 1, "state": 1, "competitive": 1, "set": 1}, {"zheng": 1, "et": 1, "al": 1}, {"52": 1, "allow": 1, "agent": 1, "condition": 1, "policies": 1, "share": 1, "continuous": 1, "latent": 1, "variable": 1}, {"contrast": 1, "set": 2, "consider": 1, "fullyobservable": 1, "centralise": 1, "control": 1, "attempt": 1, "enforce": 1, "diversity": 1, "across": 1, "share": 1, "latent": 1, "variable": 1}, {"aumann": 1, "1": 1, "propose": 1, "concept": 1, "correlate": 1, "equilibrium": 1, "noncooperative": 1, "multiagent": 1, "settings": 1, "agent": 1, "condition": 1, "policy": 1, "share": 1, "variable": 1, "sample": 1, "every": 1, "episode": 1}, {"single": 1, "agent": 1, "set": 1, "osband": 1, "et": 1, "al": 1}, {"36": 1, "learn": 1, "ensemble": 1, "qvalue": 1, "function": 1, "share": 1, "weight": 1, "except": 1, "final": 1, "layer": 1, "train": 1, "sample": 1, "trajectories": 1, "approximate": 1, "posterior": 1, "qvalues": 1, "via": 1, "statistical": 1, "bootstrapping": 1, "method": 1}, {"maven": 1, "without": 1, "mi": 1, "loss": 1, "uniform": 1, "policy": 1, "z": 1, "equivalent": 1, "agent": 1, "use": 1, "bootstrapped": 1, "dqn": 1}, {"37": 1, "extend": 1, "bootstrapped": 1, "dqn": 1, "include": 1, "prior": 1}, {"7": 1, "consider": 1, "set": 1, "concurrent": 1, "rl": 1, "multiple": 1, "agents": 1, "interact": 1, "environments": 1, "parallel": 1}, {"aim": 2, "achieve": 2, "efficient": 1, "exploration": 1, "stateaction": 1, "space": 1, "seed": 2, "agents": 1, "parametric": 1, "distributions": 1, "mdps": 1, "different": 1, "whereas": 1, "maven": 1, "maximise": 1, "mutual": 1, "information": 1, "z": 1, "trajectory": 1}, {"yet": 1, "another": 1, "direction": 1, "relate": 1, "work": 1, "lie": 1, "define": 1, "intrinsic": 1, "reward": 1, "single": 1, "agent": 1, "hierarchical": 2, "rl": 1, "enable": 1, "learn": 1, "diverse": 1, "behaviours": 1, "low": 1, "level": 1, "layer": 1, "policy": 1}, {"florensa": 1, "et": 1, "al": 1}, {"10": 1, "use": 1, "hand": 1, "design": 1, "state": 1, "feature": 1, "train": 1, "lower": 1, "layer": 2, "policy": 2, "maximise": 1, "mi": 1, "tune": 1, "network": 1, "upper": 1, "specific": 1, "task": 1}, {"similarly": 1, "14": 1, "8": 1, "learn": 2, "mixture": 1, "diverse": 1, "behaviours": 2, "use": 2, "deep": 1, "neural": 1, "network": 1, "extract": 1, "state": 1, "feature": 1, "mi": 1, "maximisation": 1, "useful": 1, "skills": 1, "without": 1, "reward": 1, "function": 1}, {"maven": 1, "differ": 1, "diayn": 1, "8": 1, "use": 1, "case": 1, "also": 1, "enforce": 1, "action": 2, "diversification": 1, "due": 1, "mi": 1, "maximise": 1, "jointly": 1, "state": 1, "trajectory": 1}, {"hence": 1, "agents": 1, "jointly": 1, "learn": 1, "solve": 1, "task": 1, "many": 1, "different": 1, "ways": 1, "maven": 1, "prevent": 1, "suboptimality": 1, "representational": 1, "constraints": 1, "whereas": 1, "diayn": 1, "concern": 1, "discover": 1, "new": 1, "state": 1}, {"furthermore": 1, "diayn": 1, "train": 2, "diversity": 1, "reward": 1, "use": 1, "rl": 1, "whereas": 1, "via": 1, "gradient": 1, "ascent": 1}, {"haarnoja": 1, "et": 1, "al": 1}, {"18": 1, "use": 2, "normalise": 1, "flow": 1, "41": 1, "learn": 1, "hierarchical": 1, "latent": 2, "space": 2, "policies": 1, "max": 1, "entropy": 1, "rl": 1, "49": 1, "53": 1, "9": 1, "relate": 1, "mi": 1, "maximisation": 1, "ignore": 1, "variational": 1, "posterior": 1, "behaviours": 1}, {"similar": 1, "vein": 1, "21": 1, "38": 1, "use": 1, "auxiliary": 1, "reward": 1, "modify": 1, "rl": 1, "objective": 1, "towards": 1, "better": 1, "tradeoff": 1, "exploration": 1, "exploitation": 1}, {"7": 1, "": 2, "conclusion": 1, "future": 1, "work": 1, "paper": 1, "analyse": 1, "effect": 1, "representational": 1, "constraints": 1, "exploration": 1, "ctde": 1}, {"also": 1, "introduce": 1, "maven": 1, "algorithm": 1, "enable": 1, "commit": 1, "exploration": 1, "obey": 1, "constraints": 1}, {"immediate": 1, "future": 1, "work": 1, "aim": 1, "develop": 1, "theoretical": 1, "analysis": 1, "similar": 1, "qmix": 1, "ctde": 1, "algorithms": 1}, {"would": 1, "also": 1, "like": 1, "carry": 1, "empirical": 1, "evaluations": 1, "maven": 1, "z": 1, "continuous": 1}, {"address": 1, "intractability": 1, "introduce": 1, "use": 2, "continuous": 1, "latent": 1, "variables": 1, "propose": 1, "stateoftheart": 1, "methods": 1, "variational": 1, "inference": 1, "24": 1, "42": 1, "41": 1, "25": 1}, {"yet": 1, "another": 1, "interest": 1, "direction": 1, "would": 1, "condition": 1, "latent": 1, "distribution": 1, "joint": 1, "state": 1, "space": 1, "time": 1, "step": 1, "transmit": 1, "across": 1, "agents": 1, "get": 1, "low": 1, "communication": 1, "cost": 1, "centralise": 1, "execution": 1, "policy": 1, "compare": 1, "merit": 1, "exist": 1, "methods": 1, "45": 1, "11": 1, "23": 1}, {"9": 1, "": 3, "8": 1, "acknowledgements": 1, "generously": 1, "fund": 1, "oxfordgoogle": 1, "deepmind": 1, "graduate": 1, "scholarship": 2, "drapers": 1}, {"tr": 1, "fund": 1, "engineer": 1, "physical": 1, "sciences": 1, "research": 1, "council": 1, "epm5081111": 1, "epn5097111": 1}, {"project": 1, "receive": 1, "fund": 1, "european": 2, "research": 2, "council": 1, "unions": 1, "horizon": 1, "2020": 1, "innovation": 1, "programme": 1, "grant": 1, "agreement": 1, "number": 1, "637713": 1}, {"experiment": 1, "make": 1, "possible": 1, "generous": 1, "equipment": 1, "grant": 2, "nvidia": 1, "cloud": 2, "credit": 1, "oracle": 1, "innovation": 1, "accelerator": 1}, {"reference": 1, "1": 1, "robert": 1, "j": 1, "aumann": 1}, {"subjectivity": 1, "correlation": 1, "randomize": 1, "strategies": 1}, {"journal": 1, "mathematical": 1, "economics": 1, "116796": 1, "1974": 1}, {"2": 1, "david": 1, "barber": 1, "taylan": 1, "cemgil": 1, "silvia": 1, "chiappa": 1}, {"bayesian": 1, "time": 1, "series": 1, "model": 1}, {"cambridge": 1, "university": 1, "press": 1, "2011": 1}, {"3": 1, "christopher": 1, "bishop": 1}, {"pattern": 1, "recognition": 1, "machine": 1, "learn": 1}, {"springer": 1, "2006": 1}, {"4": 1, "stephen": 1, "boyd": 1, "lieven": 1, "vandenberghe": 1}, {"convex": 1, "optimization": 1}, {"cambridge": 1, "university": 1, "press": 1, "2004": 1}, {"5": 1, "lucian": 1, "busoniu": 1, "robert": 1, "babuska": 1, "bart": 1, "de": 1, "schutter": 1}, {"comprehensive": 1, "survey": 1, "multiagent": 1, "reinforcement": 1, "learn": 1}, {"ieee": 1, "transactions": 1, "systems": 1, "man": 1, "cybernetics": 1, "part": 1, "c": 1, "applications": 1, "review": 1, "382156172": 1, "2008": 1}, {"6": 1, "yongcan": 1, "cao": 1, "wenwu": 1, "yu": 1, "wei": 1, "ren": 1, "guanrong": 1, "chen": 1}, {"overview": 1, "recent": 1, "progress": 1, "study": 1, "distribute": 1, "multiagent": 1, "coordination": 1}, {"ieee": 1, "transactions": 1, "industrial": 1, "informatics": 1, "91427438": 1, "2013": 1}, {"7": 1, "maria": 1, "dimakopoulou": 1, "benjamin": 1, "van": 1, "roy": 1}, {"coordinate": 1, "exploration": 1, "concurrent": 1, "reinforcement": 1, "learn": 1}, {"international": 1, "conference": 1, "machine": 1, "learn": 1, "page": 1, "12701278": 1, "2018": 1}, {"8": 1, "benjamin": 1, "eysenbach": 1, "abhishek": 1, "gupta": 1, "julian": 1, "ibarz": 1, "sergey": 1, "levine": 1}, {"diversity": 1, "need": 1, "learn": 1, "skills": 1, "without": 1, "reward": 1, "function": 1}, {"arxiv": 1, "preprint": 1, "arxiv180206070": 1, "2018": 1}, {"9": 1, "matthew": 1, "fellows": 1, "anuj": 1, "mahajan": 1, "tim": 1, "gj": 1, "rudner": 1, "shimon": 1, "whiteson": 1}, {"virel": 1, "variational": 1, "inference": 1, "framework": 1, "reinforcement": 1, "learn": 1}, {"arxiv": 1, "preprint": 1, "arxiv181101132": 1, "2018": 1}, {"10": 1, "carlos": 1, "florensa": 1, "yan": 1, "duan": 1, "pieter": 1, "abbeel": 1}, {"stochastic": 1, "neural": 1, "network": 1, "hierarchical": 1, "reinforcement": 1, "learn": 1}, {"arxiv": 1, "preprint": 1, "arxiv170403012": 1, "2017": 1}, {"11": 1, "jakob": 1, "foerster": 1, "ioannis": 1, "alexandros": 1, "assael": 1, "nando": 1, "de": 1, "freitas": 1, "shimon": 1, "whiteson": 1}, {"learn": 2, "communicate": 1, "deep": 1, "multiagent": 1, "reinforcement": 1}, {"advance": 1, "neural": 1, "information": 1, "process": 1, "systems": 1, "page": 1, "21372145": 1, "2016": 1}, {"12": 1, "jakob": 1, "foerster": 1, "nantas": 1, "nardelli": 1, "gregory": 1, "farquhar": 1, "triantafyllos": 1, "afouras": 1, "philip": 1, "h": 1, "torr": 1, "pushmeet": 1, "kohli": 1, "shimon": 1, "whiteson": 1}, {"stabilise": 1, "experience": 1, "replay": 1, "deep": 1, "multiagent": 1, "reinforcement": 1, "learn": 1}, {"proceed": 1, "34th": 1, "international": 1, "conference": 1, "machine": 1, "learn": 1, "page": 1, "11461155": 1, "2017": 1}, {"13": 1, "jakob": 1, "n": 1, "foerster": 1, "gregory": 1, "farquhar": 1, "triantafyllos": 1, "afouras": 1, "nantas": 1, "nardelli": 1, "shimon": 1, "whiteson": 1}, {"counterfactual": 1, "multiagent": 1, "policy": 1, "gradients": 1}, {"thirtysecond": 1, "aaai": 1, "conference": 1, "artificial": 1, "intelligence": 1, "2018": 1}, {"14": 1, "karol": 1, "gregor": 1, "danilo": 1, "jimenez": 1, "rezende": 1, "daan": 1, "wierstra": 1}, {"variational": 1, "intrinsic": 1, "control": 1}, {"arxiv": 1, "preprint": 1, "arxiv161107507": 1, "2016": 1}, {"15": 1, "christian": 1, "guckelsberger": 1, "christoph": 1, "salge": 1, "julian": 1, "togelius": 1}, {"new": 1, "surprise": 1, "ways": 1, "mean": 1}, {"adversarial": 1, "npcs": 1, "couple": 1, "empowerment": 1, "minimisation": 1}, {"arxiv": 1, "preprint": 1, "arxiv180601387": 1, "2018": 1}, {"10": 1, "": 1, "16": 1, "carlos": 1, "guestrin": 1, "daphne": 1, "koller": 1, "ronald": 1, "parr": 1}, {"multiagent": 1, "plan": 1, "factor": 1, "mdps": 1}, {"advance": 1, "neural": 1, "information": 1, "process": 1, "systems": 1, "page": 1, "15231530": 1}, {"mit": 1, "press": 1, "2002": 1}, {"17": 1, "carlos": 1, "guestrin": 1, "daphne": 1, "koller": 1, "ronald": 1, "parr": 1, "shobha": 1, "venkataraman": 1}, {"efficient": 1, "solution": 1, "algorithms": 1, "factor": 1, "mdps": 1}, {"journal": 1, "artificial": 1, "intelligence": 1, "research": 1, "19399468": 1, "2003": 1}, {"18": 1, "tuomas": 1, "haarnoja": 1, "kristian": 1, "hartikainen": 1, "pieter": 1, "abbeel": 1, "sergey": 1, "levine": 1}, {"latent": 1, "space": 1, "policies": 1, "hierarchical": 1, "reinforcement": 1, "learn": 1}, {"arxiv": 1, "preprint": 1, "arxiv180402808": 1, "2018": 1}, {"19": 1, "matthew": 1, "hausknecht": 1, "peter": 1, "stone": 1}, {"deep": 1, "recurrent": 1, "qlearning": 1, "partially": 1, "observable": 1, "mdps": 1}, {"aaai": 1, "fall": 1, "symposium": 1, "sequential": 1, "decision": 1, "make": 1, "intelligent": 1, "agents": 1, "2015": 1}, {"20": 1, "sepp": 1, "hochreiter": 1, "jrgen": 1, "schmidhuber": 1}, {"long": 1, "shortterm": 1, "memory": 1}, {"neural": 1, "computation": 1, "9817351780": 1, "1997": 1}, {"21": 1, "rein": 1, "houthooft": 1, "xi": 1, "chen": 1, "yan": 1, "duan": 1, "john": 1, "schulman": 1, "filip": 1, "de": 1, "turck": 1, "pieter": 1, "abbeel": 1}, {"vime": 1, "variational": 1, "information": 1, "maximize": 1, "exploration": 1}, {"advance": 1, "neural": 1, "information": 1, "process": 1, "systems": 1, "page": 1, "11091117": 1, "2016": 1}, {"22": 1, "maximilian": 1, "httenrauch": 1, "adrian": 1, "oic": 1, "gerhard": 1, "neumann": 1}, {"guide": 1, "deep": 1, "reinforcement": 1, "learn": 1, "swarm": 1, "systems": 1}, {"aamas": 1, "2017": 2, "autonomous": 1, "robots": 1, "multirobot": 1, "systems": 1, "arm": 1, "workshop": 1}, {"23": 1, "jiechuan": 1, "jiang": 1, "zongqing": 1, "lu": 1}, {"learn": 1, "attentional": 1, "communication": 1, "multiagent": 1, "cooperation": 1}, {"advance": 1, "neural": 1, "information": 1, "process": 1, "systems": 1, "page": 1, "72547264": 1, "2018": 1}, {"24": 1, "diederik": 1, "p": 1, "kingma": 1, "max": 1, "well": 1}, {"stochastic": 1, "gradient": 1, "vb": 1, "variational": 1, "autoencoder": 1}, {"second": 1, "international": 1, "conference": 1, "learn": 1, "representations": 1, "iclr": 1, "2014": 1}, {"25": 1, "durk": 1, "p": 1, "kingma": 1, "tim": 1, "salimans": 1, "rafal": 1, "jozefowicz": 1, "xi": 1, "chen": 1, "ilya": 1, "sutskever": 1, "max": 1, "well": 1}, {"improve": 1, "variational": 1, "inference": 1, "inverse": 1, "autoregressive": 1, "flow": 1}, {"advance": 1, "neural": 1, "information": 1, "process": 1, "systems": 1, "page": 1, "47434751": 1, "2016": 1}, {"26": 1, "landon": 1, "kraemer": 1, "bikramjit": 1, "banerjee": 1}, {"multiagent": 1, "reinforcement": 1, "learn": 1, "rehearsal": 1, "decentralize": 1, "plan": 1}, {"neurocomputing": 1, "1908294": 1, "2016": 1}, {"27": 1, "alex": 1, "tong": 1, "lin": 1, "mark": 1, "j": 1, "debord": 1, "katia": 1, "estabridis": 1, "gary": 1, "hewer": 1, "stanley": 1, "osher": 1}, {"cesma": 1, "centralize": 1, "expert": 1, "supervise": 1, "multiagents": 1}, {"arxiv": 1, "preprint": 1, "arxiv190202311": 1, "2019": 1}, {"28": 1, "ryan": 1, "lowe": 1, "yi": 1, "wu": 1, "aviv": 1, "tamar": 1, "jean": 1, "harb": 1, "openai": 1, "pieter": 1, "abbeel": 1, "igor": 1, "mordatch": 1}, {"multiagent": 1, "actorcritic": 1, "mix": 1, "cooperativecompetitive": 1, "environments": 1}, {"advance": 1, "neural": 1, "information": 1, "process": 1, "systems": 1, "page": 1, "63796390": 1, "2017": 1}, {"29": 1, "laurens": 1, "van": 1, "der": 1, "maaten": 1, "geoffrey": 1, "hinton": 1}, {"visualize": 1, "data": 1, "use": 1, "tsne": 1}, {"journal": 1, "machine": 1, "learn": 1, "research": 1, "9nov25792605": 1, "2008": 1}, {"30": 1, "anuj": 1, "mahajan": 1, "theja": 1, "tulabandhula": 1}, {"symmetry": 1, "detection": 1, "exploitation": 1, "function": 1, "approximation": 1, "deep": 1, "rl": 1}, {"proceed": 1, "16th": 1, "conference": 1, "autonomous": 1, "agents": 1, "multiagent": 1, "systems": 1, "page": 1, "16191621": 1}, {"international": 1, "foundation": 1, "autonomous": 1, "agents": 1, "multiagent": 1, "systems": 1, "2017": 1}, {"31": 1, "anuj": 1, "mahajan": 1, "theja": 1, "tulabandhula": 1}, {"symmetry": 1, "learn": 2, "function": 1, "approximation": 1, "reinforcement": 1}, {"arxiv": 1, "preprint": 1, "arxiv170602999": 1, "2017": 1}, {"32": 1, "andriy": 1, "mnih": 1, "karol": 1, "gregor": 1}, {"neural": 1, "variational": 1, "inference": 1, "learn": 1, "belief": 1, "network": 1}, {"arxiv": 1, "preprint": 1, "arxiv14020030": 1, "2014": 1}, {"33": 1, "volodymyr": 1, "mnih": 1, "koray": 1, "kavukcuoglu": 1, "david": 1, "silver": 1, "alex": 1, "grave": 1, "ioannis": 1, "antonoglou": 1, "daan": 1, "wierstra": 1, "martin": 1, "riedmiller": 1}, {"play": 1, "atari": 1, "deep": 1, "reinforcement": 1, "learn": 1}, {"arxiv": 1, "preprint": 1, "arxiv13125602": 1, "2013": 1}, {"34": 1, "frans": 1, "oliehoek": 1, "christopher": 1, "amato": 1}, {"concise": 1, "introduction": 1, "decentralize": 1, "pomdps": 1}, {"springerbriefs": 1, "intelligent": 1, "systems": 1}, {"springer": 1, "2016": 1}, {"11": 1, "": 1, "35": 1, "shayegan": 1, "omidshafiei": 1, "jason": 1, "pazis": 1, "christopher": 1, "amato": 1, "jonathan": 1, "p": 1, "john": 1, "vian": 1}, {"deep": 1, "decentralize": 1, "multitask": 1, "multiagent": 1, "rl": 1, "partial": 1, "observability": 1}, {"proceed": 1, "34th": 1, "international": 1, "conference": 1, "machine": 1, "learn": 1, "page": 1, "26812690": 1, "2017": 1}, {"36": 1, "ian": 1, "osband": 1, "charles": 1, "blundell": 1, "alexander": 1, "pritzel": 1, "benjamin": 1, "van": 1, "roy": 1}, {"deep": 1, "exploration": 1, "via": 1, "bootstrapped": 1, "dqn": 1}, {"advance": 1, "neural": 1, "information": 1, "process": 1, "systems": 1, "page": 1, "40264034": 1, "2016": 1}, {"37": 1, "ian": 1, "osband": 1, "benjamin": 1, "van": 1, "roy": 1, "daniel": 1, "russo": 1, "zheng": 1, "wen": 1}, {"deep": 1, "exploration": 1, "via": 1, "randomize": 1, "value": 1, "function": 1}, {"arxiv": 1, "preprint": 1, "arxiv170307608": 1, "2017": 1}, {"38": 1, "deepak": 1, "pathak": 1, "pulkit": 1, "agrawal": 1, "alexei": 1, "efros": 1, "trevor": 1, "darrell": 1}, {"curiositydriven": 1, "exploration": 1, "selfsupervised": 1, "prediction": 1}, {"icml": 1, "2017": 1}, {"39": 1, "peng": 2, "ying": 1, "wen": 1, "yaodong": 1, "yang": 1, "quan": 1, "yuan": 1, "zhenkun": 1, "tang": 1, "haitao": 1, "long": 1, "jun": 1, "wang": 1}, {"multiagent": 1, "bidirectionallycoordinated": 1, "net": 1, "emergence": 1, "humanlevel": 1, "coordination": 1, "learn": 1, "play": 1, "starcraft": 1, "combat": 1, "game": 1}, {"arxiv": 1, "preprint": 1, "arxiv170310069": 1, "2017": 1}, {"40": 1, "tabish": 1, "rashid": 1, "mikayel": 1, "samvelyan": 1, "christian": 1, "schroeder": 1, "de": 1, "witt": 1, "gregory": 1, "farquhar": 1, "jakob": 1, "foerster": 1, "shimon": 1, "whiteson": 1}, {"qmix": 1, "monotonic": 1, "value": 1, "function": 1, "factorisation": 1, "deep": 1, "multiagent": 1, "reinforcement": 1, "learn": 1}, {"proceed": 1, "35th": 1, "international": 1, "conference": 1, "machine": 1, "learn": 1, "page": 1, "42954304": 1, "2018": 1}, {"41": 1, "danilo": 1, "jimenez": 1, "rezende": 1, "shakir": 1, "mohamed": 1}, {"variational": 1, "inference": 1, "normalize": 1, "flow": 1}, {"arxiv": 1, "preprint": 1, "arxiv150505770": 1, "2015": 1}, {"42": 1, "danilo": 1, "jimenez": 1, "rezende": 1, "shakir": 1, "mohamed": 1, "daan": 1, "wierstra": 1}, {"stochastic": 1, "backpropagation": 1, "approximate": 1, "inference": 1, "deep": 1, "generative": 1, "model": 1}, {"arxiv": 1, "preprint": 1, "arxiv14014082": 1, "2014": 1}, {"43": 1, "mikayel": 1, "samvelyan": 1, "tabish": 1, "rashid": 1, "christian": 1, "schroeder": 1, "de": 1, "witt": 1, "gregory": 1, "farquhar": 1, "nantas": 1, "nardelli": 1, "tim": 1, "gj": 1, "rudner": 1, "chiaman": 1, "hang": 1, "philip": 1, "hs": 1, "torr": 1, "jakob": 1, "foerster": 1, "shimon": 1, "whiteson": 1}, {"starcraft": 1, "multiagent": 1, "challenge": 1}, {"proceed": 1, "18th": 1, "international": 1, "conference": 1, "autonomous": 1, "agents": 1, "multiagent": 1, "systems": 1, "2019": 1}, {"44": 1, "kyunghwan": 1, "son": 1, "daewoo": 1, "kim": 1, "wan": 1, "ju": 1, "kang": 1, "david": 1, "earl": 1, "hostallero": 1, "yung": 1, "yi": 1}, {"qtran": 1, "learn": 2, "factorize": 1, "transformation": 1, "cooperative": 1, "multiagent": 1, "reinforcement": 1}, {"arxiv": 1, "preprint": 1, "arxiv190505408": 1, "2019": 1}, {"45": 1, "sainbayar": 1, "sukhbaatar": 1, "rob": 1, "fergus": 1, "et": 1, "al": 1}, {"learn": 1, "multiagent": 1, "communication": 1, "backpropagation": 1}, {"advance": 1, "neural": 1, "information": 1, "process": 1, "systems": 1, "page": 1, "22442252": 1, "2016": 1}, {"46": 1, "peter": 1, "sunehag": 1, "guy": 1, "lever": 1, "audrunas": 1, "gruslys": 1, "wojciech": 1, "marian": 1, "czarnecki": 1, "vinicius": 1, "zambaldi": 1, "max": 1, "jaderberg": 1, "marc": 1, "lanctot": 1, "nicolas": 1, "sonnerat": 1, "joel": 1, "z": 1, "leibo": 1, "karl": 1, "tuyls": 1, "et": 1, "al": 1}, {"valuedecomposition": 1, "network": 1, "cooperative": 1, "multiagent": 1, "learn": 1}, {"arxiv": 1, "preprint": 1, "arxiv170605296": 1, "2017": 1}, {"47": 1, "ardi": 1, "tampuu": 1, "tambet": 1, "matiisen": 1, "dorian": 1, "kodelja": 1, "ilya": 1, "kuzovkin": 1, "kristjan": 1, "korjus": 1, "juhan": 1, "aru": 2, "jaan": 1, "raul": 1, "vicente": 1}, {"multiagent": 1, "cooperation": 1, "competition": 1, "deep": 1, "reinforcement": 1, "learn": 1}, {"plos": 1, "one": 1, "2017": 1}, {"48": 1, "ming": 1, "tan": 1}, {"multiagent": 1, "reinforcement": 1, "learn": 1, "independent": 1, "vs": 1, "cooperative": 1, "agents": 1}, {"proceed": 1, "tenth": 1, "international": 1, "conference": 1, "machine": 1, "learn": 1, "page": 1, "330337": 1, "1993": 1}, {"49": 1, "emanuel": 1, "todorov": 1}, {"linearlysolvable": 1, "markov": 1, "decision": 1, "problems": 1}, {"advance": 1, "neural": 1, "information": 1, "process": 1, "systems": 1, "page": 1, "13691376": 1, "2007": 1}, {"50": 1, "martin": 1, "j": 1, "wainwright": 1, "michael": 1, "jordan": 1, "et": 1, "al": 1}, {"graphical": 1, "model": 1, "exponential": 1, "families": 1, "variational": 1, "inference": 1}, {"foundations": 1, "trend": 1, "r": 1, "machine": 1, "learn": 1, "1121305": 1, "2008": 1}, {"51": 1, "erfu": 1, "yang": 1, "dongbing": 1, "gu": 1}, {"multiagent": 1, "reinforcement": 1, "learn": 1, "multirobot": 1, "systems": 1, "survey": 1}, {"technical": 1, "report": 1, "university": 1, "strathclyde": 1, "2004": 1}, {"52": 1, "stephan": 1, "zheng": 1, "yisong": 1, "yue": 1}, {"structure": 1, "exploration": 1, "via": 1, "hierarchical": 1, "variational": 1, "policy": 1, "network": 1}, {"openreview": 1, "2018": 1}, {"53": 1, "brian": 1, "ziebart": 1, "andrew": 2, "l": 1, "maas": 1, "j": 1, "bagnell": 1, "anind": 1, "k": 1, "dey": 1}, {"maximum": 1, "entropy": 1, "inverse": 1, "reinforcement": 1, "learn": 1}, {"aaai": 1, "volume": 1, "8": 1, "page": 1, "14331438": 1}, {"chicago": 1, "il": 1, "usa": 1, "2008": 1}, {"12": 1}]