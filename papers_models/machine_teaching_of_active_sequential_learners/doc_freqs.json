[{"machine": 2, "teach": 2, "active": 1, "sequential": 1, "learners": 1, "": 5, "tomi": 1, "peltola": 1, "tomipeltolaaaltofi": 1, "mustafa": 1, "mert": 1, "elikok": 1, "mustafacelikokaaltofi": 1, "pedram": 1, "daee": 1, "pedramdaeeaaltofi": 1, "samuel": 1, "kaski": 1, "samuelkaskiaaltofi": 1, "helsinki": 2, "institute": 1, "information": 1, "technology": 1, "hiit": 1, "department": 1, "computer": 1, "science": 1, "aalto": 1, "university": 1, "finland": 1, "abstract": 1, "address": 1, "problem": 1, "find": 1, "best": 1, "train": 1, "data": 1, "guide": 1, "learn": 1, "algorithm": 1, "target": 1, "model": 1, "minimal": 1, "effort": 1}, {"conventional": 1, "settings": 1, "teacher": 1, "provide": 1, "data": 2, "consistent": 1, "true": 1, "distribution": 1}, {"however": 1, "sequential": 1, "learners": 3, "actively": 1, "choose": 1, "query": 2, "multiarmed": 1, "bandits": 1, "active": 1, "teacher": 1, "provide": 1, "responses": 1, "design": 1, "full": 1, "data": 1}, {"set": 1, "consistent": 1, "teachers": 1, "suboptimal": 1, "finite": 1, "horizons": 1}, {"formulate": 1, "sequential": 1, "teach": 2, "problem": 1, "current": 1, "techniques": 1, "machine": 1, "address": 1, "markov": 1, "decision": 1, "process": 1, "dynamics": 1, "nest": 1, "model": 1, "learner": 1, "action": 1, "teachers": 1, "responses": 1}, {"furthermore": 1, "address": 1, "complementary": 1, "problem": 1, "learn": 1, "teacher": 2, "plan": 1, "recognise": 1, "teach": 1, "intent": 1, "responses": 1, "learner": 1, "endow": 1, "model": 1}, {"test": 1, "formulation": 1, "multiarmed": 1, "bandit": 1, "learners": 1, "simulate": 1, "experiment": 1, "user": 1, "study": 1}, {"result": 1, "show": 1, "learn": 1, "improve": 1, "plan": 1, "teach": 1, "ii": 1, "learner": 1, "model": 1, "teacher": 1}, {"approach": 1, "give": 1, "tool": 1, "take": 1, "account": 1, "strategic": 1, "plan": 1, "behaviour": 1, "users": 1, "interactive": 1, "intelligent": 1, "systems": 1, "recommendation": 1, "engines": 1, "consider": 1, "boundedly": 1, "optimal": 1, "teachers": 1}, {"1": 1, "": 2, "introduction": 1, "humans": 1, "casual": 1, "users": 1, "domain": 1, "experts": 1, "alike": 1, "increasingly": 1, "interact": 1, "artificial": 1, "intelligence": 1, "machine": 1, "learn": 1, "base": 1, "systems": 1}, {"number": 1, "interactions": 1, "humancomputer": 1, "type": 1, "agentagent": 1, "interaction": 1, "usually": 1, "limit": 1, "systems": 1, "often": 1, "base": 1, "active": 2, "sequential": 1, "machine": 1, "learn": 2, "methods": 1, "multiarmed": 1, "bandits": 1, "bayesian": 1, "optimization": 1}, {"methods": 1, "explicitly": 1, "optimise": 1, "efficiency": 1, "interaction": 1, "systems": 1, "perspective": 1}, {"hand": 1, "goaloriented": 1, "task": 1, "humans": 1, "create": 1, "mental": 1, "model": 1, "environment": 1, "plan": 1, "action": 1, "achieve": 1, "goals": 1, "1": 1, "2": 1}, {"ai": 1, "systems": 1, "recent": 1, "research": 1, "show": 1, "users": 1, "form": 1, "mental": 1, "model": 1, "ais": 1, "state": 1, "behaviour": 1, "3": 1, "4": 1}, {"yet": 1, "statistical": 1, "model": 1, "underlie": 1, "active": 1, "sequential": 1, "machine": 1, "learn": 1, "methods": 1, "treat": 1, "human": 1, "action": 1, "passive": 1, "data": 1, "rather": 1, "acknowledge": 1, "strategic": 1, "think": 1, "user": 1}, {"machine": 2, "teach": 1, "study": 1, "complementary": 1, "problem": 1, "active": 1, "learn": 2, "provide": 1, "learner": 1, "data": 1, "target": 1, "model": 1, "minimal": 1, "effort": 1, "57": 1}, {"apart": 1, "fundamental": 1, "machine": 2, "learn": 1, "interest": 1, "teach": 1, "apply": 1, "domains": 1, "education": 1, "8": 1, "adversarial": 1, "attack": 1, "9": 1}, {"paper": 1, "study": 1, "machine": 2, "teach": 1, "problem": 1, "active": 1, "sequential": 1, "learners": 1, "learner": 1, "sequentially": 1, "choose": 1, "query": 1, "teacher": 1, "provide": 1, "responses": 1}, {"importantly": 1, "steer": 1, "learner": 1, "towards": 1, "teach": 1, "goal": 1, "teacher": 1, "need": 1, "appreciate": 1, "order": 1, "learners": 1, "query": 1, "effect": 1, "responses": 1}, {"current": 1, "techniques": 1, "machine": 1, "teach": 1, "33rd": 1, "conference": 1, "neural": 1, "information": 1, "process": 1, "systems": 1, "neurips": 1, "2019": 1, "vancouver": 1, "canada": 1}, {"address": 1, "interaction": 1}, {"furthermore": 1, "view": 1, "users": 2, "boundedly": 1, "optimal": 1, "teachers": 2, "solve": 1, "inverse": 1, "machine": 1, "teach": 1, "problem": 1, "learn": 1, "responses": 1, "approach": 1, "provide": 1, "way": 1, "formulate": 1, "model": 1, "strategically": 1, "plan": 1, "interactive": 1, "ai": 1, "systems": 1}, {"main": 1, "contributions": 1, "formulate": 2, "problem": 1, "machine": 1, "teach": 1, "active": 1, "sequential": 1, "learners": 2, "plan": 1, "markov": 1, "decision": 1, "process": 1, "ii": 1, "learn": 2, "teachers": 1, "responses": 1, "probabilistic": 1, "inverse": 1, "reinforcement": 1, "iii": 1, "implement": 1, "approach": 1, "bayesian": 1, "bernoulli": 1, "multiarmed": 1, "bandit": 1, "arm": 1, "dependencies": 1, "iv": 1, "empirically": 1, "study": 2, "performance": 1, "simulate": 1, "settings": 1, "user": 1}, {"source": 1, "code": 1, "available": 1, "httpsgithub": 1}, {"comaaltopmlmachineteachingofactivesequentiallearners": 1}, {"2": 1, "": 2, "relate": 1, "work": 2, "machine": 1, "teach": 1, "consider": 1, "batch": 1, "set": 1, "teacher": 1, "design": 1, "minimal": 1, "dataset": 1, "make": 1, "learner": 1, "learn": 1, "target": 1, "model": 1, "57": 1}, {"work": 1, "also": 1, "study": 1, "sequential": 1, "teach": 2, "different": 1, "settings": 1, "methods": 1, "develop": 1, "construct": 1, "batch": 1, "stateaction": 1, "trajectories": 1, "inverse": 1, "reinforcement": 1, "learners": 1, "10": 1, "11": 1}, {"variations": 1, "teach": 1, "online": 1, "learners": 1, "gradient": 1, "descent": 1, "algorithms": 1, "provide": 1, "sequence": 1, "x": 1, "data": 1, "point": 1, "also": 1, "consider": 1, "1214": 1}, {"teach": 1, "context": 1, "education": 1, "uncertainty": 1, "learners": 1, "state": 1, "formulate": 1, "plan": 1, "partiallyobservable": 1, "markov": 1, "decision": 1, "process": 1, "8": 1, "15": 1}, {"theoretical": 1, "study": 1, "teacheraware": 1, "learners": 1, "present": 1, "16": 1, "17": 1, "teacher": 1, "learner": 1, "aware": 1, "cooperation": 1}, {"compare": 1, "set": 1, "work": 1, "teacher": 1, "control": 1, "design": 1, "learn": 1, "data": 2, "possibly": 1, "use": 1, "interaction": 1, "probe": 1, "state": 1, "learner": 1, "allow": 1, "inconsistent": 1, "regard": 1, "true": 1, "distribution": 1}, {"apart": 1, "11": 1, "16": 1, "17": 1, "also": 1, "consider": 1, "teacheraware": 1, "learners": 1}, {"machine": 1, "teach": 1, "also": 1, "use": 1, "towards": 1, "attack": 2, "learn": 1, "systems": 1, "9": 1, "adversarial": 1, "multiarmed": 1, "bandits": 1, "develop": 1, "poison": 1, "historical": 1, "data": 1, "18": 1, "modify": 1, "reward": 1, "online": 1, "19": 1}, {"goal": 1, "settings": 1, "propose": 1, "methods": 1, "differ": 1}, {"relatedly": 1, "teach": 1, "approach": 1, "case": 1, "bandit": 1, "learner": 1, "see": 1, "form": 1, "reward": 1, "shape": 1, "aim": 1, "make": 1, "environment": 1, "supportive": 1, "reinforcement": 1, "learn": 1, "alleviate": 1, "temporal": 1, "credit": 1, "assignment": 1, "problem": 1, "20": 1}, {"propose": 1, "model": 2, "interaction": 1, "teacher": 1, "active": 1, "sequential": 1, "learner": 1, "probabilistic": 1, "multiagent": 1}, {"connect": 1, "overarch": 1, "framework": 1, "interactive": 1, "partially": 1, "observable": 1, "markov": 1, "decision": 1, "process": 1, "ipomdps": 1, "see": 1, "supplementary": 1, "section": 1, "1": 1, "detail": 1, "21": 1, "relate": 1, "multiagent": 1, "model": 1, "2225": 1}, {"ipomdps": 1, "provide": 1, "principled": 1, "decisiontheoretic": 1, "framework": 1, "general": 1, "approach": 1, "define": 1, "multiagent": 1, "model": 1, "recursive": 1, "beliefs": 1, "agents": 1}, {"also": 1, "form": 1, "rich": 1, "basis": 1, "computational": 1, "model": 1, "theory": 1, "mind": 1, "ability": 1, "attribute": 1, "mental": 1, "state": 1, "beliefs": 1, "desire": 1, "oneself": 1, "agents": 1, "essential": 1, "efficient": 1, "social": 1, "collaboration": 1, "26": 1, "27": 1}, {"teach": 1, "problem": 1, "nest": 1, "model": 2, "teacherunaware": 1, "learner": 1, "form": 1, "learnerteacher": 1}, {"teachingaware": 1, "learn": 1, "add": 1, "layer": 1, "form": 1, "nest": 1, "learnerteacherlearner": 1, "model": 3, "higher": 1, "level": 1, "learner": 2, "teacher": 1, "teachingunaware": 1}, {"learn": 1, "humans": 1, "recursive": 1, "reason": 1, "opine": 1, "28": 1}, {"knowledge": 1, "work": 1, "first": 1, "propose": 1, "multiagent": 1, "recursive": 1, "reason": 1, "model": 1, "practically": 1, "important": 1, "case": 1, "multiarmed": 1, "bandits": 1, "allow": 1, "us": 1, "learn": 1, "online": 1, "scarce": 1, "data": 1, "emerge": 1, "humancomputer": 1, "interaction": 1}, {"user": 2, "model": 1, "humancomputer": 2, "interaction": 1, "aim": 1, "improve": 1, "usability": 1, "usefulness": 1, "collaborative": 1, "systems": 1, "provide": 1, "personalise": 1, "experience": 1, "29": 1}, {"machine": 1, "learn": 1, "base": 1, "interactive": 1, "systems": 1, "extend": 1, "user": 1, "model": 2, "encompass": 1, "statistical": 1, "interpret": 1, "users": 1, "action": 1}, {"example": 1, "information": 1, "exploration": 1, "discovery": 1, "system": 1, "need": 1, "iteratively": 1, "recommend": 1, "items": 1, "user": 2, "update": 1, "recommendations": 1, "base": 1, "feedback": 1, "30": 1, "31": 1}, {"current": 1, "underlie": 1, "statistical": 1, "model": 1, "use": 1, "users": 1, "response": 1, "systems": 1, "query": 1, "like": 1, "movie": 1, "data": 1, "build": 1, "relevance": 1, "profile": 1, "user": 1}, {"recent": 1, "work": 2, "investigate": 1, "advance": 1, "user": 2, "model": 4, "32": 1, "33": 1, "however": 1, "far": 1, "know": 1, "previous": 1, "propose": 1, "statistical": 1, "incorporate": 1, "users": 1, "mental": 1, "system": 1}, {"finally": 1, "approach": 1, "ground": 1, "computational": 2, "rationality": 1, "model": 1, "human": 1, "behaviour": 1, "decision": 1, "make": 1, "uncertainty": 1, "expect": 1, "utility": 1, "maximisation": 1, "subject": 1, "constraints": 1, "34": 1}, {"model": 1, "assume": 1, "teacher": 1, "choose": 1, "action": 1, "proportional": 1, "likelihood": 1, "maximise": 1, "limit": 1, "horizon": 1, "future": 1, "accumulate": 1, "utility": 1}, {"2": 1, "": 3, "3": 1, "model": 1, "computation": 1, "consider": 1, "machine": 1, "teach": 1, "active": 1, "sequential": 1, "learner": 2, "iterations": 1, "consist": 1, "query": 1, "input": 1, "point": 1, "x": 1, "teacher": 1, "provide": 1, "response": 1}, {"first": 1, "teach": 2, "problem": 1, "formulate": 1, "markov": 1, "decision": 1, "process": 1, "solution": 1, "provide": 1, "policy": 1}, {"learn": 2, "responses": 1, "provide": 1, "teacher": 1, "formulate": 1, "inverse": 1, "reinforcement": 1, "problem": 1}, {"formulate": 1, "approach": 1, "general": 1, "learners": 1, "give": 1, "detail": 1, "implementation": 1, "specific": 1, "case": 1, "bayesian": 1, "bernoulli": 1, "multiarmed": 1, "bandit": 1, "learner": 1, "model": 1, "arm": 1, "dependencies": 1}, {"31": 1, "": 2, "active": 2, "sequential": 2, "learn": 1, "consider": 2, "machine": 1, "teach": 1, "first": 1, "define": 1, "type": 1, "learners": 1}, {"also": 1, "provide": 1, "baseline": 1, "teachers": 1, "performance": 1, "compare": 1}, {"general": 1, "definition": 1, "encompass": 1, "multiple": 1, "popular": 1, "sequential": 1, "learn": 2, "approach": 1, "include": 1, "bayesian": 1, "optimisation": 1, "multiarmed": 1, "bandits": 1, "aim": 1, "fast": 1, "query": 1}, {"active": 1, "sequential": 1, "learner": 1, "define": 1, "machine": 1, "learn": 2, "model": 1, "relate": 1, "response": 1, "input": 1, "x": 3, "function": 1, "f": 2, "": 11, "parameterised": 1, "conditional": 1, "distribution": 1, "py": 1, "ii": 1, "deterministic": 1, "algorithm": 1, "fit": 1, "parameters": 1, "posterior": 1, "p": 1, "give": 1, "dataset": 1, "x1": 1, "y1": 1}, {"": 1}, {"": 1}, {"": 3, "xt": 1, "yt": 1, "iii": 1, "query": 2, "function": 1, "possibly": 1, "stochastically": 1, "choose": 1, "input": 1, "point": 1, "x": 1, "response": 1, "usually": 1, "formulate": 1, "utility": 1, "maximisation": 1}, {"dynamics": 1, "learn": 1, "process": 1, "": 2, "1": 1}, {"": 1}, {"": 1}, {"": 2, "consist": 1, "iterate": 1, "follow": 1, "step": 1, "1": 1}, {"use": 1, "query": 2, "function": 1, "choose": 1, "xt": 1, "": 1}, {"2": 1}, {"obtain": 1, "response": 1, "yt": 1, "query": 1, "xt": 1, "teacher": 1, "information": 1, "source": 1}, {"3": 1}, {"update": 1, "train": 1, "set": 1, "dt": 1, "": 4, "dt1": 1, "xt": 1, "yt": 1, "model": 1, "correspondingly": 1}, {"data": 1, "produce": 1, "dynamics": 1, "form": 1, "sequence": 1, "history": 1, "ht": 1, "": 6, "x1": 1, "y1": 1, "x2": 1, "y2": 1}, {"": 1}, {"": 1}, {"": 3, "xt": 2, "define": 1, "history": 1, "end": 1, "input": 1, "yt": 1, "notational": 1, "convenience": 1, "follow": 1}, {"bayesian": 2, "bernoulli": 2, "multiarmed": 1, "bandit": 1, "learner": 1, "main": 1, "application": 1, "paper": 1, "consider": 1, "bandits": 1}, {"iteration": 1, "learner": 1, "choose": 1, "arm": 1, "": 2, "1": 1}, {"": 1}, {"": 1}, {"": 2, "k": 1, "receive": 1, "stochastic": 1, "reward": 1, "yt": 1, "0": 1, "1": 1, "depend": 1, "choose": 1, "arm": 1}, {"goal": 1, "learner": 1, "pt": 1, "maximise": 1, "expect": 1, "accumulate": 1, "reward": 1, "rt": 1, "": 2, "e": 1, "t1": 1, "yt": 1}, {"present": 1, "exploration": 1, "exploitation": 1, "problem": 1, "learner": 1, "need": 1, "learn": 1, "arm": 1, "produce": 1, "reward": 1, "high": 1, "probability": 1}, {"learner": 1, "associate": 1, "arm": 1, "k": 4, "feature": 1, "vector": 2, "xk": 1, "": 13, "rm": 1, "model": 1, "reward": 2, "bernoullidistributed": 1, "binary": 1, "random": 1, "variables": 1, "pb": 1, "yt": 1, "bernoulliyt": 1, "1": 2, "probabilities": 1, "xt": 1, "weight": 1}, {"": 1}, {"": 1}, {"": 3, "k": 1, "r": 1, "logistic": 1, "sigmoid": 1, "function": 1}, {"linearity": 1, "assumption": 1, "could": 1, "relax": 1, "example": 1, "encode": 1, "xk": 1, "use": 1, "suitable": 1, "basis": 1, "function": 1, "gaussian": 1, "process": 1}, {"bayesian": 1, "learner": 1, "prior": 1, "distribution": 1, "model": 1, "parameters": 1, "assume": 1, "multivariate": 1, "normal": 1, "": 4, "n0": 1, "2": 2, "mean": 1, "zero": 1, "diagonal": 1, "covariance": 1, "matrix": 1}, {"give": 1, "collect": 1, "set": 1, "arm": 1, "selections": 1, "reward": 1, "observations": 1, "step": 1, "dt": 1, "": 4, "i1": 1, "y1": 1}, {"": 1}, {"": 1}, {"": 9, "yt": 2, "equivalently": 1, "dt": 2, "ht": 1, "posterior": 1, "distribution": 1, "p": 1, "compute": 1}, {"learner": 1, "use": 1, "bandit": 1, "arm": 2, "selection": 1, "strategy": 1, "select": 1, "next": 1, "query": 1}, {"use": 2, "thompson": 1, "sample": 1, "35": 1, "practical": 1, "empirically": 1, "theoretically": 1, "wellperforming": 1, "algorithm": 1, "36": 1, "methods": 1, "could": 1, "easily": 1, "instead": 1}, {"next": 1, "arm": 2, "sample": 1, "probabilities": 1, "proportional": 1, "maximise": 1, "expect": 1, "reward": 1, "estimate": 1, "current": 1, "posterior": 1, "distribution": 1, "z": 1, "prit1": 1, "": 6, "k": 2, "iarg": 1, "max": 1, "j": 2, "p": 1, "dt": 1, "2": 1, "indicator": 1, "function": 1}, {"realise": 1, "first": 1, "sample": 1, "weight": 1, "vector": 1, "": 8, "p": 1, "dt": 1, "compute": 1, "correspond": 1, "choose": 1, "arm": 1, "maximal": 1, "reward": 1, "probability": 1, "it1": 1, "arg": 1, "maxk": 1, "k": 1}, {"3": 1, "": 18, "full": 2, "data": 1, "pool": 2, "fit": 1, "without": 2, "teacher": 4, "10": 2, "accuracy": 1, "09": 1, "08": 1, "07": 1, "grind": 1, "truth": 1, "random": 1, "query": 1, "baseline": 1, "active": 3, "learner": 3, "06": 1, "0": 1, "2": 1, "4": 1, "step": 1, "6": 1, "8": 1, "figure": 1, "1": 1, "example": 1, "teach": 1, "effect": 1, "poolbased": 1, "logistic": 1, "regression": 1}, {"use": 1, "uncertainty": 1, "sample": 2, "query": 1, "learner": 1, "fail": 1, "useful": 1, "point": 1, "pool": 1, "10": 1, "iterations": 1, "learn": 1, "good": 1, "decision": 1, "boundary": 1, "without": 1, "teacher": 1, "start": 1, "blue": 1, "train": 1, "data": 1}, {"plan": 1, "teacher": 2, "help": 1, "learner": 1, "sample": 1, "representative": 1, "point": 1, "switch": 2, "label": 2, "show": 1, "red": 1}, {"average": 1, "accuracy": 1, "improvement": 1, "show": 1, "right": 1, "panel": 1}, {"detail": 1, "set": 1, "give": 1, "supplementary": 1, "section": 1, "2": 1}, {"32": 1, "": 3, "machine": 1, "teach": 1, "active": 2, "sequential": 2, "learner": 1, "reward": 1, "probability": 1, "standard": 1, "learn": 1, "responses": 1, "yt": 1, "assume": 1, "generate": 1, "stationary": 1, "datagenerating": 1, "mechanism": 1, "independent": 1, "identically": 1, "distribute": 1, "sample": 1}, {"call": 1, "mechanism": 1, "naive": 1, "teacher": 1}, {"machine": 1, "teach": 2, "formulation": 1, "replace": 1, "plan": 1, "teacher": 1, "choose": 1, "yt": 1, "carefully": 1, "aim": 1, "steer": 1, "learner": 1, "towards": 1, "goal": 1, "minimal": 1, "effort": 1}, {"10": 2, "05": 1, "00": 1, "": 2, "1": 1, "2": 2, "3": 1, "4": 1, "5": 1, "6": 1, "7": 1, "8": 1, "9": 1, "arm": 1, "figure": 1, "example": 1, "teach": 2, "effect": 1, "formulate": 1, "problem": 1, "markov": 1, "multiarmed": 1, "bandit": 1, "learner": 1}, {"environmendecision": 1, "process": 1, "mdp": 1, "transition": 1, "tal": 1, "reward": 1, "probabilities": 1, "show": 1, "figure": 1, "condynamics": 1, "follow": 1, "dynamics": 1, "se": 1, "sider": 1, "first": 1, "query": 1, "arm": 1, "6": 1}, {"reward": 1, "probquential": 1, "learner": 1, "responses": 1, "yt": 1, "ac": 1, "ability": 1, "arm": 1, "low": 1, "y1": 1, "": 1, "0": 1, "high": 1, "tions": 1}, {"teach": 1, "mdp": 1, "define": 1, "tuple": 1, "probability": 1, "naive": 1, "teacher": 1}, {"yet": 1, "optimal": 1, "": 10, "h": 2, "r": 1, "state": 1, "ht": 2, "action": 2, "plan": 1, "teacher": 2, "y1": 1, "1": 1, "correspond": 1, "history": 1, "anticipate": 1, "lead": 1, "higher": 2, "sponses": 1, "yt": 2, "transition": 1, "probabilities": 1, "pht1": 1, "probability": 1, "learner": 1, "sample": 1, "next": 1, "arm": 1, "define": 1, "learners": 1, "sequen": 1, "near": 1, "peak": 1}, {"detail": 1, "set": 1, "tial": 1, "dynamics": 1, "reward": 1, "rt": 1, "ht": 1, "": 4, "r": 1, "use": 1, "give": 1, "supplementary": 1, "section": 1, "3": 1, "define": 1, "teachers": 1, "goal": 1, "0": 1, "1": 1, "discount": 1, "factor": 1, "optional": 1, "finite": 1}, {"objective": 1, "teacher": 1, "choose": 1, "action": 1, "yt": 1, "maximise": 1, "pt": 1, "cumulative": 1, "reward": 1, "call": 1, "value": 1, "v": 1, "": 6, "h1": 1, "e": 1, "t1": 2, "rt": 1, "ht": 1, "teachers": 2, "plan": 1, "horizon": 1, "expectation": 1, "possible": 1, "stochasticity": 1, "learners": 1, "query": 1, "policy": 1}, {"teachers": 1, "policy": 1, "ht": 3, "": 6, "yt": 1, "pyt": 1, "map": 1, "state": 1, "probabilities": 1, "action": 1, "space": 1}, {"solution": 1, "teach": 2, "problem": 1, "correspond": 1, "find": 1, "optimal": 1, "policy": 1, "": 3}, {"reward": 1, "function": 1, "rt": 1, "ht": 1, "": 1, "define": 1, "goal": 1, "teacher": 1}, {"design": 1, "teach": 1, "mdp": 1, "reinforcement": 1, "learn": 1, "choice": 1, "crucial": 1}, {"machine": 1, "teach": 1, "natural": 1, "assumption": 1, "reward": 1, "function": 1, "parameterized": 1, "optimal": 1, "model": 1, "parameter": 1, "": 3, "grind": 1, "truth": 1, "know": 1, "teacher": 1, "learner": 1}, {"teach": 1, "supervise": 1, "learn": 1, "algorithm": 1, "reward": 1, "rt": 1, "ht": 1, "": 7, "example": 1, "define": 1, "base": 1, "distance": 1, "learners": 2, "estimate": 1, "evaluation": 1, "predictions": 1, "teachers": 1, "privilege": 1, "knowledge": 1, "outcomes": 1, "figure": 1, "1": 1}, {"multiarmed": 1, "bandit": 1, "application": 1, "assume": 1, "teacher": 1, "know": 1, "true": 1, "parameter": 1, "": 2, "underlie": 1, "environmental": 2, "reward": 2, "distribution": 1, "aim": 1, "teach": 1, "learner": 1, "accumulate": 1, "maximise": 1, "figure": 1, "2": 1}, {"define": 1, "teachers": 1, "reward": 1, "function": 1, "": 8, "rt": 1, "ht": 1, "xt": 1, "leave": 1, "simplify": 1, "formulas": 1, "teacher": 1, "model": 1}, {"4": 2, "": 1, "properties": 2, "teach": 2, "mdp": 2, "supplementary": 1, "section": 1, "briefly": 1, "discuss": 1, "transition": 1, "dynamics": 1, "state": 1, "definition": 1, "contrast": 1, "bayesadaptive": 1, "mdps": 1, "better": 1, "understand": 1}, {"find": 1, "optimal": 1, "teach": 1, "policy": 1, "present": 1, "similar": 1, "challenge": 1, "plan": 1, "bayesadaptive": 1, "mdps": 1}, {"methods": 1, "monte": 1, "carlo": 1, "tree": 1, "search": 1, "37": 1, "find": 1, "provide": 1, "effective": 1, "approach": 1}, {"33": 1, "": 2, "learn": 1, "teachers": 2, "responses": 2, "next": 1, "describe": 1, "learner": 1, "interpret": 1, "acknowledge": 1, "teach": 1, "intent": 1}, {"formulate": 1, "teach": 1, "mdp": 1, "teacheraware": 1, "learn": 2, "follow": 1, "naturally": 1, "inverse": 1, "reinforcement": 1, "38": 1, "39": 1}, {"formulate": 1, "probabilistic": 2, "teacher": 2, "model": 3, "make": 1, "learn": 1, "robust": 1, "towards": 1, "suboptimal": 1, "teach": 1, "allow": 1, "use": 1, "block": 1}, {"iteration": 1, "learner": 1, "assume": 1, "teacher": 1, "choose": 1, "action": 4, "yt": 6, "probability": 1, "proportional": 1, "optimal": 3, "value": 3, "exp": 2, "q": 3, "ht": 4, "": 24, "pm": 1, "p": 1, "3": 1, "0": 2, "stateaction": 1, "function": 1, "teach": 1, "mdp": 1, "take": 1, "follow": 1, "policy": 1, "afterwards": 1}, {"": 6, "teacher": 1, "optimality": 1, "parameter": 1, "inverse": 1, "temperature": 1, "0": 1, "distribution": 1, "yt": 1, "uniform": 1, "action": 1, "highest": 1, "value": 1, "choose": 1, "deterministically": 1}, {"teachingaware": 1, "learners": 1, "perspective": 1, "teachers": 1, "": 3, "unknown": 1, "equation": 1, "3": 1, "function": 1, "likelihood": 1, "learn": 1, "observe": 1, "teach": 1}, {"bandit": 1, "case": 1, "replace": 1, "equation": 1, "1": 1}, {"note": 1, "teach": 1, "mdp": 1, "dynamics": 1, "still": 1, "follow": 1, "teachingunaware": 1, "learner": 1}, {"onestep": 2, "plan": 2, "since": 1, "main": 1, "motivate": 1, "application": 1, "model": 1, "users": 1, "boundedly": 1, "optimal": 1, "teachers": 1, "implement": 1, "bernoulli": 1, "multiarmed": 1, "bandit": 1, "system": 1, "interest": 1, "consider": 1, "special": 1, "case": 1, "horizon": 1, "": 1, "1": 1}, {"stateaction": 1, "value": 1, "function": 1, "q": 1, "ht": 2, "": 19, "yt": 5, "simplify": 1, "reward": 1, "next": 1, "possible": 1, "arm": 1, "action": 1, "observation": 1, "model": 1, "pm": 1, "exp": 1, "x": 1, "pht": 2, "4": 1, "p1ht": 1}, {"": 1}, {"": 1}, {"": 5, "pkht": 1, "yt": 2, "collect": 2, "probabilities": 1, "next": 1, "arm": 3, "give": 1, "action": 1, "0": 1, "1": 1, "current": 1, "xt": 1, "ht": 1, "estimate": 1, "accord": 1, "teach": 1, "mdp": 1, "x": 1, "rkm": 1, "feature": 1, "matrix": 1}, {"note": 1, "reward": 1, "current": 1, "arm": 1, "appear": 1, "action": 1, "probability1": 1, "": 1}, {"deterministic": 1, "bandit": 1, "arm": 3, "selection": 1, "strategies": 1, "transition": 1, "probabilities": 1, "pkht": 1, "yt": 1, "two": 1, "action": 2, "would": 1, "single": 1, "1": 2, "k": 1, "": 1, "zero": 1, "essentially": 1, "pick": 1, "one": 2, "possible": 2, "give": 1, "probability": 1, "interpretation": 1, "preference": 1, "next": 1}, {"stochastic": 1, "selection": 1, "strategies": 1, "thompson": 1, "sample": 1, "interpretation": 1, "similar": 1, "two": 1, "arm": 1, "weight": 1, "average": 1, "xyt": 2, "0": 2, "": 3, "x": 2, "pht": 2, "yt": 2, "1": 2}, {"algorithmic": 1, "overview": 1, "learn": 1, "onestep": 1, "plan": 1, "teacher": 1, "model": 1, "give": 1, "supplementary": 1, "section": 1, "5": 1}, {"illustrative": 1, "example": 1, "consider": 1, "case": 1, "two": 1, "independent": 1, "arm": 2, "x1": 1, "": 4, "1": 3, "0": 2, "x2": 1, "first": 1, "larger": 1, "reward": 1, "probability": 1, "2": 1}, {"optimal": 1, "teach": 1, "action": 1, "give": 1, "yt": 2, "": 2, "1": 2, "query": 1, "arm": 2, "0": 1, "2": 1}, {"teachingunaware": 1, "learner": 1, "still": 1, "need": 1, "query": 1, "arm": 2, "multiple": 1, "time": 1, "identify": 1, "better": 1}, {"teachingaware": 1, "learner": 1, "": 5, "identify": 1, "better": 1, "arm": 2, "single": 1, "query": 1, "either": 1, "since": 1, "likelihood": 1, "function": 2, "tend": 1, "step": 1, "i1": 1, "2": 1}, {"demonstrate": 1, "teachingaware": 1, "learner": 1, "use": 1, "query": 1, "reduce": 1, "uncertainty": 1, "arm": 2, "even": 1, "extreme": 1, "case": 1, "independent": 1}, {"incorporate": 1, "uncertainty": 1, "teacher": 1, "teachers": 1, "exhibit": 1, "different": 1, "kinds": 1, "strategies": 1}, {"make": 1, "learners": 1, "model": 2, "teacher": 1, "robust": 1, "different": 1, "type": 1, "teachers": 1, "formulate": 1, "mixture": 1, "set": 1, "alternative": 1, "strategies": 1}, {"multiarmed": 1, "bandit": 1, "case": 1, "consider": 1, "combination": 1, "teacher": 3, "pass": 1, "environmental": 1, "reward": 1, "naive": 1, "equation": 2, "1": 3, "plan": 1, "3": 1, "pbm": 1, "yt": 3, "": 16, "ht": 2, "pb": 1, "pm": 1, "5": 1, "cancel": 1}, {"teacher": 1, "cannot": 1, "affect": 1, "arm": 1, "choice": 1, "anymore": 1, "already": 1, "make": 1}, {"5": 1, "": 8, "0": 1, "1": 1, "mix": 1, "weight": 1, "xt": 1, "reward": 1, "probability": 1, "latest": 1, "arm": 1, "history": 1, "ht": 1}, {"beta": 1, "prior": 1, "distribution": 1, "": 2, "beta1": 1, "1": 1, "assume": 1, "mix": 1, "weight": 1}, {"34": 1, "": 9, "computational": 1, "detail": 1, "bayesian": 1, "bernoulli": 1, "multiarmed": 1, "bandits": 1, "computation": 1, "present": 1, "three": 1, "challenge": 1, "compute": 2, "analytically": 1, "intractable": 1, "posterior": 1, "distribution": 1, "model": 1, "parameters": 1, "p": 2, "dt": 2, "ii": 1, "solve": 1, "statevalue": 2, "function": 2, "q": 1, "teach": 1, "mdp": 1, "iii": 1, "thompson": 1, "sample": 1, "probabilities": 1, "need": 1}, {"implement": 1, "model": 1, "probabilistic": 1, "program": 1, "language": 1, "pyro": 1, "version": 1, "03": 1, "pytorch": 1, "v10": 1, "40": 1, "approximate": 1, "posterior": 1, "distributions": 1, "laplace": 1, "approximations": 1, "41": 2, "section": 1}, {"brief": 1, "posterior": 1, "approximate": 1, "multivariate": 1, "gaussian": 1, "mean": 1, "define": 1, "maximum": 1, "posteriori": 1, "map": 2, "estimate": 2, "covariance": 1, "matrix": 2, "negative": 1, "inverse": 1, "hessian": 1}, {"mixture": 2, "model": 1, "coefficient": 1, "": 2, "0": 1, "1": 1, "transform": 1, "real": 1, "axis": 1, "via": 1, "logit": 1, "function": 1, "compute": 1, "approximation": 1}, {"inference": 1, "require": 1, "compute": 1, "gradient": 1, "logarithm": 1, "unnormalised": 1, "posterior": 1, "probability": 1}, {"teacher": 1, "model": 2, "entail": 1, "compute": 2, "gradient": 1, "logarithm": 1, "equation": 1, "3": 1, "value": 2, "parameters": 1, "require": 1, "solve": 1, "gradients": 1, "optimal": 1, "stateaction": 1, "function": 1, "q": 1, "respect": 1, "": 3}, {"solve": 1, "q": 1, "possible": 2, "observable": 1, "action": 1, "yt": 2, "": 2, "0": 1, "1": 1, "compute": 1, "trajectories": 1, "mdp": 1, "horizon": 1, "choose": 1, "ones": 1, "give": 1, "maximal": 1, "expect": 1, "cumulative": 1, "reward": 1}, {"choi": 1, "kim": 1, "39": 1, "show": 1, "gradients": 1, "q": 1, "exist": 2, "almost": 1, "everywhere": 1, "direct": 1, "computation": 1, "give": 1, "subgradient": 1, "boundaries": 1, "gradient": 1}, {"mainly": 1, "focus": 1, "onestep": 1, "plan": 1, "": 1, "1": 1, "experiment": 1}, {"long": 1, "plan": 1, "horizons": 1, "stochastic": 1, "arm": 1, "selection": 1, "strategies": 1, "number": 1, "possible": 1, "trajectories": 2, "grow": 1, "fast": 1, "exact": 1, "exhaustive": 1, "computation": 1, "feasible": 1, "k": 1, "initial": 1, "action": 1}, {"multistep": 1, "experiment": 1, "approximate": 1, "forward": 1, "simulation": 1, "mdp": 1, "virtual": 2, "arm": 4, "instead": 1, "consider": 1, "possible": 2, "next": 2, "give": 1, "action": 1, "yt": 4, "weight": 1, "selection": 1, "probabilities": 1, "pht": 2, "": 2, "update": 1, "model": 1, "selectionprobabilityweighted": 1, "average": 1, "xht": 1, "x": 1, "deterministic": 1, "strategies": 1, "exact": 1, "computation": 1}, {"virtual": 1, "arm": 3, "correspond": 1, "real": 1, "system": 1, "expectations": 1, "next": 1}, {"lead": 1, "2t": 1, "1": 1, "trajectories": 1, "simulate": 1, "initial": 1, "action": 1}, {"moreover": 1, "trajectory": 1, "pt": 1, "action": 1, "y1": 1, "": 2}, {"": 1}, {"": 1}, {"": 13, "yt": 2, "approximation": 1, "give": 1, "qh1": 1, "y1": 1, "x": 1, "t1": 2, "pht": 1, "cache": 1, "sum": 1, "discount": 1, "transition": 1, "probabilities": 1, "trajectory": 1, "forward": 1, "simulation": 1, "easily": 1, "find": 1, "optimal": 1, "q": 1, "value": 1, "require": 1, "inference": 1}, {"compute": 2, "next": 1, "arm": 1, "probabilities": 2, "q": 1, "value": 1, "require": 1, "actual": 1, "thompson": 1, "sample": 2, "equation": 1, "2": 1, "instead": 1}, {"sigmoid": 1, "function": 1, "r": 1, "monotonic": 1, "one": 1, "equivalently": 1, "compute": 1, "probabilities": 1, "prit1": 1, "": 7, "k": 1, "iarg": 1, "maxj": 1, "zj": 1, "kpz": 1, "dt": 1, "dz": 1, "z": 1, "x": 1}, {"p": 1, "": 8, "dt": 1, "n": 1, "z": 1, "multivariate": 1, "normal": 1, "distribution": 1, "mean": 1, "xm": 1, "covariance": 1, "xx": 1}, {"selection": 1, "probabilities": 1, "estimate": 1, "monte": 1, "carlo": 1, "sample": 1}, {"use": 1, "raoblackwellized": 1, "estimate": 1, "prit1": 1, "": 10, "pl": 1, "l": 3, "k": 1, "l1": 2, "przk": 2, "maxj6k": 2, "zj": 2, "zk": 5, "monte": 1, "carlo": 1, "sample": 1, "draw": 1, "z": 1, "kth": 1, "component": 3, "remove": 1, "conditional": 1, "normal": 1, "probability": 1, "larger": 1, "largest": 1}, {"4": 1, "": 2, "experiment": 2, "perform": 1, "simulation": 1, "bayesian": 1, "bernoulli": 1, "multiarmed": 1, "bandit": 1, "learner": 3, "base": 1, "real": 1, "dataset": 1, "study": 1, "whether": 4, "teacher": 1, "efficiently": 1, "steer": 1, "towards": 1, "target": 1, "increase": 2, "learn": 1, "performance": 3, "ii": 1, "ability": 1, "recognise": 1, "teach": 2, "intent": 1, "iii": 1, "mixture": 1, "model": 1, "robust": 1, "assumptions": 1, "teachers": 1, "strategy": 1, "iv": 1, "plan": 1, "multiple": 1, "step": 1, "ahead": 1, "improve": 1}, {"present": 1, "result": 1, "proofofconcept": 1, "study": 1, "humans": 1}, {"supplementary": 1, "section": 1, "61": 1, "include": 1, "additional": 1, "experiment": 1, "study": 1, "teach": 2, "uncertaintysamplingbased": 1, "logistic": 1, "regression": 1, "active": 1, "learner": 1, "show": 1, "improve": 1, "learn": 1, "performance": 1, "markedly": 1}, {"6": 1, "": 49, "nn": 3, "5": 2, "0": 2, "pn": 3, "08": 2, "07": 2, "06": 2, "05": 2, "1": 4, "10": 6, "20": 4, "30": 4, "step": 4, "pp": 5, "pm": 2, "nm": 2, "np": 2, "c": 4, "oncordance": 2, "ndex": 2, "ean": 2, "umulative": 2, "r": 2, "eward": 2, "figure": 1, "3": 1, "leftside": 1, "panel": 1, "plan": 2, "teacher": 3, "improve": 1, "performance": 1, "learners": 1, "model": 1, "naive": 2}, {"rightside": 1, "panel": 1, "naive": 1, "teacher": 2, "learner": 1, "expect": 1, "plan": 1, "np": 1, "degrade": 1, "performance": 1}, {"learners": 1, "mixture": 1, "teacher": 1, "model": 2, "attain": 1, "similar": 1, "performance": 1, "match": 1, "pm": 1, "vs": 2, "pp": 1, "nm": 1, "nn": 1, "leave": 1}, {"line": 1, "show": 1, "mean": 2, "100": 1, "replications": 1, "shade": 1, "area": 1, "95": 1, "confidence": 1, "intervals": 1}, {"see": 1, "table": 1, "1": 1, "key": 1, "abbreviations": 1}, {"41": 1, "": 2, "simulation": 1, "experiment": 1, "use": 1, "word": 1, "relevance": 1, "dataset": 1, "simulate": 1, "information": 1, "retrieval": 1, "task": 1}, {"task": 1, "user": 1, "try": 1, "teach": 1, "relevance": 1, "profile": 1, "learner": 1, "order": 1, "reach": 1, "target": 1, "word": 1}, {"word": 2, "dataset": 2, "random": 1, "selection": 1, "10000": 1, "google": 2, "word2vec": 1, "vectors": 1, "pretrained": 1, "news": 1, "42": 1}, {"reduce": 1, "dimensionality": 1, "word": 1, "embeddings": 1, "original": 1, "300": 1, "10": 1, "use": 1, "pca": 1}, {"feature": 1, "vectors": 1, "meancentred": 1, "normalise": 1, "unit": 1, "length": 1}, {"report": 1, "result": 1, "similar": 1, "conclusions": 1, "two": 1, "datasets": 1, "supplementary": 1, "section": 1, "62": 1}, {"randomly": 2, "generate": 1, "100": 2, "replicate": 1, "experiment": 1, "set": 1, "arm": 2, "sample": 1, "without": 1, "replacement": 1, "one": 1, "choose": 1, "target": 1, "x": 1, "": 2, "rm": 1}, {"groundtruth": 1, "relevance": 1, "profile": 1, "generate": 1, "first": 1, "set": 1, "": 7, "c": 2, "dx": 1, "rm": 1, "1": 2, "4": 1, "weight": 1, "intercept": 1, "term": 1, "constant": 1, "element": 1, "add": 1, "xs": 1, "8": 1, "scale": 1, "factor": 1}, {"groundtruth": 1, "": 4, "reward": 2, "probabilities": 1, "compute": 1, "k": 3, "xt": 1, "arm": 1, "supplementary": 1, "figure": 1, "2": 1, "show": 1, "mean": 1, "probability": 1, "profile": 1}, {"reduce": 1, "experimental": 1, "variance": 1, "method": 1, "comparison": 1, "choose": 1, "one": 1, "arm": 1, "randomly": 1, "initial": 1, "query": 1, "methods": 1}, {"table": 1, "1": 1, "teacherlearner": 1, "pair": 1}, {"compare": 1, "learn": 1, "performances": 1, "different": 1, "pair": 1, "simulate": 1, "teachers": 1, "learners": 1, "table": 1, "1": 1}, {"learners": 1, "model": 1, "teacher": 3, "naive": 3, "n": 1, "intentionally": 1, "teach": 1, "plan": 1, "mixture": 1, "pass": 1, "stochastic": 1, "binary": 1, "reward": 1, "equation": 1, "1": 1, "base": 1, "grind": 1, "truth": 1, "k": 2, "action": 1, "arm": 1, "nn": 1, "np": 1, "nm": 1, "standard": 1, "bandit": 1, "assumption": 1}, {"plan": 3, "teacher": 1, "p": 1, "pn": 1, "pp": 1, "pm": 1, "use": 1, "probabilistic": 1, "teach": 1, "mdp": 1, "model": 1, "equation": 2, "4": 1, "onestep": 1, "3": 1, "multistep": 1, "base": 1, "grind": 1, "truth": 1, "": 2, "action": 1}, {"use": 1, "": 3, "20": 1, "plan": 1, "teachers": 1, "optimality": 1, "parameter": 1, "also": 1, "set": 1, "learners": 1, "teacher": 1, "model": 1, "value": 1}, {"multistep": 1, "model": 1, "set": 1, "": 3, "t1": 1, "plan": 1, "maximise": 1, "average": 1, "return": 1, "horizon": 1}, {"learners": 1, "name": 1, "base": 2, "model": 3, "teacher": 3, "teachingunaware": 1, "learner": 2, "learn": 1, "naive": 1, "n": 1, "equation": 3, "1": 1, "teachingaware": 1, "plan": 1, "p": 1, "4": 1, "3": 1}, {"mixture": 2, "model": 2, "refer": 1, "learner": 1, "two": 1, "teacher": 1, "equation": 1, "5": 1}, {"expect": 1, "cumulative": 1, "reward": 1, "concordance": 1, "index": 1, "use": 1, "performance": 1, "measure": 1, "higher": 1, "better": 1}, {"expect": 1, "cumulative": 1, "reward": 2, "measure": 1, "efficiently": 1, "system": 1, "find": 1, "high": 1, "arm": 1, "standard": 1, "bandit": 1, "benchmark": 1, "value": 1}, {"concordance": 1, "index": 1, "equivalent": 1, "area": 1, "receiver": 1, "operate": 1, "characteristic": 1, "curve": 1}, {"common": 1, "performance": 1, "measure": 1, "information": 1, "retrieval": 1, "task": 1}, {"estimate": 2, "probability": 1, "random": 2, "pair": 1, "arm": 1, "order": 2, "grind": 1, "truth": 1, "relevances": 2, "model": 1, "05": 1, "correspond": 1, "10": 1, "perfect": 1, "performance": 1}, {"7": 1, "": 3, "42": 1, "simulation": 1, "result": 1, "plan": 3, "multiple": 1, "step": 3, "increase": 1, "performance": 1, "figure": 1, "4": 1, "show": 1, "cumulative": 1, "reward": 1, "difference": 1, "match": 1, "teacher": 1, "learner": 1, "pair": 1, "pp": 1, "two": 1, "four": 1, "ahead": 1, "compare": 1, "one": 1}, {"mark": 1, "improvement": 1, "especially": 1, "go": 1, "3step": 1, "4step": 1, "plan": 1, "horizon": 1}, {"sensitivity": 2, "analysis": 1, "result": 2, "simulate": 1, "teachers": 1, "optimality": 1, "parameter": 1, "": 2, "performance": 1, "degrade": 1, "markedly": 1, "small": 1, "value": 1, "number": 1, "arm": 1, "500": 1, "instead": 1, "100": 1, "remain": 1, "qualitatively": 1, "similar": 1, "show": 1, "supplementary": 1, "section": 1, "62": 1}, {"43": 1, "": 2, "mean": 1, "cumulative": 1, "reward": 1, "cumul": 1}, {"reward": 1, "difference": 1, "1step": 1, "": 2, "4step": 1, "3step": 1, "2step": 1, "teach": 1, "improve": 1, "performance": 2, "figure": 1, "3": 1, "show": 1, "different": 1, "combina15": 1, "tions": 1, "pair": 1, "teachers": 2, "learners": 1, "plan": 2, "horizon": 1, "10": 1, "1": 1}, {"plan": 1, "teacher": 2, "steer": 1, "teacherunaware": 1, "learner": 1, "achieve": 1, "mark": 1, "increase": 1, "performance": 1, "compare": 1, "naive": 1, "pn": 1, "05": 1, "vs": 1, "nn": 1, "leftside": 1, "panel": 1, "show": 1, "intentional": 1, "teach": 1, "make": 1, "reward": 1, "signal": 1, "supportive": 1, "learn": 1}, {"performance": 1, "in00": 1, "crease": 1, "markedly": 1, "learner": 1, "model": 1, "plan": 1, "teacher": 1, "pp": 1, "leftside": 1, "panel": 1}, {"improvements": 1, "see": 1, "performance": 2, "05": 1, "measure": 1, "concordance": 1, "index": 1, "imply": 1, "1": 1, "10": 1, "20": 1, "30": 2, "particularly": 1, "propose": 1, "model": 1, "learn": 1, "faster": 1, "step": 2, "relevant": 1, "arm": 1, "also": 1, "achieve": 1, "higher": 1, "overall": 1, "end": 1}, {"figure": 1, "4": 1, "teachers": 1, "plan": 1, "multiple": 1, "step": 1, "ahead": 1, "improve": 1, "1step": 1, "pp": 1, "performance": 1}, {"mixture": 2, "model": 3, "increase": 1, "robustness": 1, "assumptions": 1, "teacher": 5, "mismatch": 1, "human": 2, "": 2, "naive": 2, "learner": 1, "expect": 1, "planrandom": 1, "draw": 1, "baseline": 1, "8": 1, "ning": 1, "np": 1, "markedly": 1, "detrimental": 1, "performance": 1, "figure": 1, "3": 1, "rightside": 1, "panel": 1}, {"6": 1, "mixture": 1, "model": 1, "guard": 1, "mismatch": 1, "attain": 1, "performance": 1, "similar": 1, "match": 1, "assumptions": 1, "pm": 1, "vs": 2, "pp": 1, "nm": 1, "nn": 1}, {"4": 1, "": 7, "2": 1, "0": 1, "1": 1, "3": 1, "5": 2, "7": 1, "9": 1, "11": 1, "number": 1, "question": 1, "13": 1, "15": 1, "figure": 1, "accumulate": 1, "reward": 1, "consistently": 1, "higher": 1, "participants": 1, "interact": 1, "learner": 2, "mixture": 1, "teacher": 2, "model": 2, "compare": 1, "naive": 1}, {"shade": 1, "line": 1, "show": 1, "mean": 1, "performance": 1, "20": 1, "target": 1, "word": 1, "individual": 1, "participants": 1}, {"solid": 1, "line": 1, "show": 1, "mean": 1, "participants": 1}, {"random": 1, "arm": 1, "sample": 1, "show": 1, "baseline": 1}, {"user": 2, "experiment": 1, "": 1, "conduct": 1, "proofofconcept": 1, "study": 1, "task": 1, "introduce": 1, "use": 1, "subset": 1, "20": 1, "word": 1, "ten": 1, "university": 1, "students": 1, "researchers": 1}, {"goal": 1, "study": 1, "introduce": 1, "participants": 2, "help": 1, "system": 1, "find": 1, "target": 4, "word": 5, "fast": 1, "possible": 1, "provide": 1, "binary": 1, "answer": 1, "yesno": 1, "systems": 1, "question": 1, "relevant": 1, "give": 1, "begin": 1, "round": 2, "twenty": 1, "choose": 1}, {"detail": 1, "study": 1, "set": 1, "provide": 1, "supplementary": 1, "section": 1, "7": 1}, {"participants": 1, "achieve": 1, "noticeably": 1, "higher": 1, "average": 1, "cumulative": 1, "reward": 1, "interact": 1, "learner": 2, "mixture": 1, "teacher": 2, "model": 2, "compare": 1, "naive": 1, "figure": 1, "5": 1, "red": 1, "vs": 1, "blue": 1}, {"difference": 1, "significant": 1, "level": 1, "pvalue": 1, "": 1, "001": 1, "12": 1, "question": 1, "compute": 1, "use": 1, "pair": 1, "sample": 1, "ttest": 1, "see": 1, "supplementary": 1, "section": 1, "7": 1, "pvalues": 1, "per": 1, "step": 1}, {"8": 1, "": 3, "5": 1, "discussion": 1, "conclusions": 1, "introduce": 1, "new": 1, "sequential": 1, "machine": 1, "teach": 1, "problem": 1, "learner": 1, "actively": 1, "choose": 1, "query": 1, "teacher": 1, "provide": 1, "responses": 1}, {"encompass": 1, "teach": 1, "popular": 1, "sequential": 1, "learners": 2, "active": 1, "multiarmed": 1, "bandits": 1}, {"teach": 2, "problem": 1, "formulate": 1, "markov": 1, "decision": 1, "process": 1, "solution": 1, "provide": 1, "optimal": 1, "policy": 1}, {"formulate": 1, "teacheraware": 1, "learn": 2, "teachers": 1, "responses": 1, "probabilistic": 1, "inverse": 1, "reinforcement": 1}, {"experiment": 1, "bayesian": 1, "bernoulli": 1, "multiarmed": 1, "bandits": 1, "logistic": 1, "regression": 1, "active": 1, "learners": 1, "demonstrate": 1, "improve": 1, "performance": 1, "teach": 1, "learn": 1, "teacher": 1, "awareness": 1}, {"better": 1, "theoretical": 1, "understand": 1, "set": 2, "study": 1, "vary": 1, "assumptions": 1, "approach": 1, "plan": 1, "teacher": 1, "teacheraware": 1, "learner": 1, "important": 1, "future": 1, "directions": 1}, {"formulation": 1, "provide": 1, "way": 1, "model": 1, "users": 1, "strategic": 1, "behaviour": 1, "boundedly": 1, "optimal": 1, "teachers": 1, "interactive": 1, "intelligent": 1, "systems": 1}, {"conduct": 1, "proofofconcept": 1, "user": 2, "study": 1, "show": 1, "encourage": 1, "result": 1, "task": 1, "steer": 1, "bandit": 1, "system": 1, "towards": 1, "target": 1, "word": 1}, {"scale": 1, "approach": 1, "realistic": 1, "systems": 1, "example": 1, "interactive": 1, "exploratory": 1, "information": 1, "retrieval": 1, "43": 1, "user": 2, "study": 1, "simplify": 1, "instance": 1, "humanintheloop": 1, "bayesian": 1, "optimisation": 1, "44": 1, "might": 1, "possess": 1, "exact": 1, "knowledge": 1, "goal": 1, "future": 1, "work": 1, "consider": 1, "incorporate": 1, "advance": 1, "cognitive": 1, "model": 1, "users": 1}, {"efficient": 1, "teacher": 1, "user": 3, "need": 1, "able": 1, "model": 2, "learner": 1, "system": 2, "result": 1, "also": 2, "highlight": 1, "role": 1, "understandability": 1, "predictability": 1, "interactive": 1, "systems": 1, "important": 1, "design": 1, "factor": 1, "experience": 1, "statistical": 1}, {"focus": 1, "teachers": 1, "bound": 1, "shorthorizon": 1, "plan": 1, "would": 1, "expect": 1, "human": 1, "users": 1, "able": 1, "predict": 1, "behaviour": 1, "interactive": 1, "systems": 1, "long": 1, "horizons": 1, "scale": 1, "computation": 1, "larger": 1, "problems": 1, "interest": 1}, {"give": 1, "similarity": 1, "teach": 2, "mdp": 1, "bayesadaptive": 1, "mdps": 2, "partially": 1, "observable": 1, "plan": 1, "methods": 1, "develop": 1, "could": 1, "use": 1, "efficient": 1, "search": 1, "action": 1}, {"teach": 1, "set": 1, "advantage": 1, "teacher": 1, "assume": 1, "privilege": 1, "information": 2, "target": 1, "model": 1, "could": 1, "use": 1, "generate": 1, "reasonable": 1, "initial": 1, "policy": 1, "choose": 1, "action": 1}, {"policy": 1, "could": 1, "refine": 1, "example": 1, "use": 1, "monte": 1, "carlo": 1, "tree": 1, "search": 1}, {"teacheraware": 1, "learn": 2, "problem": 2, "challenge": 1, "inverse": 1, "reinforcement": 1, "require": 1, "handle": 1, "plan": 1, "inner": 1, "loop": 1}, {"consider": 1, "application": 1, "adaptation": 1, "stateoftheart": 1, "inverse": 1, "reinforcement": 1, "learn": 2, "methods": 1, "teacheraware": 1, "future": 1, "work": 1}, {"acknowledgments": 1, "work": 1, "financially": 1, "support": 1, "academy": 1, "finland": 1, "flagship": 1, "programme": 1, "finnish": 1, "center": 1, "artificial": 1, "intelligence": 1, "fcai": 1, "grant": 1, "319264": 1, "313195": 1, "305780": 1, "292334": 1}, {"mustafa": 1, "mert": 1, "elikok": 1, "partially": 1, "fund": 1, "finnish": 1, "science": 1, "foundation": 1, "technology": 1, "economics": 1, "kaute": 1}, {"acknowledge": 1, "computational": 1, "resources": 1, "provide": 1, "aalto": 1, "scienceit": 1, "project": 1}, {"thank": 1, "antti": 1, "oulasvirta": 1, "marta": 1, "soare": 1, "comment": 1, "improve": 1, "article": 1}, {"reference": 1, "1": 1, "allen": 1, "newell": 1, "herbert": 1, "alexander": 1, "simon": 1}, {"human": 1, "problem": 1, "solve": 1}, {"prenticehall": 1, "inc": 1, "upper": 1, "saddle": 1, "river": 1, "nj": 1, "usa": 1, "1972": 1}, {"2": 1, "keith": 1, "j": 1, "holyoak": 1}, {"problem": 1, "solve": 1}, {"edward": 1, "e": 1, "smith": 1, "daniel": 1, "n": 1, "osherson": 1, "editors": 1, "think": 1, "invitation": 1, "cognitive": 1, "science": 1, "vol": 1}, {"3": 1, "page": 1, "267296": 1}, {"mit": 1, "press": 1, "2nd": 1, "edition": 1, "1995": 1}, {"3": 1, "arjun": 1, "chandrasekaran": 1, "deshraj": 1, "yadav": 1, "prithvijit": 1, "chattopadhyay": 1, "viraj": 1, "prabhu": 1, "devi": 1, "parikh": 1}, {"take": 1, "two": 1, "tango": 1, "towards": 1, "theory": 1, "ais": 1, "mind": 1}, {"arxiv": 1, "preprint": 1, "arxiv170400717": 1, "2017": 1}, {"4": 1, "randi": 1, "williams": 1, "hae": 1, "park": 1, "cynthia": 1, "breazeal": 1}, {"artificial": 2, "intelligence": 2, "impact": 1, "activities": 1, "young": 1, "childrens": 1, "perceptions": 1, "robots": 1}, {"proceed": 1, "2019": 2, "chi": 1, "conference": 1, "human": 1, "factor": 1, "compute": 1, "systems": 1, "page": 1, "447144711": 1}, {"5": 1, "sally": 1, "goldman": 1, "michael": 1, "j": 1, "kearns": 1}, {"complexity": 1, "teach": 1}, {"journal": 1, "computer": 1, "system": 1, "sciences": 1, "5012031": 1, "1995": 1}, {"9": 1, "": 1, "6": 1, "xiaojin": 1, "zhu": 1}, {"machine": 2, "teach": 1, "inverse": 1, "problem": 1, "learn": 1, "approach": 1, "toward": 1, "optimal": 1, "education": 1}, {"proceed": 1, "twentyninth": 1, "aaai": 1, "conference": 1, "artificial": 1, "intelligence": 1, "page": 1, "40834087": 1, "2015": 1}, {"7": 1, "xiaojin": 1, "zhu": 1, "adish": 1, "singla": 1, "sandra": 1, "zilles": 1, "anna": 1, "n": 1, "rafferty": 1}, {"overview": 1, "machine": 1, "teach": 1}, {"arxiv": 1, "preprint": 1, "arxiv180105927": 1, "2018": 1}, {"8": 1, "anna": 1, "n": 1, "rafferty": 1, "emma": 1, "brunskill": 1, "thomas": 1, "l": 1, "griffiths": 1, "patrick": 1, "shafto": 1}, {"faster": 1, "teach": 1, "via": 1, "pomdp": 1, "plan": 1}, {"cognitive": 1, "science": 1, "40612901332": 1, "2016": 1}, {"9": 1, "shike": 1, "mei": 1, "xiaojin": 1, "zhu": 1}, {"use": 1, "machine": 2, "teach": 1, "identify": 1, "optimal": 1, "trainingset": 1, "attack": 1, "learners": 1}, {"proceed": 1, "twentyninth": 1, "aaai": 1, "conference": 1, "artificial": 1, "intelligence": 1, "page": 1, "28712877": 1, "2015": 1}, {"10": 1, "maya": 1, "cakmak": 1, "manuel": 1, "lop": 1}, {"algorithmic": 1, "human": 1, "teach": 1, "sequential": 1, "decision": 1, "task": 1}, {"proceed": 1, "twentysixth": 1, "aaai": 1, "conference": 1, "artificial": 1, "intelligence": 1, "page": 1, "15361542": 1, "2012": 1}, {"11": 1, "daniel": 1, "brown": 1, "scott": 1, "niekum": 1}, {"machine": 1, "teach": 1, "inverse": 1, "reinforcement": 1, "learn": 1, "algorithms": 1, "applications": 1}, {"proceed": 1, "thirtythird": 1, "aaai": 1, "conference": 1, "artificial": 1, "intelligence": 1, "2019": 1}, {"12": 1, "laurent": 1, "lessard": 1, "xuezhou": 1, "zhang": 1, "xiaojin": 1, "zhu": 1}, {"optimal": 1, "control": 1, "approach": 1, "sequential": 1, "machine": 1, "teach": 1}, {"proceed": 1, "22nd": 1, "international": 1, "conference": 1, "artificial": 1, "intelligence": 1, "statistics": 1, "aistats": 1, "page": 1, "24952503": 1, "2019": 1}, {"13": 1, "weiyang": 1, "liu": 1, "bo": 1, "dai": 1, "ahmad": 1, "humayun": 1, "charlene": 1, "tay": 1, "chen": 1, "yu": 1, "linda": 1, "b": 1, "smith": 1, "jam": 1, "rehg": 1, "le": 1, "song": 1}, {"iterative": 1, "machine": 1, "teach": 1}, {"proceed": 1, "34th": 1, "international": 1, "conference": 1, "machine": 1, "learn": 1, "icml": 1, "page": 1, "21492158": 1, "2017": 1}, {"14": 1, "weiyang": 1, "liu": 2, "bo": 1, "dai": 1, "xingguo": 1, "li": 1, "zhen": 1, "jam": 1, "rehg": 1, "le": 1, "song": 1}, {"towards": 1, "blackbox": 1, "iterative": 1, "machine": 1, "teach": 1}, {"proceed": 1, "35th": 1, "international": 1, "conference": 1, "machine": 1, "learn": 1, "icml": 1, "page": 1, "31413149": 1, "2018": 1}, {"15": 1, "jacob": 1, "whitehill": 1, "javier": 1, "movellan": 1}, {"approximately": 2, "optimal": 2, "teach": 1, "learners": 1}, {"ieee": 1, "transactions": 1, "learn": 1, "technologies": 1, "112152164": 1, "2017": 1}, {"16": 1, "sandra": 1, "zilles": 1, "steffen": 1, "lange": 1, "robert": 1, "holte": 1, "martin": 1, "zinkevich": 1}, {"model": 1, "cooperative": 1, "teach": 1, "learn": 1}, {"journal": 1, "machine": 1, "learn": 1, "research": 1, "12349384": 1, "2011": 1}, {"17": 1, "thorsten": 1, "doliwa": 1, "gaojian": 1, "fan": 1, "hans": 1, "ulrich": 1, "simon": 1, "sandra": 1, "zilles": 1}, {"recursive": 1, "teach": 1, "dimension": 1, "vcdimension": 1, "sample": 1, "compression": 1}, {"journal": 1, "machine": 1, "learn": 1, "research": 1, "1531073131": 1, "2014": 1}, {"18": 1, "yuzhe": 1, "kwangsung": 1, "jun": 1, "lihong": 1, "li": 1, "xiaojin": 1, "zhu": 1}, {"data": 1, "poison": 1, "attack": 1, "contextual": 1, "bandits": 1}, {"international": 1, "conference": 1, "decision": 1, "game": 1, "theory": 1, "security": 1, "page": 1, "186204": 1, "2018": 1}, {"19": 1, "kwangsung": 1, "jun": 1, "lihong": 1, "li": 1, "yuzhe": 1, "jerry": 1, "zhu": 1}, {"adversarial": 1, "attack": 1, "stochastic": 1, "bandits": 1}, {"advance": 1, "neural": 1, "information": 1, "process": 1, "systems": 1, "neurips": 1, "page": 1, "36403649": 1, "2018": 1}, {"20": 1, "andrew": 1, "ng": 1, "daishi": 1, "harada": 1, "stuart": 1, "russell": 1}, {"policy": 1, "invariance": 1, "reward": 2, "transformations": 1, "theory": 1, "application": 1, "shape": 1}, {"proceed": 1, "16th": 1, "international": 1, "conference": 1, "machine": 1, "learn": 1, "icml": 1, "volume": 1, "99": 1, "page": 1, "278287": 1, "1999": 1}, {"21": 1, "piotr": 1, "j": 1, "gmytrasiewicz": 1, "prashant": 1, "doshi": 1}, {"framework": 1, "sequential": 1, "plan": 1, "multiagent": 1, "settings": 1}, {"journal": 1, "artificial": 1, "intelligence": 1, "research": 1, "244979": 1, "2005": 1}, {"22": 1, "david": 1, "v": 1, "pynadath": 1, "milind": 1, "tambe": 1}, {"communicative": 1, "multiagent": 1, "team": 1, "decision": 1, "problem": 1, "analyze": 1, "teamwork": 1, "theories": 1, "model": 1}, {"journal": 1, "artificial": 1, "intelligence": 1, "research": 1, "16": 1, "389423": 1, "2002": 1}, {"10": 1, "": 1, "23": 1, "dylan": 1, "hadfieldmenell": 1, "anca": 1, "dragan": 1, "pieter": 1, "abbeel": 1, "stuart": 1, "russell": 1}, {"cooperative": 1, "inverse": 1, "reinforcement": 1, "learn": 1}, {"advance": 1, "neural": 1, "information": 1, "process": 1, "systems": 1, "nip": 1, "page": 1, "39093917": 1, "2016": 1}, {"24": 1, "frans": 1, "oliehoek": 1, "christopher": 1, "amato": 1}, {"concise": 1, "introduction": 1, "decentralize": 1, "pomdps": 1}, {"springerbriefs": 1, "intelligent": 1, "systems": 1}, {"springer": 1, "may": 1, "2016": 1}, {"25": 1, "stefano": 1, "v": 1, "albrecht": 1, "peter": 1, "stone": 1}, {"autonomous": 1, "agents": 2, "model": 1, "comprehensive": 1, "survey": 1, "open": 1, "problems": 1}, {"artificial": 1, "intelligence": 1, "2586695": 1, "2018": 1}, {"26": 1, "chris": 1, "l": 1, "baker": 1, "julian": 1, "jaraettinger": 1, "rebecca": 1, "saxe": 1, "joshua": 1, "b": 1, "tenenbaum": 1}, {"rational": 1, "quantitative": 1, "attribution": 1, "beliefs": 1, "desire": 1, "percepts": 1, "human": 1, "mentalizing": 1}, {"nature": 1, "human": 1, "behaviour": 1, "140064": 1, "2017": 1}, {"27": 1, "jaime": 1, "f": 1, "fisac": 1, "monica": 1}, {"gate": 1, "jessica": 1, "b": 1, "hamrick": 1, "chang": 1, "liu": 1, "dylan": 1, "hadfieldmenell": 1, "malayandi": 1, "palaniappan": 1, "dhruv": 1, "malik": 1, "shankar": 1, "sastry": 1, "thomas": 1, "l": 1, "griffiths": 1, "anca": 1, "dragan": 1}, {"pragmaticpedagogic": 1, "value": 1, "alignment": 1}, {"international": 1, "symposium": 1, "robotics": 1, "research": 1, "isrr": 1, "2017": 1}, {"28": 1, "mark": 1, "p": 1, "woodward": 1, "robert": 1, "j": 1}, {"wood": 1}, {"learn": 1, "humans": 1, "ipomdp": 1}, {"arxiv": 1, "preprint": 1, "arxiv12040274": 1, "2012": 1}, {"29": 1, "gerhard": 1, "fischer": 1}, {"user": 1, "model": 1, "humancomputer": 1, "interaction": 1}, {"user": 1, "model": 1, "useradapted": 1, "interaction": 1, "11126586": 1, "2001": 1}, {"30": 1, "gary": 1, "marchionini": 1}, {"exploratory": 1, "search": 1, "find": 1, "understand": 1}, {"communications": 1, "acm": 1, "4944146": 1, "2006": 1}, {"31": 1, "tuukka": 1, "ruotsalo": 1, "giulio": 1, "jacucci": 1, "petri": 1, "myllymki": 1, "samuel": 1, "kaski": 1}, {"interactive": 1, "intent": 1, "model": 1, "information": 1, "discovery": 1, "beyond": 1, "search": 1}, {"communications": 1, "acm": 1, "5818692": 1, "2015": 1}, {"32": 1, "sven": 1, "schmit": 1, "carlos": 1, "riquelme": 1}, {"human": 1, "interaction": 1, "recommendation": 1, "systems": 1}, {"proceed": 1, "twentyfirst": 1, "international": 1, "conference": 1, "artificial": 1, "intelligence": 1, "statistics": 1, "aistats": 1, "page": 1, "862870": 1, "2018": 1}, {"33": 1, "pedram": 1, "daee": 1, "tomi": 1, "peltola": 1, "aki": 1, "vehtari": 1, "samuel": 1, "kaski": 1}, {"user": 1, "model": 1, "avoid": 1, "overfitting": 1, "interactive": 1, "knowledge": 1, "elicitation": 1, "prediction": 1}, {"23rd": 1, "international": 1, "conference": 1, "intelligent": 1, "user": 1, "interfaces": 1, "iui": 1, "page": 1, "305310": 1, "2018": 1}, {"34": 1, "samuel": 1, "j": 2, "gershman": 1, "eric": 1, "horvitz": 1, "joshua": 1, "b": 1, "tenenbaum": 1}, {"computational": 1, "rationality": 1, "converge": 1, "paradigm": 1, "intelligence": 1, "brain": 1, "mind": 1, "machine": 1}, {"science": 1, "3496245": 1, "273278": 1, "2015": 1}, {"35": 1, "william": 1, "r": 1, "thompson": 1}, {"likelihood": 1, "one": 1, "unknown": 1, "probability": 1, "exceed": 1, "another": 1, "view": 1, "evidence": 1, "two": 1, "sample": 1}, {"biometrika": 1, "2534285294": 1, "1933": 1}, {"36": 1, "daniel": 1, "j": 1, "russo": 1, "benjamin": 1, "van": 1, "roy": 1, "abbas": 1, "kazerouni": 1, "ian": 1, "osband": 1, "zheng": 1, "wen": 1}, {"tutorial": 1, "thompson": 1, "sample": 1}, {"foundations": 1, "trend": 1, "r": 1, "machine": 1, "learn": 1, "111196": 1, "2018": 1}, {"37": 1, "arthur": 1, "guez": 1, "david": 1, "silver": 1, "peter": 1, "dayan": 1}, {"scalable": 1, "efficient": 1, "bayesadaptive": 1, "reinforcement": 1, "learn": 1, "base": 1, "montecarlo": 1, "tree": 1, "search": 1}, {"journal": 1, "artificial": 1, "intelligence": 1, "research": 1, "48": 1, "841883": 1, "2013": 1}, {"38": 1, "deepak": 1, "ramachandran": 1, "eyal": 1, "amir": 1}, {"bayesian": 1, "inverse": 1, "reinforcement": 1, "learn": 1}, {"proceed": 1, "twentieth": 1, "international": 1, "joint": 1, "conference": 1, "artificial": 1, "intelligence": 1, "ijcai": 1, "page": 1, "2586": 1, "2591": 1, "2007": 1}, {"39": 1, "jaedeug": 1, "choi": 1, "keeeung": 1, "kim": 1}, {"map": 1, "inference": 1, "bayesian": 1, "inverse": 1, "reinforcement": 1, "learn": 1}, {"advance": 1, "neural": 1, "information": 1, "process": 1, "systems": 1, "nip": 1, "page": 1, "19891997": 1, "2011": 1}, {"40": 1, "eli": 1, "bingham": 1, "jonathan": 1, "p": 1, "chen": 1, "martin": 1, "jankowiak": 1, "fritz": 1, "obermeyer": 1, "neeraj": 1, "pradhan": 1, "theofanis": 1, "karaletsos": 1, "rohit": 1, "singh": 1, "paul": 2, "szerlip": 1, "horsfall": 1, "noah": 1, "goodman": 1}, {"pyro": 1, "deep": 1, "universal": 1, "probabilistic": 1, "program": 1}, {"journal": 1, "machine": 1, "learn": 1, "research": 1, "202816": 1, "2019": 1}, {"11": 1, "": 1, "41": 1, "andrew": 1, "gelman": 1, "john": 1, "b": 3, "carlin": 1, "hal": 1, "stern": 1, "david": 1, "dunson": 1, "aki": 1, "vehtari": 1, "donald": 1, "rubin": 1}, {"bayesian": 1, "data": 1, "analysis": 1}, {"chapman": 1, "": 1, "hallcrc": 1, "3rd": 1, "edition": 1, "2014": 1}, {"42": 1, "tomas": 1, "mikolov": 1, "ilya": 1, "sutskever": 1, "kai": 1, "chen": 1, "greg": 1, "corrado": 1, "jeff": 1, "dean": 1}, {"distribute": 1, "representations": 1, "word": 1, "phrase": 1, "compositionality": 1}, {"advance": 1, "neural": 1, "information": 1, "process": 1, "systems": 1, "nip": 1, "page": 1, "31113119": 1, "2013": 1}, {"43": 1, "tuukka": 1, "ruotsalo": 1, "jaakko": 1, "peltonen": 1, "manuel": 1, "j": 1}, {"eugster": 1, "dorota": 1, "glowacka": 1, "patrik": 1, "floren": 1, "petri": 1, "myllymki": 1, "giulio": 1, "jacucci": 1, "samuel": 1, "kaski": 1}, {"interactive": 1, "intent": 1, "model": 1, "exploratory": 1, "search": 1}, {"acm": 1, "trans": 1}, {"inf": 1}, {"syst": 1, "3644414446": 1, "2018": 1}, {"44": 1, "eric": 1, "brochu": 2, "tyson": 1, "nando": 1, "de": 1, "freitas": 1}, {"bayesian": 1, "interactive": 1, "optimization": 1, "approach": 1, "procedural": 1, "animation": 1, "design": 1}, {"proceed": 1, "2010": 2, "acm": 1, "siggrapheurographics": 1, "symposium": 1, "computer": 1, "animation": 1, "page": 1, "103112": 1}, {"12": 1}]