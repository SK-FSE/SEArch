[{"neural": 2, "machine": 2, "translation": 3, "soft": 1, "prototype": 1, "": 6, "yiren": 2, "wang1": 1, "yingce": 1, "xia2": 1, "fei": 2, "tian3": 1, "gao4": 1, "tao": 1, "qin2": 1, "chengxiang": 1, "zhai1": 1, "tieyan": 1, "liu2": 1, "1": 2, "university": 1, "illinois": 1, "urbanachampaign": 1, "2": 2, "microsoft": 1, "research": 1, "3": 2, "facebook": 1, "4": 2, "institute": 1, "compute": 1, "technology": 1, "chinese": 1, "academy": 1, "sciences": 1, "czhaiillinoisedu": 1, "yingcexia": 1, "taoqin": 1, "tieyanliumicrosoftcom": 1, "feitiafbcom": 1, "gaofei17nictaccn": 1, "abstract": 1, "model": 1, "usually": 1, "use": 1, "encoderdecoder": 1, "framework": 1, "generate": 1, "leave": 2, "right": 2, "without": 1, "fully": 1, "utilize": 1, "targetside": 1, "global": 1, "information": 1}, {"recent": 1, "approach": 1, "seek": 1, "exploit": 1, "global": 1, "information": 1, "twopass": 1, "decode": 1, "yet": 1, "limitations": 1, "translation": 1, "quality": 1, "model": 1, "efficiency": 1}, {"work": 1, "propose": 1, "new": 1, "framework": 1, "introduce": 1, "soft": 1, "prototype": 1, "encoderdecoder": 1, "architecture": 1, "allow": 1, "decoder": 1, "indirect": 1, "access": 1, "past": 1, "future": 1, "information": 1, "target": 1, "word": 1, "generate": 1, "base": 1, "better": 1, "global": 1, "understand": 1}, {"provide": 1, "efficient": 1, "effective": 1, "method": 1, "generate": 1, "prototype": 1}, {"empirical": 1, "study": 1, "various": 1, "neural": 1, "machine": 1, "translation": 1, "task": 1, "show": 1, "approach": 1, "bring": 1, "substantial": 1, "improvement": 1, "generation": 1, "quality": 1, "baseline": 1, "model": 1, "little": 1, "extra": 1, "cost": 1, "storage": 1, "inference": 1, "time": 1, "demonstrate": 1, "effectiveness": 1, "propose": 1, "framework": 1}, {"specially": 1, "achieve": 1, "stateoftheart": 1, "result": 1, "wmt2014": 1, "2015": 1, "2017": 1, "englishgerman": 1, "translation": 1}, {"1": 2, "": 2, "introduction": 1, "neural": 1, "machine": 1, "translation": 1, "briefly": 1, "nmt": 1, "17": 1, "16": 1, "attract": 1, "much": 1, "research": 1, "attention": 1, "recently": 1}, {"major": 1, "approach": 1, "neural": 1, "machine": 1, "translation": 1, "also": 1, "sequence": 2, "generation": 1, "generate": 1, "target": 1, "onepass": 1, "decode": 1, "process": 1, "either": 1, "leave": 2, "right": 2, "17": 1, "1": 1, "15": 1}, {"translate": 1, "sentence": 2, "x": 2, "model": 1, "usually": 1, "condition": 1, "source": 1, "previously": 1, "generate": 2, "word": 2, "yt": 2, "tth": 1, "target": 1, "": 1}, {"one": 1, "limitation": 1, "onepass": 1, "process": 1, "generation": 1, "word": 1, "yt": 2, "use": 1, "partial": 1, "information": 2, "previously": 1, "generate": 1, "incomplete": 1, "sentence": 1, "": 6, "rather": 1, "consider": 1, "global": 1, "carry": 1, "complete": 1, "possible": 1, "target": 1, "candidate": 1, "0": 1, "y10": 1, "y20": 1, "yl0": 1}, {"global": 1, "information": 1, "target": 2, "domain": 1, "intuitively": 1, "beneficial": 1, "sequence": 1, "generation": 1, "since": 1, "word": 2, "sentence": 1, "consistent": 1, "surround": 1, "ie": 1}, {"word": 1}, {"different": 1, "approach": 1, "propose": 1, "leverage": 1, "global": 1, "information": 1, "overcome": 1, "limitation": 1, "include": 1, "introduce": 1, "additional": 1, "network": 1, "generate": 1, "intermediate": 2, "sequence": 2, "0": 2, "leave": 2, "right": 2, "18": 1, "12": 1, "20": 1, "21": 1, "retrieve": 1, "exist": 1, "corpus": 1, "5": 1, "4": 1, "11": 1}, {"approach": 1, "though": 1, "propose": 1, "different": 2, "task": 1, "settings": 1, "share": 1, "intrinsic": 1, "idea": 1, "introduce": 1, "prototype": 1, "sequence": 1, "standard": 1, "encoderdecoder": 1, "framework": 1}, {"example": 1, "intermediate": 1, "sequence": 1, "0": 1, "4": 1, "5": 1, "serve": 1, "prototype": 1}, {"generate": 2, "0": 2, "token": 1, "yt": 3, "": 3, "prototype": 1, "allow": 1, "decoder": 1, "indirect": 1, "access": 1, "previous": 1, "future": 1, "information": 1, "thus": 1, "tokens": 1, "base": 1, "good": 1, "global": 1, "understand": 1}, {"": 3, "work": 1, "conduct": 1, "microsoft": 1, "research": 1, "asia": 1}, {"correspond": 1, "author": 1}, {"33rd": 1, "conference": 1, "neural": 1, "information": 1, "process": 1, "systems": 1, "neurips": 1, "2019": 1, "vancouver": 1, "canada": 1}, {"intuitively": 1, "good": 2, "prototype": 3, "follow": 1, "properties": 1, "1": 1, "quality": 1, "ideal": 1, "highquality": 1, "representation": 1, "rich": 1, "global": 1, "information": 1, "low": 1, "variance": 1, "2": 1, "high": 1, "efficiency": 1, "easy": 1, "generate": 1, "little": 1, "additional": 1, "cost": 1, "time": 1, "storage": 1}, {"previous": 1, "prototypes": 1, "obtain": 1, "either": 1, "additional": 1, "decode": 1, "step": 1, "18": 1, "12": 1, "20": 1, "retrieve": 1, "large": 1, "corpus": 1, "4": 1, "5": 1, "11": 1, "relatively": 1, "good": 1, "quality": 1, "complete": 1, "global": 1, "information": 1, "inefficient": 1, "generate": 1}, {"furthermore": 1, "high": 2, "cost": 1, "prototype": 2, "generation": 1, "previous": 1, "approach": 1, "use": 1, "single": 1, "sequence": 1, "hard": 1, "practice": 1, "lead": 1, "variance": 1, "might": 1, "deteriorate": 1, "quality": 1, "eventual": 1, "output": 1}, {"paper": 1, "propose": 1, "new": 1, "framework": 1, "soft": 1, "prototype": 1, "leverage": 1, "target": 1, "side": 1, "global": 1, "information": 1}, {"soft": 1, "prototype": 1, "r": 1, "key": 1, "component": 1, "propose": 1, "framework": 1, "global": 1, "representation": 1, "calculate": 1, "multiple": 1, "instead": 1, "single": 1, "candidates": 1, "target": 1, "domain": 1}, {"source": 1, "sentence": 2, "x": 1, "soft": 1, "prototype": 1, "r": 1, "encode": 1, "higherlevel": 1, "contextual": 1, "representations": 1, "decode": 1, "generate": 1, "target": 1}, {"introduce": 1, "simple": 1, "yet": 1, "effective": 1, "solution": 1, "efficiently": 1, "obtain": 1, "soft": 1, "prototype": 1}, {"specifically": 1, "word": 3, "input": 1, "sequence": 1, "map": 2, "distribution": 1, "target": 2, "vocabulary": 1, "weight": 1, "average": 1, "embeddings": 1, "treat": 1, "expect": 1, "representation": 1, "prototype": 1, "r": 1, "probabilistic": 1, "manner": 2, "solution": 1, "help": 1, "reduce": 1, "variance": 1, "enrich": 1, "encode": 1, "information": 1, "wordlevel": 1, "nonautoregressive": 1, "guarantee": 1, "efficiency": 1}, {"framework": 1, "general": 1, "build": 1, "model": 1, "architectures": 1, "sequence": 1, "generation": 1, "include": 1, "lstm": 1, "17": 1, "cnn": 1, "3": 1, "transformer": 1, "16": 1, "etc": 1}, {"work": 1, "integrate": 1, "propose": 1, "soft": 1, "prototype": 1, "stateoftheart": 1, "transformer": 1, "16": 1, "model": 1, "evaluate": 1, "multiple": 1, "nmt": 2, "task": 1, "different": 1, "data": 1, "settings": 1, "include": 1, "supervise": 1, "semisupervised": 1, "unsupervised": 1}, {"experiment": 1, "show": 1, "method": 1, "significantly": 1, "improve": 1, "translation": 1, "quality": 1, "strong": 1, "transformer": 1, "baselines": 1}, {"furthermore": 1, "integrate": 1, "soft": 1, "prototype": 1, "sophisticate": 1, "translation": 2, "systems": 1, "result": 1, "stateoftheart": 1, "performances": 1, "wmt2014": 1, "2015": 1, "2017": 1, "englishtogerman": 1, "task": 1}, {"2": 1, "": 28, "background": 1, "give": 1, "two": 1, "domains": 1, "x": 3, "associate": 1, "vocabularies": 1, "vx": 2, "vy": 2, "respectively": 1, "denote": 1, "x1": 1, "x2": 1, "xlx": 1, "source": 1, "sentence": 2, "lx": 2, "tokens": 2, "xi": 1, "y1": 1, "y2": 1, "yly": 1, "target": 1, "ly": 2, "yj": 1, "j": 1}, {"sequence": 1, "generation": 1, "model": 1, "aim": 1, "learn": 1, "map": 1, "f": 1, "": 1, "x": 1, "7": 1}, {"context": 1, "neural": 1, "machine": 1, "translation": 1, "x": 1, "collections": 1, "sentence": 1, "two": 1, "different": 1, "languages": 1}, {"nmt": 1, "systems": 1, "adopt": 1, "encoderdecoder": 1, "framework": 1, "15": 1, "input": 1, "sequence": 1, "x": 2, "": 3, "firstly": 1, "process": 1, "encoder": 1, "enc": 1, "get": 1, "higherlevel": 1, "context": 1, "representations": 1, "feed": 1, "decoder": 1, "dec": 1, "generate": 1, "output": 1, "ie": 1, "decencx": 1}, {"enc": 1, "dec": 1, "specialize": 1, "use": 1, "different": 1, "neural": 1, "architectures": 1, "include": 1, "gru": 1, "1": 1, "lstm": 1, "17": 1, "cnn": 1, "3": 1, "transformer": 2, "16": 1, "among": 1, "recent": 1, "selfattention": 1, "base": 1, "stateoftheart": 1, "architecture": 1, "nmt": 1}, {"previous": 1, "approach": 1, "leverage": 1, "target": 1, "side": 1, "global": 1, "information": 1, "better": 1, "generation": 1, "quality": 1, "mostly": 1, "base": 1, "follow": 1, "formulation": 1, "x": 5, "p": 3, "yx": 1, "": 5, "yy": 1, "0": 6, "fe": 3, "g": 2, "1": 1, "generator": 1, "map": 2, "input": 1, "coarse": 1, "model": 1, "deliberatesrefines": 1, "usually": 1, "consist": 1, "three": 1, "part": 1, "two": 1, "encode": 1, "modules": 1, "use": 1, "extract": 1, "hide": 2, "representations": 2, "one": 1, "decode": 1, "module": 1, "eventual": 1, "output": 1}, {"differences": 1, "previous": 1, "work": 1, "lie": 1, "g": 1, "design": 1, "sequence": 2, "generator": 1, "decode": 1, "lefttoright": 1, "18": 1, "12": 1, "20": 1, "righttoleft": 1, "21": 1, "manner": 1, "retriever": 1, "sample": 1, "train": 1, "corpus": 1, "similar": 1, "x": 1, "5": 1, "4": 1, "11": 1}, {"directly": 1, "generate": 1, "sequence": 1, "follow": 1, "eqn": 1}, {"1": 1, "infeasible": 1, "give": 1, "exponentially": 1, "large": 1, "since": 1, "represent": 1, "possible": 1, "sequence": 1, "target": 1, "domain": 1}, {"therefore": 1, "previous": 1, "work": 1, "use": 1, "monte": 1, "carlo": 1, "base": 1, "estimation": 1, "instead": 1, "usually": 1, "estimate": 1, "single": 1, "sample": 1, "0": 1, "actual": 1, "implementation": 1}, {"sample": 1, "0": 2, "distribution": 1, "p": 4, "": 4, "x": 2, "g": 1, "approximate": 1, "yx": 2, "yy": 1, "fe": 1}, {"2": 1, "": 3, "3": 1, "approach": 1, "section": 2, "first": 1, "introduce": 1, "general": 1, "framework": 1, "soft": 1, "prototype": 1, "31": 1}, {"introduce": 1, "specific": 1, "solution": 1, "generate": 1, "effective": 1, "soft": 1, "prototype": 2, "efficiently": 1, "section": 2, "32": 1, "show": 1, "propose": 1, "integrate": 1, "transformer": 1, "16": 1, "model": 1, "33": 1}, {"31": 1, "": 3, "framework": 2, "general": 1, "prototype": 1, "sequence": 2, "learn": 1, "formulate": 1, "decencx": 1, "netr": 1}, {"2": 1, "": 1, "enc": 1, "dec": 1, "encoder": 1, "decoder": 1, "network": 2, "traditional": 1, "sequence": 2, "framework": 1, "net": 1, "additional": 1, "encode": 1, "prototype": 1, "r": 1, "higher": 1, "level": 1, "contextual": 1, "representation": 1}, {"prototype": 2, "r": 1, "matrix": 1, "r1": 1, "": 6, "r2": 1, "rl": 1, "size": 1, "l": 2, "row": 1, "ri": 1, "vector": 1, "calculate": 1, "base": 1, "one": 1, "multiple": 1, "0": 1, "length": 1, "dimension": 1, "hide": 1, "representation": 1}, {"define": 2, "ey": 1, "embed": 2, "target": 1, "domain": 1, "size": 1, "vy": 1, "": 2, "dimension": 1, "prototype": 1}, {"give": 1, "0": 3, "": 5, "let": 1, "1y": 1, "denote": 1, "correspond": 1, "2d": 1, "representation": 1, "size": 1, "ly0": 2, "vy": 1, "length": 1}, {"row": 1, "onehot": 1, "vector": 1, "word": 1, "yt": 1, "": 3, "ly0": 1}, {"soft": 1, "prototype": 1, "calculate": 1, "x": 2, "def": 1, "r": 1, "1y": 1, "0": 3, "ey": 1, "p": 2, "g": 2, "": 3, "gy": 1, "xey": 1, "3": 1, "generator3": 1}, {"define": 1, "gy": 1, "x": 2, "": 2, "y0": 1, "0": 2, "p": 1, "g": 1, "gyij": 1, "intuitively": 1, "probability": 1, "ith": 1, "representation": 1, "prototype": 1, "embed": 1, "jth": 1, "word": 1, "vy": 1}, {"framework": 1, "bias": 1, "approximation": 1, "eqn1": 1}, {"explain": 1, "section": 1, "2": 1, "eqn": 1}, {"1": 1, "intractable": 1, "calculate": 1, "due": 1, "follow": 1, "two": 1, "reason": 1, "exponentially": 1, "large": 1, "since": 1, "represent": 1, "possible": 1, "sentence": 1, "target": 1, "domain": 1, "ii": 1, "fe": 2, "usually": 1, "specialize": 1, "deep": 1, "neural": 1, "network": 1, "make": 1, "even": 1, "costly": 1, "compute": 1, "p": 1, "0": 1, "": 2, "x": 1}, {"framework": 1, "alleviate": 1, "issue": 1, "efficient": 1, "approximation": 1, "first": 1, "aggregate": 1, "potential": 1, "candidates": 1, "soft": 1, "prototype": 1, "r": 1, "calculate": 1, "eqn": 1}, {"3": 1, "generate": 1, "single": 1, "model": 1, "eqn2": 1}, {"need": 1, "calculate": 1, "probability": 1, "use": 1, "model": 1, "fe": 1, "instead": 1, "time": 1, "show": 1, "eqn1": 1}, {"previous": 1, "approach": 1, "usually": 1, "adopt": 1, "approximation": 1, "eqn": 1}, {"1": 1, "generatingretrieving": 1, "one": 1, "0": 1, "practical": 1, "implementations": 1, "reduce": 1, "high": 2, "computational": 1, "cost": 1, "introduce": 1, "variance": 1}, {"case": 1, "methods": 1, "fall": 1, "framework": 1, "different": 2, "solutions": 1, "generate": 1, "prototype": 1, "gy": 1, "x": 1}, {"specifically": 1, "construct": 2, "probabilistic": 1, "matrix": 1, "gy": 1, "x": 1, "row": 1, "gi": 1, "": 3, "1": 1, "2": 1, "l": 1, "onehot": 1, "vector": 1, "either": 1, "autoregressively": 1, "decode": 1, "sentence": 1, "18": 1, "21": 1, "retrieve": 1, "sequence": 1, "5": 1, "11": 1}, {"reformulate": 1, "previous": 1, "approach": 1, "framework": 1, "way": 1, "offer": 1, "us": 1, "better": 1, "understand": 1, "qualityefficiency": 1, "tradeoff": 1, "solution": 1, "design": 1, "gy": 1, "onehot": 1, "representation": 1, "simple": 1, "construct": 1, "yet": 1, "lead": 1, "high": 1, "variance": 1, "information": 1, "loss": 1, "potentially": 1, "limit": 1, "quality": 1, "final": 1, "generate": 1, "output": 1}, {"b": 1, "gy": 1, "": 1, "generate": 1, "autoregressive": 1, "decode": 1, "retrieval": 1, "provide": 1, "contextaware": 1, "representation": 1, "yet": 1, "lead": 1, "common": 1, "issue": 1, "low": 1, "efficiency": 1}, {"cost": 1, "generation": 1, "base": 2, "approach": 2, "18": 1, "21": 1, "12": 1, "come": 2, "autoregressive": 1, "decode": 1, "process": 1, "complexity": 1, "retrieval": 1, "5": 1, "4": 1, "search": 1, "exponentially": 1, "large": 1, "space": 1, "sequences4": 1, "": 1}, {"32": 1, "": 2, "efficient": 1, "generation": 1, "soft": 1, "prototype": 2, "good": 2, "quality": 1, "rich": 1, "global": 1, "information": 1, "low": 1, "variance": 1, "plus": 1, "high": 1, "efficiency": 1}, {"eqn": 1}, {"3": 1, "satisfy": 1, "first": 1, "one": 3, "general": 1, "still": 1, "suffer": 1, "low": 1, "efficiency": 1, "consider": 1, "exponentially": 1, "large": 1, "tokens": 1, "0": 1, "sequentially": 1, "generate": 1}, {"motivate": 1, "us": 1, "use": 1, "nonautoregressive": 1, "way": 1}, {"0": 2, "different": 1, "size": 2, "pad": 2, "largest": 1, "elements": 1, "zero": 1}, {"fact": 1, "due": 1, "high": 1, "cost": 1, "search": 1, "large": 1, "sequence": 1, "space": 1, "retrieval": 1, "base": 1, "approach": 1, "applicable": 1, "task": 1, "tremendous": 1, "number": 1, "candidates": 1, "like": 1, "nmt": 1}, {"therefore": 1, "focus": 1, "discuss": 1, "generation": 1, "base": 1, "approach": 1, "particular": 1, "representative": 1, "model": 1, "delibnet": 1, "18": 1, "rest": 1, "paper": 1}, {"3": 2, "": 5, "4": 1, "achieve": 1, "use": 1, "probability": 1, "generator": 1, "g": 1, "project": 1, "vx": 2, "vy": 1, "1dimensional": 1, "pvy": 1, "simplex": 1}, {"vx": 2, "": 14, "gvx": 1, "p1": 1, "p2": 1, "pvy": 1, "pj": 2, "0": 1, "j1": 1, "1": 1}, {"case": 1, "give": 1, "x": 2, "gy": 1, "lx": 2, "": 2, "vy": 1, "matrix": 1, "number": 1, "word": 1}, {"ith": 1, "row": 1, "gy": 1, "gxi": 1, "": 3, "lx": 1}, {"prototype": 1, "r": 1, "calculate": 1, "eqn": 1}, {"3": 1, "accurately": 1}, {"nonautoregressive": 1, "method": 2, "several": 1, "advantage": 1, "previous": 2, "better": 1, "efficiency": 1, "need": 1, "sum": 1, "exponentially": 1, "large": 1, "space": 1, "autoregressive": 1, "property": 1, "remove": 1, "b": 1, "richer": 2, "information": 2, "approach": 1, "refine": 1, "hard": 1, "prototype": 2, "represent": 1, "single": 1, "0": 1, "": 1, "soft": 1, "consist": 1, "multiple": 1, "candidate": 1, "translations": 1, "contribute": 1, "lower": 1, "variance": 1}, {"note": 1, "vy": 1, "large": 1, "save": 1, "estimate": 1, "g": 1, "become": 1, "expensive": 1}, {"adopt": 1, "approximation": 1, "strategy": 1, "alleviate": 1, "issue": 1, "sparse": 1, "probability": 1, "generator": 1, "g": 2, "": 5, "n": 1, "input": 1, "output": 1, "largest": 1, "probabilities": 1, "zero": 1, "remain": 1, "elements": 1}, {"output": 1, "normalize": 1, "sum": 1, "1": 1, "final": 1, "probability": 1, "generate": 1, "soft": 1, "prototype": 1}, {"33": 1, "": 2, "adaptation": 1, "transformer": 2, "show": 1, "propose": 1, "framework": 1, "soft": 1, "prototype": 1, "adapt": 1, "architecture": 1}, {"modify": 1, "model": 1, "illustrate": 1, "figure": 1, "1": 1}, {"omit": 1, "detail": 1, "transformer": 1, "give": 1, "highlevel": 1, "introduction": 1}, {"source": 1, "cod": 1, "include": 1, "supplementary": 1, "document": 1, "detail": 1, "find": 1, "transformersoftprotopy": 1}, {"soft": 1, "prototype": 1, "r": 1, "generate": 1, "probabilistic": 1, "generator": 1, "g": 2, "": 2, "follow": 1, "eqn3": 1}, {"prototype": 1, "encode": 2, "higherlevel": 1, "global": 1, "representations": 1, "h": 2, "": 2, "netr": 1, "input": 1, "sentence": 1, "x": 1, "encx": 1}, {"enc": 1, "net": 2, "specialize": 1, "llayer": 1, "transformer": 1, "encoders": 1, "module": 1, "lower": 1, "right": 1, "part": 1, "figure": 1}, {"b": 1, "two": 1, "context": 2, "representations": 1, "h": 2, "use": 1, "vectors": 1, "encoderdecoder": 1, "attention": 1, "transformer": 1, "decoder": 1}, {"specifically": 1, "let": 1, "slt": 1, "denote": 1, "output": 1, "lth": 1, "decoder": 1, "layer": 1, "step": 1, "0": 1, "s0j": 1, "de": 1, "figure": 1, "1": 1, "illustration": 1, "modify": 1, "transformer": 1, "note": 1, "embed": 1, "vector": 1, "jth": 1, "generate": 1, "soft": 1, "prototype": 1}, {"word": 1, "target": 1, "domain": 1}, {"let": 1, "fs": 1, "q": 2, "k": 2, "v": 2, "": 2, "fc": 1, "fn": 1, "h": 1, "denote": 1, "self": 1, "attention": 2, "layer": 3, "encoderdecoder": 1, "feedforward": 1, "respectively": 1}, {"selfattention": 1, "layer": 1, "require": 1, "query": 1, "q": 1, "key": 1, "k": 1, "value": 1, "v": 1, "input": 1}, {"detail": 1, "formulation": 1, "aforementioned": 1, "three": 1, "layer": 1, "leave": 1, "appendix": 1}, {"slt": 7, "obtain": 1, "follow": 1, "l1": 3, "": 26, "fs": 1, "sl1": 2, "stl1": 2, "st": 2, "fc": 2, "h": 4, "4": 1, "fn": 1, "l": 1, "1": 1, "s2": 1}, {"affine": 1, "transformation": 1, "later": 1, "apply": 1, "st": 1, "generate": 1, "word": 1, "yt": 1, "": 1}, {"sake": 1, "storage": 1, "train": 1, "efficiency": 1, "set": 1, "enc": 1, "": 1, "net": 1, "experiment": 1}, {"detail": 1, "study": 1, "parameter": 1, "reuse": 1, "present": 1, "appendix": 1, "b": 1}, {"discussion": 1, "1": 1, "storage": 1, "cost": 1, "parameter": 1, "reuse": 1, "ie": 1, "set": 1, "enc": 1, "": 1, "net": 1, "total": 1, "number": 1, "network": 1, "parameters": 1, "exactly": 1, "standard": 1, "transformer": 1}, {"additional": 2, "storage": 1, "cost": 1, "come": 1, "probabilistic": 1, "generator": 1, "g": 1, "": 4, "use": 1, "2vy": 1, "parameters": 1, "store": 1, "prototype": 1, "distribution": 1, "4": 1, "form": 1, "nonzero": 1, "word": 1, "id": 1, "probability": 1, "almost": 1, "negligible": 1, "compare": 1, "large": 1, "nmt": 1, "model": 1}, {"2": 1, "inference": 2, "efficiency": 1, "standard": 1, "transformer": 1, "large": 1, "portion": 1, "time": 1, "spend": 1, "decode": 1, "process": 1, "encode": 1, "stage": 1, "less": 1, "operations": 1, "allow": 1, "parallelism": 1}, {"therefore": 1, "new": 1, "approach": 1, "generate": 1, "soft": 1, "prototype": 1, "introduce": 1, "complexity": 1, "encoder": 1, "side": 1, "greatly": 1, "hamper": 1, "inference": 1, "efficiency": 1, "like": 1, "previous": 1, "generation": 1, "base": 1, "methods": 1}, {"compare": 1, "standard": 1, "model": 1, "method": 1, "introduce": 1, "34": 1, "additional": 1, "inference": 1, "time": 1, "delibnet": 1, "bring": 1, "80": 1}, {"present": 1, "detail": 1, "analysis": 1, "storage": 1, "cost": 1, "inference": 1, "efficiency": 1, "section": 1, "412": 1}, {"3": 1, "tokenlevel": 2, "translation": 1, "map": 1, "employ": 1, "maximum": 1, "efficiency": 1}, {"potential": 1, "issue": 1, "translate": 1, "middle": 2, "bpe": 1, "tokens": 2, "impact": 1, "relatively": 1, "small": 1, "give": 1, "vocabulary": 1, "train": 1, "corpus": 1, "dominant": 1, "standard": 1, "word": 1, "rather": 1}, {"example": 1, "65": 1, "vocabulary": 1, "wmt14": 1, "ende": 1, "standard": 1, "word": 2, "make": 2, "88": 1, "total": 1, "frequency": 1, "train": 1, "corpus": 1, "b": 1, "soft": 1, "prototype": 1, "r": 1, "feed": 1, "net": 1, "encode": 1, "higherlevel": 1, "contextual": 1, "representations": 1, "intuitively": 1, "provide": 1, "rich": 1, "global": 1, "information": 1, "help": 1, "decoder": 1, "decision": 1}, {"4": 1, "": 2, "experiment": 1, "section": 1, "present": 1, "empirical": 1, "study": 1, "propose": 1, "framework": 1, "multiple": 1, "task": 1, "across": 1, "different": 1, "set": 1, "include": 1, "supervise": 1, "semisupervised": 1, "unsupervised": 1, "nmt": 1}, {"41": 1, "": 2, "supervise": 2, "nmt": 1, "first": 1, "study": 1, "effectiveness": 1, "framework": 1, "set": 1, "align": 1, "bilingual": 1, "data": 1}, {"datasets": 2, "experiment": 1, "two": 1, "large": 1, "scale": 1, "widely": 1, "adopt": 1, "benchmark": 1, "wmt2014": 2, "english": 2, "german": 1, "news": 2, "translation": 2, "ende": 1, "french": 1, "enfr": 1}, {"use": 1, "45m": 1, "bilingual": 1, "sentence": 1, "pair": 2, "train": 1, "data": 1, "ende": 1, "36m": 1, "enfr5": 1, "": 1}, {"use": 1, "concatenation": 1, "newstest2012": 1, "newstest2013": 1, "validation": 1, "set": 2, "6003": 1, "sentence": 2, "newstest2014": 1, "test": 1, "3003": 1}, {"word": 1, "split": 1, "subword": 1, "units": 1, "use": 1, "byte": 1, "pair": 1, "encode": 1, "bpe": 1, "14": 1, "form": 1, "vocabulary": 1, "32k": 1, "45k": 1, "ende": 1, "enfr": 1, "respectively": 1}, {"vocabulary": 1, "share": 1, "among": 1, "source": 1, "target": 1, "languages": 1}, {"model": 1, "use": 1, "transformerbig": 1, "set": 1, "follow": 1, "16": 1, "6layer": 2, "encoder": 1, "decoder": 1}, {"dimension": 1, "word": 1, "embeddings": 1, "hide": 1, "state": 1, "filter": 1, "size": 1, "1024": 2, "4096": 1, "respectively": 1}, {"dropout": 1, "03": 1, "ende": 1, "01": 1, "enfr": 1}, {"model": 1, "train": 1, "8": 1, "m40": 1, "gpus": 1, "10": 1, "days": 2, "ende": 1, "21": 1, "enfr": 1}, {"": 1, "fix": 1, "3": 1, "across": 1, "task": 1}, {"use": 2, "beam": 1, "size": 1, "4": 1, "length": 1, "penalty": 1, "06": 1, "inference": 1, "multibleu6": 1, "evaluate": 1, "quality": 1, "translation": 1}, {"optimization": 2, "use": 2, "adam": 1, "7": 1, "learn": 1, "rate": 1, "scheduler": 1, "16": 1}, {"model": 2, "p": 2, "prototype": 1, "initialize": 1, "follow": 1, "1": 1, "standard": 1, "nmt": 1, "f0": 2, "pretrained": 1, "maximize": 1, "xyx": 1, "log": 1, "yx": 1, "": 1}, {"stop": 1, "criterion": 1, "validation": 1, "bleu": 1, "improve": 1, "10k": 1, "iterations": 1, "output": 1, "f0": 1, "": 1}, {"2": 1, "define": 1, "gij": 1, "": 9, "p": 1, "wj": 2, "vi": 2, "f0": 2, "vx": 1, "vy": 1, "convert": 1, "g": 3, "sparse": 1, "probabilistic": 1, "probabilisitc": 1, "generator": 1, "3": 1, "modify": 1, "transformer": 1, "soft": 1, "prototype": 1, "train": 1, "use": 1, "initialize": 1, "new": 1, "model": 1}, {"411": 1, "": 2, "result": 2, "ende": 1, "enfr": 1, "translations": 1, "present": 1, "table": 1, "1": 1}, {"compare": 1, "performances": 1, "multiple": 1, "systems": 1, "1": 1, "transformer": 6, "baseline": 1, "2": 1, "model": 1, "hard": 1, "prototype": 2, "include": 1, "delibnet": 4, "stack": 1, "lstm": 1, "report": 1, "18": 1, "implement": 1, "": 2, "fair": 1, "comparison": 1, "3": 1, "soft": 1, "softprototype": 1}, {"5": 1, "": 1, "data": 1, "filtration": 1, "rule": 1, "httpsgooglsg9hlh": 1}, {"httpsgithubcommosessmtmosesdecoderblobmasterscriptsgenericmultibleu": 1}, {"perl": 1, "6": 1, "": 2, "5": 1, "table": 1, "1": 1, "result": 1, "wmt2014": 1, "ende": 1, "fr": 1, "translations": 1}, {"": 1, "denote": 1, "result": 1, "implementation": 1, "slightly": 1, "better": 1, "report": 1, "value": 1, "16": 1}, {"params": 1, "denote": 1, "number": 1, "model": 1, "parameters": 1, "ende": 1}, {"inference": 1, "time": 2, "measure": 1, "total": 1, "decode": 1, "one": 1, "m40": 1, "gpu": 1, "ende": 1, "newstest2014": 1, "3003": 1, "sentence": 1, "batch": 1, "size": 2, "128": 1, "beam": 1, "4": 1}, {"ende": 1, "transformer": 3, "16": 1, "delibnet": 2, "18": 1, "": 18, "softprototype": 1, "enfr": 1, "284": 1, "2868": 1, "2911": 1, "2946": 1, "418": 1, "4185": 1, "4150": 1, "4258": 1, "4299": 1, "params": 1, "inference": 1, "time": 1, "200m": 1, "372m": 1, "2002m": 1, "116s": 1, "207s": 1, "156s": 1, "result": 1, "observe": 1, "1": 1, "introduce": 1, "target": 1, "side": 1, "prototype": 1, "leverage": 1, "global": 1, "information": 1, "significantly": 1, "boost": 1, "model": 1, "performance": 1}, {"different": 1, "prototypes": 1, "either": 1, "hard": 1, "manner": 1, "soft": 1, "lead": 1, "improvements": 1, "translation": 1, "quality": 1, "statistically": 1, "significant": 1, "p": 1, "": 1, "001": 1, "pair": 1, "bootstrap": 1, "sampling7": 1, "8": 1}, {"2": 1, "propose": 1, "approach": 1, "generate": 1, "soft": 1, "prototype": 1, "achieve": 1, "better": 2, "performances": 1, "efficiency": 1, "compare": 1, "twopass": 1, "decode": 1, "delibnet": 1}, {"present": 1, "detail": 1, "study": 1, "discussion": 1, "section": 1, "412": 1}, {"412": 1, "": 2, "analysis": 1, "present": 1, "multiple": 1, "study": 1, "thoroughly": 1, "analyze": 1, "propose": 1, "framework": 1, "soft": 1, "prototype": 1, "include": 1, "traininginference": 1, "efficiency": 1, "translation": 1, "quality": 1}, {"inference": 1, "efficiency": 1}, {"report": 1, "number": 1, "model": 1, "parameters": 1, "total": 1, "inference": 1, "time": 1, "decode": 1, "3003": 1, "sentence": 1, "table": 1, "1": 1}, {"see": 1, "1": 1, "delibnet": 1, "extra": 1, "decoder": 1, "softmax": 1, "layer": 1, "introduce": 1, "86": 1, "additional": 1, "parameters": 1, "standard": 1, "transformer": 1, "increase": 1, "inference": 1, "time": 1, "80": 1}, {"2": 1, "transformersoftprototype": 1, "efficient": 1, "way": 1, "term": 1, "inference": 1, "time": 1, "storage": 2, "cost": 1, "01": 1, "additional": 1, "g": 1, "": 2}, {"method": 1, "double": 1, "encode": 2, "time": 1, "source": 1, "sequence": 1, "prototype": 1}, {"encode": 1, "far": 1, "less": 1, "expensive": 1, "decode": 1, "inference": 2, "nmt": 1, "increase": 1, "time": 1, "smaller": 1, "34": 1}, {"train": 1, "efficiency": 1}, {"since": 1, "use": 1, "pretrained": 1, "baseline": 1, "model": 1, "warm": 1, "start": 1, "additional": 1, "train": 1, "cost": 1, "high": 1}, {"pretraining": 1, "take": 2, "60": 1, "gpu": 2, "days": 2, "ende": 1, "propose": 1, "soft": 1, "prototype": 1, "extra": 1, "20": 1, "warm": 1, "start": 1, "result": 1, "total": 1, "13x": 1, "time": 1, "significant": 1, "performance": 1, "improvement": 1}, {"study": 1, "parameter": 1, "reuse": 1}, {"study": 1, "influence": 1, "parameter": 1, "reuse": 1, "approach": 1, "ie": 1, "parameters": 1, "enc": 1, "net": 1}, {"compare": 1, "performances": 1, "wmt2014": 1, "ende": 1, "two": 2, "settings": 1, "share": 1, "set": 2, "enc": 2, "": 2, "net": 2, "one": 1, "fc": 2, "b": 1, "nonshare": 1, "independent": 1, "separate": 1, "eqn4": 1}, {"bleu": 1, "score": 1, "share": 1, "nonshare": 1, "settings": 1, "2946": 1, "2945": 1, "respectively": 1, "almost": 1, "identical": 1}, {"indicate": 1, "improvements": 1, "approach": 1, "bring": 1, "soft": 1, "prototype": 1, "instead": 1, "introduce": 1, "model": 1, "parameters": 1}, {"set": 1, "netenc": 1, "experiment": 2, "minimize": 1, "total": 1, "number": 1, "parameters": 1, "rest": 1}, {"however": 1, "worth": 1, "point": 1, "inherent": 1, "setup": 1, "propose": 1, "approach": 1}, {"net": 1, "generally": 1, "share": 2, "parameters": 1, "enc": 1, "even": 1, "use": 1, "different": 1, "network": 1, "architecture": 1, "eg": 1}, {"different": 1, "number": 1, "layer": 1, "": 1, "hide": 1, "dimension": 1, "etc": 1}, {"case": 1, "study": 1}, {"present": 1, "two": 1, "examples": 1, "wmt2014": 1, "ende": 1, "task": 1, "illustrate": 1, "method": 1, "produce": 1, "better": 1, "translation": 1, "result": 1}, {"examples": 1, "present": 1, "table": 1, "2": 1, "include": 1, "source": 1, "sentence": 1, "reference": 1, "ie": 1}, {"grind": 1, "truth": 1, "translation": 2, "give": 1, "standard": 1, "transformer": 3, "hard": 1, "prototype": 2, "delibnet": 1, "soft": 1, "softproto": 1}, {"see": 1, "two": 2, "examples": 1, "propose": 1, "framework": 1, "soft": 1, "prototype": 1, "improve": 1, "translation": 1, "quality": 1, "ways": 1, "better": 1, "capture": 1, "content": 1, "input": 1, "sentence": 1}, {"first": 1, "example": 1, "semantic": 1, "talk": 1, "child": 1, "miss": 1, "transformer": 1, "baseline": 1, "two": 1, "methods": 1, "prototype": 1, "successfully": 1, "capture": 1, "mean": 1}, {"similarly": 1, "second": 1, "example": 1, "softproto": 1, "one": 1, "correctly": 1, "reveal": 1, "relation": 1, "christian": 1, "strbele": 1, "green": 1, "party": 1, "mp": 1, "whereas": 1, "standard": 1, "7": 1, "": 3, "httpsgithubcommosessmtmosesdecoderblobmasterscriptsanalysis": 1, "bootstraphypothesisdifferencesignificancepl": 1, "6": 1, "table": 1, "2": 1, "translation": 1, "examples": 1, "wmt2014": 1, "ende": 1, "task": 1}, {"use": 2, "italic": 1, "fonts": 2, "red": 1, "indicate": 1, "sentence": 2, "piece": 1, "accurate": 2, "bond": 1, "blue": 1, "highlight": 1, "translations": 1, "underline": 1, "correspond": 1, "content": 1, "source": 1}, {"source": 2, "reference": 2, "transformer": 2, "delibnet": 2, "softprototype": 2, "": 6, "parent": 1, "hesitate": 1, "get": 1, "guidance": 1, "pediatrician": 1, "talk": 1, "child": 1}, {"eltern": 1, "sollten": 2, "nicht": 1, "zgern": 1, "": 3, "sich": 1, "von": 1, "ihrem": 2, "kinderarzt": 1, "beraten": 1, "zu": 1, "lassen": 1, "wie": 1, "sie": 1, "mit": 1, "kind": 1, "sprechen": 1}, {"eltern": 1, "sollten": 1, "nicht": 1, "zgern": 1, "": 2, "sich": 1, "von": 1, "ihrem": 1, "kinderarzt": 1, "beraten": 1, "zu": 1, "lassen": 1}, {"eltern": 1, "sollten": 1, "nicht": 1, "zgern": 1, "": 3, "sich": 1, "von": 1, "ihrem": 2, "kinderarzt": 1, "beraten": 1, "zu": 1, "lassen": 1, "wie": 1, "man": 1, "mit": 1, "kind": 1, "spricht": 1}, {"eltern": 1, "sollten": 1, "nicht": 1, "zgern": 1, "": 3, "sich": 1, "von": 1, "ihrem": 2, "kinderarzt": 1, "beraten": 1, "zu": 1, "lassen": 1, "wie": 1, "sie": 1, "mit": 1, "kind": 1, "sprechen": 1, "knnen": 1}, {"accord": 1, "green": 1, "party": 1, "mp": 1, "": 1}, {"hans": 1, "": 3, "christian": 1, "strbele": 1, "surprise": 1, "meet": 1, "snowden": 1, "russia": 1, "address": 1, "condition": 1, "former": 1, "secret": 1, "service": 1, "employee": 1, "would": 1, "make": 1, "statement": 1, "german": 1, "district": 1, "attorney": 1, "investigation": 1, "committee": 1}, {"nach": 1, "darstellung": 1, "des": 1, "grnen": 1, "": 5, "bundestagsabgeordneten": 1, "hans": 1, "christian": 1, "strbele": 1, "ging": 1, "es": 1, "bei": 2, "seinem": 1, "berraschenden": 1, "treffen": 1, "mit": 1, "snowden": 1, "russland": 1, "darum": 1, "unter": 1, "welchen": 1, "bedingungen": 1, "der": 1, "ex": 1, "geheimdienstmitarbeiter": 1, "einer": 1, "deutschen": 1, "staatsanwaltschaft": 1, "oder": 1, "vor": 1, "einem": 1, "untersuchungsausschuss": 1, "aussagen": 1, "wrde": 1}, {"seinem": 1, "berraschenden": 1, "treffen": 1, "mit": 2, "snowden": 1, "russland": 1, "befasste": 1, "sich": 1, "hans": 1, "": 4, "christian": 1, "strbele": 1, "nach": 1, "ansicht": 1, "des": 2, "abgeordneten": 1, "der": 1, "grnen": 1, "partei": 1, "den": 1, "bedingungen": 1, "unter": 1, "denen": 1, "ehemalige": 1, "mitarbeiter": 1, "geheimdienstes": 1, "vor": 2, "einem": 2, "deutschen": 1, "bezirksstaatsanwalt": 1, "oder": 1, "untersuchungsausschuss": 1, "stellung": 1, "nehmen": 1, "wrde": 1}, {"seinem": 1, "berraschenden": 1, "treffen": 1, "mit": 1, "snowden": 1, "russland": 1, "errterte": 1, "hans": 1, "": 3, "christian": 1, "strbele": 1, "die": 1, "bedingungen": 1, "unter": 1, "denen": 1, "der": 1, "ehemalige": 1, "mitarbeiter": 1, "des": 1, "geheimdienstes": 1, "eine": 1, "erklrung": 1, "vor": 2, "einem": 2, "deutschen": 1, "bezirksstaatsanwalt": 1, "oder": 1, "untersuchungsausschuss": 1, "abgeben": 1, "wrde": 1}, {"laut": 1, "dem": 1, "grnen": 1, "": 4, "abgeordneten": 1, "hans": 1, "christian": 1, "strbele": 1, "ging": 1, "es": 1, "bei": 1, "seinem": 1, "berraschenden": 1, "treffen": 1, "mit": 1, "snowden": 1, "russland": 1, "um": 1, "die": 1, "bedingungen": 1, "unter": 1, "denen": 1, "ein": 1, "ehemaliger": 1, "geheimdienstmitarbeiter": 1, "vor": 2, "einem": 2, "deutschen": 1, "bezirksanwalt": 1, "oder": 1, "untersuchungsausschuss": 1, "eine": 1, "erklrung": 1, "abgibt": 1}, {"translation": 1, "clear": 1, "person": 1, "green": 1, "party": 1, "mp": 1}, {"conjecture": 1, "soft": 1, "prototype": 1, "global": 1, "information": 1, "target": 1, "side": 1, "enhance": 1, "particularly": 1, "helpful": 1, "generation": 1, "longer": 1, "harder": 1, "sentence": 1}, {"b": 1, "accurate": 1, "selection": 1, "word": 1}, {"first": 1, "example": 1, "sie": 1, "better": 1, "translation": 1, "man": 1, "output": 1, "delibnet": 1}, {"second": 1, "example": 1, "mitarbeiter": 1, "geheimdienstmitarbeiter": 1, "mean": 2, "employee": 2, "latter": 1, "softproto": 1, "accurately": 1, "express": 1, "secret": 1, "service": 1}, {"however": 1, "softproto": 1, "still": 1, "limitation": 1}, {"example": 1, "word": 1, "ein": 2, "ehemaliger": 1, "geheimdienstmitarbeiter": 1, "former": 1, "secret": 1, "service": 1, "employee": 1, "der": 1, "instead": 1, "since": 1, "refer": 1, "snowden": 1, "particular": 1}, {"quantitative": 1, "study": 1, "wrt": 1}, {"sentence": 1, "length": 1}, {"conduct": 1, "follow": 1, "error": 1, "analysis": 1, "wmt2014": 1, "ende": 1, "task": 1}, {"break": 1, "sentence": 4, "dev": 1, "set": 1, "two": 2, "group": 1, "long": 1, "length": 2, "": 2, "40": 1, "vs": 1, "short": 1, "20": 1, "base": 1, "source": 1, "measure": 1, "performances": 1, "subsets": 1}, {"method": 2, "achieve": 1, "037": 1, "bleu": 2, "gain": 2, "short": 1, "subset": 2, "157": 1, "long": 1, "baseline": 1, "roughly": 1, "demonstrate": 1, "particularly": 1, "helpful": 1, "generation": 1, "longer": 1, "harder": 1, "sentence": 1}, {"42": 1, "": 2, "semisupervised": 2, "nmt": 1, "study": 1, "set": 1, "bilingual": 1, "monolingual": 1, "data": 1}, {"set": 1, "directly": 1, "apply": 1, "framework": 2, "stateoftheart": 1, "translation": 2, "systems": 1, "verify": 1, "whether": 1, "generally": 1, "contribute": 1, "improve": 1, "quality": 1}, {"7": 1, "": 1, "table": 1, "3": 1, "detokenized": 1, "bleu": 1, "score": 1, "various": 1, "test": 1, "set": 1, "wmt": 1, "ende": 1, "translation": 1}, {"stand": 2, "single": 1, "model": 1, "performance": 1, "e": 1, "ensemble": 1}, {"model": 2, "": 30, "newstest14": 1, "newstest15": 1, "newstest16": 1, "newstest17": 1, "newstest18": 1, "fair": 2, "2": 3, "softprototype": 2, "3267": 1, "016": 1, "3325": 1, "021": 2, "3389": 1, "3467": 1, "026": 1, "3704": 1, "017": 1, "3835": 1, "025": 1, "3186": 1, "022": 1, "3288": 1, "018": 1, "4463": 1, "013": 1, "4628": 1, "027": 1, "msmarian": 1, "6": 2, "e": 3, "3369": 1, "340": 1, "3473": 1, "357": 1, "396": 1, "3799": 1, "394": 1, "319": 1, "3280": 1, "337": 1, "483": 1, "4605": 1, "481": 1, "configuration": 1, "work": 1, "powerful": 1, "ende": 1, "translation": 1, "release": 1, "fair8": 1, "well": 1, "train": 2, "128": 1, "gpus": 1, "semisupervised": 1, "set": 1, "518m": 1, "bitext": 1, "226m": 1, "monolingual": 1, "sentence": 1, "use": 1, "data": 1}, {"leverage": 1, "model": 1, "generate": 1, "probability": 1, "g": 1, "": 3, "3": 1, "initialization": 1, "modify": 1, "transformer": 1, "soft": 1, "prototype": 1}, {"train": 1, "model": 1, "8": 1, "m40": 1, "gpus": 1, "45m": 1, "bitext": 1, "wmt2014": 1, "ende": 1, "another": 1, "15": 1, "days": 1}, {"report": 1, "single": 1, "model": 2, "performances": 1, "mean": 1, "standard": 1, "derivation": 1, "six": 1, "ensemble": 1, "result": 1, "different": 1, "run": 1}, {"compare": 1, "model": 1, "finetuned": 1, "soft": 1, "prototype": 1, "two": 1, "systems": 1, "represent": 1, "stateoftheart": 1, "include": 1, "fair": 1, "2": 1, "wmt2018": 1, "champion": 1, "system": 1, "msmarian": 1, "6": 1}, {"translations": 1, "generate": 1, "beam": 1, "size": 1, "5": 1, "length": 1, "penalty": 1, "10": 1, "model": 1, "evaluate": 1, "various": 1, "test": 1, "set": 1, "newstest20142018": 1, "sacrebleu9": 1, "": 1}, {"result": 2, "observe": 1, "table": 1, "3": 1, "1": 1, "framework": 1, "improve": 1, "model": 1, "performances": 1, "large": 1, "margin": 1}, {"compare": 1, "2": 2, "performances": 1, "single": 1, "model": 2, "boost": 1, "10": 1, "bleu": 2, "score": 2, "average": 1, "ensemble": 1, "improve": 1}, {"2": 1, "achieve": 1, "stateoftheart": 1, "result": 1, "newstest2014": 1, "2015": 1, "2017": 1}, {"observations": 1, "demonstrate": 1, "propose": 1, "framework": 1, "target": 1, "side": 1, "soft": 1, "prototype": 1, "capable": 1, "enhance": 1, "translation": 2, "qualities": 1, "even": 1, "powerful": 1, "systems": 1}, {"43": 1, "": 2, "unsupervised": 2, "nmt": 2, "apply": 1, "framework": 1, "scenario": 1, "recent": 1, "popular": 1, "research": 1, "direction": 1, "aim": 1, "learn": 1, "translation": 1, "model": 1, "without": 1, "access": 1, "parallel": 1, "train": 1, "data": 1}, {"datasets": 1, "experiment": 1, "wmt2016": 1, "ende": 1, "translation": 1}, {"use": 1, "50m": 1, "monolingual": 1, "sentence": 1, "language": 1, "newscrawl": 1, "20072017": 1, "train": 1, "data": 1, "follow": 1, "10": 1, "report": 1, "multibleu": 1, "score": 1, "newstest2016": 1}, {"configuration": 1, "use": 1, "base": 1, "transformer": 1, "set": 2, "follow": 1, "10": 1, "number": 1, "layer": 1, "embed": 1, "dimension": 2, "hide": 1, "filter": 1, "size": 1, "4": 1, "512": 2, "2048": 1, "respectively": 1}, {"set": 1, "": 4, "3": 1, "g": 1}, {"table": 1, "4": 1, "result": 1, "unsupervised": 1, "nmt": 1, "wmt2016": 1, "ende": 1}, {"": 1, "denote": 1, "implementation": 1, "slightly": 1, "better": 1, "report": 1, "value": 1, "10": 1}, {"model": 1, "ende": 1, "deen": 1, "": 1, "result": 2, "nmt": 1, "base": 1, "unsupervised": 1, "9": 1, "964": 1, "1333": 1, "translation": 1, "show": 1, "table": 1, "4": 1}, {"base": 1, "19": 1, "1086": 1, "1462": 1, "line": 1, "10": 2, "performances": 1, "improve": 1, "1716": 1, "": 2, "1764": 1, "2100": 1, "2224": 1, "method": 1, "large": 1, "margin": 1, "15": 1, "bleu": 1, "softprototype": 1, "1923": 1, "2378": 1, "directions": 1}, {"meanwhile": 1, "aware": 1, "leverage": 1, "statistical": 1, "machine": 1, "translation": 1, "smt": 2, "techniques": 1, "could": 1, "improve": 1, "unsupervised": 1, "nmt": 1, "13": 1, "10": 1, "leave": 1, "combination": 1, "framework": 1, "future": 1, "work": 1}, {"8": 1, "": 1, "httpsdlfbaipublicfilescomfairseqmodelswmt18endeensembletarbz2": 1}, {"sacrebleu": 1, "signature": 1, "bleucasemixedlangendenumrefs1smoothexptestwmtset": 1, "tok13aversion1211": 1, "set1415161718": 1}, {"9": 1, "": 4, "8": 1, "5": 1, "conclusion": 1, "future": 1, "work": 2, "propose": 1, "general": 1, "framework": 1, "target": 1, "side": 1, "soft": 1, "prototype": 1}, {"discuss": 1, "previous": 1, "twopass": 1, "decode": 1, "base": 1, "approach": 1, "adapt": 1, "framework": 1, "different": 1, "prototypes": 1, "propose": 1, "alternative": 1, "way": 1, "generate": 1, "prototype": 1, "expect": 1, "semantic": 1, "representations": 1}, {"experiment": 1, "show": 1, "framework": 1, "bring": 1, "significant": 1, "improvements": 1, "generation": 1, "quality": 1, "reasonable": 1, "increase": 1, "storage": 1, "inference": 1, "time": 1}, {"evaluate": 1, "method": 1, "extensive": 1, "empirical": 1, "study": 1, "multiple": 1, "different": 1, "task": 1, "achieve": 1, "stateoftheart": 1, "result": 1, "wmt2014": 1, "2015": 1, "2017": 1, "ende": 1, "translation": 1}, {"propose": 1, "framework": 1, "soft": 1, "prototype": 1, "general": 1, "widely": 1, "applicable": 1, "almost": 1, "model": 1, "architectures": 1, "sequence": 1, "generation": 1, "task": 1, "limit": 1, "nmt": 1, "explore": 1, "future": 1}, {"different": 1, "approach": 1, "use": 1, "generate": 1, "soft": 1, "prototype": 1}, {"explore": 1, "construct": 1, "soft": 1, "prototype": 1, "better": 1, "quality": 1, "contextaware": 1, "manner": 1, "efficiently": 1, "another": 1, "interest": 1, "valuable": 1, "future": 1, "work": 1, "direction": 1}, {"reference": 1, "1": 1, "dzmitry": 1, "bahdanau": 1, "kyunghyun": 1, "cho": 1, "yoshua": 1, "bengio": 1}, {"neural": 1, "machine": 1, "translation": 1, "jointly": 1, "learn": 1, "align": 1, "translate": 1}, {"iclr": 1, "2015": 1}, {"2": 1, "sergey": 1, "edunov": 1, "myle": 1, "ott": 1, "michael": 1, "auli": 1, "david": 1, "grangier": 1}, {"understand": 1, "backtranslation": 1, "scale": 1}, {"emnlp": 1, "2018": 1}, {"3": 1, "jonas": 1, "gehring": 1, "michael": 1, "auli": 1, "david": 1, "grangier": 1, "denis": 1, "yarats": 1, "yann": 1, "n": 1, "dauphin": 1}, {"convolutional": 1, "sequence": 2, "learn": 1}, {"icml": 1, "2017": 1}, {"4": 1, "kelvin": 1, "guu": 1, "tatsunori": 1, "b": 1, "hashimoto": 1, "yonatan": 1, "oren": 1, "percy": 1, "liang": 1}, {"generate": 1, "sentence": 1, "edit": 1, "prototypes": 1}, {"transactions": 1, "association": 1, "computational": 1, "linguistics": 1, "6437450": 1, "2018": 1}, {"5": 1, "tatsunori": 1, "b": 1, "hashimoto": 1, "kelvin": 1, "guu": 1, "yonatan": 1, "oren": 1, "percy": 1, "liang": 1}, {"retrieveandedit": 1, "framework": 1, "predict": 1, "structure": 1, "output": 1}, {"advance": 1, "neural": 1, "information": 1, "process": 1, "systems": 1, "page": 1, "1007310083": 1, "2018": 1}, {"6": 1, "marcin": 1, "junczysdowmunt": 1}, {"microsofts": 1, "submission": 1, "wmt2018": 1, "news": 1, "translation": 1, "task": 1, "learn": 1, "stop": 1, "worry": 1, "love": 1, "data": 1}, {"arxiv": 1, "preprint": 1, "arxiv180900196": 1, "2018": 1}, {"7": 1, "diederik": 1, "p": 1, "kingma": 1, "jimmy": 1, "ba": 1}, {"adam": 1, "method": 1, "stochastic": 1, "optimization": 1}, {"arxiv": 1, "preprint": 1, "arxiv14126980": 1, "2014": 1}, {"8": 1, "philipp": 1, "koehn": 1}, {"statistical": 1, "significance": 1, "test": 1, "machine": 1, "translation": 1, "evaluation": 1}, {"proceed": 1, "2004": 2, "conference": 1, "empirical": 1, "methods": 1, "natural": 1, "language": 1, "process": 1}, {"9": 1, "guillaume": 1, "lample": 1, "alexis": 1, "conneau": 1, "ludovic": 1, "denoyer": 1, "marcaurelio": 1, "ranzato": 1}, {"unsupervised": 1, "machine": 1, "translation": 1, "use": 1, "monolingual": 1, "corpora": 1}, {"iclr": 1, "2018": 1}, {"10": 1, "guillaume": 1, "lample": 1, "myle": 1, "ott": 1, "alexis": 1, "conneau": 1, "ludovic": 1, "denoyer": 1, "marcaurelio": 1, "ranzato": 1}, {"phrasebased": 1, "": 1, "neural": 1, "unsupervised": 1, "machine": 1, "translation": 1}, {"proceed": 1, "2018": 2, "conference": 1, "empirical": 1, "methods": 1, "natural": 1, "language": 1, "process": 1, "emnlp": 1}, {"11": 1, "juncen": 1, "li": 1, "robin": 1, "jia": 1, "percy": 1, "liang": 1}, {"delete": 1, "retrieve": 1, "generate": 1, "simple": 1, "approach": 1, "sentiment": 1, "style": 1, "transfer": 1}, {"arxiv": 1, "preprint": 1, "arxiv180406437": 1, "2018": 1}, {"12": 1, "jan": 1, "niehues": 1, "eunah": 1, "cho": 1, "thanhle": 1, "ha": 1, "alex": 1, "waibel": 1}, {"pretranslation": 1, "neural": 1, "machine": 1, "translation": 1}, {"proceed": 1, "coling": 1, "2016": 1, "26th": 1, "international": 1, "conference": 1, "computational": 1, "linguistics": 1, "technical": 1, "paper": 1, "page": 1, "18281836": 1}, {"coling": 1, "2016": 2, "organize": 1, "committee": 1}, {"13": 1, "shuo": 1, "ren": 1, "zhirui": 1, "zhang": 1, "shujie": 1, "liu": 1, "ming": 1, "zhou": 1, "shuai": 1}, {"unsupervised": 1, "neural": 1, "machine": 1, "translation": 1, "smt": 1, "posterior": 1, "regularization": 1}, {"aaai": 1, "2019": 1}, {"14": 1, "rico": 1, "sennrich": 1, "barry": 1, "haddow": 1, "alexandra": 1, "birch": 1}, {"neural": 1, "machine": 1, "translation": 1, "rare": 1, "word": 1, "subword": 1, "units": 1}, {"acl": 1, "2016": 1}, {"9": 1, "": 1, "15": 1, "ilya": 1, "sutskever": 1, "oriol": 1, "vinyals": 1, "quoc": 1, "v": 1, "le": 1}, {"sequence": 2, "learn": 1, "neural": 1, "network": 1}, {"advance": 1, "neural": 1, "information": 1, "process": 1, "systems": 1, "page": 1, "31043112": 1, "2014": 1}, {"16": 1, "ashish": 1, "vaswani": 1, "noam": 1, "shazeer": 1, "niki": 1, "parmar": 1, "jakob": 1, "uszkoreit": 1, "llion": 1, "jones": 1, "aidan": 1, "n": 1, "gomez": 1, "ukasz": 1, "kaiser": 1, "illia": 1, "polosukhin": 1}, {"attention": 1, "need": 1}, {"advance": 1, "neural": 1, "information": 1, "process": 1, "systems": 1, "page": 1, "59986008": 1, "2017": 1}, {"17": 1, "yonghui": 1, "wu": 1, "mike": 1, "schuster": 1, "zhifeng": 1, "chen": 1, "quoc": 1, "v": 1, "le": 1, "mohammad": 1, "norouzi": 1, "wolfgang": 1, "macherey": 2, "maxim": 1, "krikun": 1, "yuan": 1, "cao": 1, "qin": 1, "gao": 1, "klaus": 1, "et": 1, "al": 1}, {"google": 1, "neural": 1, "machine": 2, "translation": 2, "system": 1, "bridge": 1, "gap": 1, "human": 1}, {"arxiv": 1, "preprint": 1, "arxiv160908144": 1, "2016": 1}, {"18": 1, "yingce": 1, "xia": 1, "fei": 1, "tian": 1, "lijun": 1, "wu": 1, "jianxin": 1, "lin": 1, "tao": 1, "qin": 1, "nenghai": 1, "yu": 1, "tieyan": 1, "liu": 1}, {"deliberation": 1, "network": 1, "sequence": 1, "generation": 1, "beyond": 1, "onepass": 1, "decode": 1}, {"advance": 1, "neural": 1, "information": 1, "process": 1, "systems": 1, "page": 1, "17841794": 1, "2017": 1}, {"19": 1, "zhen": 1, "yang": 1, "wei": 1, "chen": 1, "feng": 1, "wang": 1, "bo": 1, "xu": 1}, {"unsupervised": 1, "neural": 1, "machine": 1, "translation": 1, "weight": 1, "share": 1}, {"arxiv": 1, "preprint": 1, "arxiv180409057": 1, "2018": 1}, {"20": 1, "haoyu": 1, "zhang": 1, "yeyun": 1, "gong": 2, "yu": 1, "yan": 1, "nan": 1, "duan": 1, "jianjun": 1, "xu": 1, "ji": 1, "wang": 1, "ming": 2, "zhou": 1}, {"pretrainingbased": 1, "natural": 1, "language": 1, "generation": 1, "text": 1, "summarization": 1}, {"arxiv": 1, "preprint": 1, "arxiv190209243": 1, "2019": 1}, {"21": 1, "xiangwen": 1, "zhang": 1, "jinsong": 1, "su": 1, "yue": 1, "qin": 1, "yang": 1, "liu": 1, "rongrong": 1, "ji": 1, "hongji": 1, "wang": 1}, {"asynchronous": 1, "bidirectional": 1, "decode": 1, "neural": 1, "machine": 1, "translation": 1}, {"aaai": 1, "2018": 1}, {"10": 1}]