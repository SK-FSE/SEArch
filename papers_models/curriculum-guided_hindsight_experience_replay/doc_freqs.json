[{"curriculumguided": 1, "hindsight": 1, "experience": 2, "replay": 1, "": 5, "meng": 1, "fang1": 1, "tianyi": 1, "zhou2": 1, "yali": 1, "du3": 1, "lei": 1, "han1": 1, "zhengyou": 1, "zhang1": 1, "1": 1, "tencent": 1, "robotics": 1, "x": 1, "2": 1, "paul": 1, "g": 1, "allen": 1, "school": 1, "computer": 1, "science": 1, "engineer": 1, "university": 2, "washington": 1, "3": 1, "college": 1, "london": 1, "abstract": 1, "offpolicy": 1, "deep": 1, "reinforcement": 1, "learn": 2, "usually": 1, "hard": 1, "collect": 1, "sufficient": 1, "successful": 1, "sparse": 1, "reward": 1}, {"hindsight": 1, "experience": 2, "replay": 1, "enable": 1, "agent": 1, "learn": 1, "failures": 1, "treat": 1, "achieve": 1, "state": 1, "fail": 1, "pseudo": 1, "goal": 1}, {"however": 1, "fail": 1, "experience": 1, "equally": 1, "useful": 1, "different": 1, "learn": 1, "stag": 1, "efficient": 1, "replay": 1, "uniform": 1, "sample": 1}, {"paper": 1, "propose": 1, "1": 1, "adaptively": 1, "select": 1, "fail": 1, "experience": 1, "replay": 1, "accord": 1, "proximity": 1, "true": 1, "goals": 2, "curiosity": 3, "exploration": 1, "diverse": 1, "pseudo": 1, "2": 1, "gradually": 1, "change": 2, "proportion": 1, "goalproximity": 2, "diversitybased": 1, "selection": 1, "criteria": 1, "adopt": 1, "humanlike": 1, "learn": 1, "strategy": 1, "enforce": 1, "earlier": 1, "stag": 1, "larger": 1, "later": 1}, {"goalandcuriositydriven": 1, "curriculum": 1, "learn": 2, "lead": 1, "curriculumguided": 1, "cher": 1, "adaptively": 1, "dynamically": 1, "control": 1, "explorationexploitation": 1, "tradeoff": 1, "process": 1, "via": 1, "hindsight": 1, "experience": 1, "selection": 1}, {"show": 1, "cher": 1, "improve": 1, "state": 1, "art": 1, "challenge": 1, "robotics": 1, "environments": 1}, {"1": 1, "": 2, "introduction": 1, "deep": 1, "reinforcement": 1, "learn": 1, "rl": 1, "effective": 1, "framework": 1, "address": 1, "rich": 1, "repertoire": 1, "complex": 1, "control": 1, "problems": 1}, {"simulate": 1, "domains": 1, "deep": 1, "rl": 1, "train": 1, "agents": 1, "perform": 1, "diverse": 1, "array": 1, "challenge": 1, "task": 1, "mnih": 1, "et": 3, "al": 3, "2015": 2, "lillicrap": 1, "duan": 1, "2016": 1}, {"order": 1, "train": 1, "reliable": 1, "agents": 1, "critical": 1, "design": 1, "reward": 2, "faithfully": 1, "reflect": 1, "successful": 1, "task": 1, "also": 1, "reshape": 1, "ng": 1, "et": 1, "al": 1, "1999": 1, "provide": 1, "dense": 1, "feedback": 1, "efficiently": 1, "guide": 1, "policy": 1, "optimization": 1, "towards": 1, "better": 1, "solution": 1, "give": 1, "environment": 1}, {"unfortunately": 1, "many": 1, "capabilities": 1, "demonstrate": 1, "current": 1, "reward": 1, "engineer": 1, "often": 1, "limit": 1, "specific": 1, "task": 1, "specify": 1, "environments": 1}, {"moreover": 1, "quality": 1, "reward": 1, "shape": 1, "heavily": 1, "rely": 1, "choice": 1, "rl": 1, "algorithm": 1, "domainspecific": 1, "knowledge": 1}, {"situations": 1, "know": 1, "admissible": 1, "behavior": 1, "may": 1, "look": 1, "like": 1, "example": 1, "use": 1, "lego": 1, "bricks": 1, "build": 1, "desire": 1, "architecture": 1, "difficult": 1, "apply": 1, "reward": 1, "engineer": 1}, {"therefore": 1, "essential": 1, "also": 1, "challenge": 1, "develop": 1, "smarter": 1, "general": 1, "algorithms": 1, "directly": 1, "learn": 1, "unshaped": 1, "usually": 1, "sparse": 1, "reward": 1, "signal": 1, "sparsity": 1, "cause": 1, "insufficiency": 1, "successful": 1, "experience": 1, "expensive": 1, "collect": 1}, {"hindsight": 1, "experience": 3, "replay": 1, "andrychowicz": 1, "et": 1, "al": 1, "2017": 1, "propose": 1, "additionally": 1, "leverage": 1, "rich": 1, "repository": 1, "fail": 2, "replace": 1, "desire": 1, "true": 1, "goals": 2, "train": 1, "trajectories": 1, "achieve": 1}, {"modification": 1, "fail": 1, "experience": 1, "nonnegative": 1, "reward": 1}, {"achieve": 1, "goals": 1, "fail": 1, "experience": 1, "significantly": 1, "different": 2, "proximity": 1, "desire": 1, "goal": 2, "vary": 1, "learn": 1, "reach": 1, "pseudo": 1, "distant": 1, "true": 1, "one": 1, "cannot": 1, "directly": 1, "help": 1, "target": 1, "task": 1, "also": 1, "carry": 1, "information": 1, "manipulation": 1, "environment": 1}, {"": 2, "correspondence": 1, "meng": 1, "fang": 1, "mfangtencentcom": 1, "tianyi": 1, "zhou": 1, "tianyizhuwedu": 1}, {"33rd": 1, "conference": 1, "neural": 1, "information": 1, "process": 1, "systems": 1, "neurips": 1, "2019": 1, "vancouver": 1, "canada": 1}, {"hence": 1, "distinct": 1, "level": 1, "difficulty": 1, "learn": 2, "contributions": 1, "task": 1, "vary": 1, "across": 1, "different": 1, "stag": 1}, {"nevertheless": 1, "treat": 1, "equally": 1, "uniformly": 1, "sample": 1, "replace": 2, "desire": 1, "goals": 2, "result": 1, "train": 2, "trajectories": 1, "weight": 1}, {"however": 1, "fail": 1, "experience": 1, "equally": 1, "useful": 1, "improve": 1, "agent": 1, "provide": 1, "limit": 1, "help": 1, "reach": 1, "true": 1, "goal": 1, "similar": 1, "thus": 1, "redundant": 1, "learn": 1}, {"human": 1, "education": 1, "delicately": 1, "design": 1, "curriculum": 1, "significantly": 1, "improve": 1, "learn": 1, "quality": 1, "efficiency": 1}, {"inspire": 1, "curriculum": 2, "learn": 2, "bengio": 1, "et": 3, "al": 3, "2009": 2, "applications": 1, "khan": 1, "2011": 1, "basu": 1, "christensen": 1, "2013": 1, "spitkovsky": 1, "propose": 1, "train": 2, "model": 1, "design": 1, "sequence": 1, "samplestasks": 1, "ie": 1, "lead": 1, "improvement": 1, "performance": 1, "efficiency": 1}, {"learn": 2, "stage": 1, "train": 2, "sample": 1, "select": 1, "either": 2, "human": 1, "expert": 1, "adaptive": 1, "algorithm": 1, "selection": 1, "predefined": 1, "begin": 1, "determine": 1, "progress": 1, "fly": 1, "kumar": 1, "et": 1, "al": 1, "2010": 1}, {"curriculum": 1, "learn": 2, "methods": 1, "eg": 1, "selfpaced": 1, "variants": 1, "tang": 2, "et": 2, "al": 2, "2012a": 1, "supancic": 1, "iii": 1, "ramanan": 1, "2013": 1, "2012b": 1, "adopt": 1, "strategy": 1, "select": 1, "easier": 1, "train": 1, "sample": 1, "begin": 1, "increase": 1, "amount": 1, "difficult": 1, "ones": 1, "later": 1}, {"recent": 1, "work": 1, "zhou": 2, "bilmes": 1, "2018": 2, "et": 1, "al": 1, "show": 1, "diversity": 1, "also": 1, "need": 1, "consider": 1, "curriculum": 1, "generation": 1}, {"curriculum": 1, "learn": 1, "explain": 1, "form": 1, "continuation": 1, "scheme": 1, "allgower": 1, "georg": 1, "2003": 1, "address": 1, "hard": 2, "task": 4, "solve": 1, "sequence": 1, "move": 1, "easy": 1, "use": 1, "solution": 1, "warm": 1, "start": 1, "next": 1, "slightly": 1, "harder": 1}, {"continuation": 1, "scheme": 1, "reduce": 1, "impact": 1, "local": 1, "minima": 1, "within": 1, "neural": 1, "network": 1, "bengio": 2, "et": 1, "al": 1, "2013": 1, "2014": 1}, {"paper": 1, "propose": 1, "goalandcuriositydriven": 1, "curriculum": 1, "learn": 1, "dynamically": 1, "adaptively": 1, "control": 1, "explorationexploitation": 1, "tradeoff": 1, "select": 1, "hindsight": 1, "experience": 1, "replay": 1, "gradually": 1, "change": 1, "preference": 1, "1": 1, "goalproximity": 1, "close": 1, "achieve": 2, "goals": 3, "desire": 1, "2": 1, "diversitybased": 1, "curiosity": 1, "diverse": 1, "environment": 1}, {"specifically": 1, "give": 1, "candidate": 1, "subset": 1, "achieve": 1, "goals": 2, "train": 1, "define": 1, "proximity": 1, "sum": 1, "similarities": 1, "desire": 1, "measure": 1, "diversity": 1, "submodular": 1, "function": 2, "fujishige": 1, "2005": 1, "eg": 1, "facility": 1, "location": 1, "cornujols": 1, "et": 2, "al": 2, "1977": 1, "lin": 1, "2009": 1}, {"episode": 1, "subset": 1, "achieve": 1, "goals": 1, "select": 1, "accord": 1, "proximity": 2, "curiosity": 2, "prefer": 1, "earlier": 1, "episodes": 2, "exploration": 1, "gradually": 1, "increase": 1, "proportion": 1, "selection": 1, "criteria": 1, "later": 1}, {"apply": 1, "train": 2, "framework": 1, "call": 1, "curriculumguided": 1, "cher": 1, "agents": 1, "multigoal": 1, "set": 1, "uvfa": 1, "schaul": 1, "et": 2, "al": 2, "2015": 1, "andrychowicz": 1, "2017": 1, "assume": 1, "goal": 1, "pursue": 1, "influence": 1, "environment": 1, "dynamics": 1}, {"several": 1, "challenge": 1, "robotics": 1, "environments": 1, "deep": 2, "rl": 2, "methods": 1, "suffer": 1, "sparse": 1, "reward": 1, "problem": 1, "cher": 1, "outperform": 1, "stateoftheart": 1, "approach": 1, "learn": 2, "efficiency": 1, "final": 1, "performance1": 1, "": 3, "2": 1, "relate": 1, "work": 2, "recent": 1, "curriculum": 1, "progressive": 1, "train": 1, "strategy": 1, "introduce": 1, "different": 1, "scenarios": 1}, {"methods": 1, "differ": 1, "apply": 1, "increase": 1, "difficultycomplexity": 1, "schedule": 1, "different": 1, "components": 1, "train": 1, "loop": 1, "eg": 1, "initial": 1, "position": 1, "florensa": 1, "et": 5, "al": 5, "2017": 3, "require": 1, "accuracy": 1, "fournier": 1, "2018": 4, "policies": 1, "intermediate": 1, "agents": 1, "use": 1, "mix": 1, "czarnecki": 1, "environments": 1, "wu": 1, "tian": 2, "aid": 1, "builtin": 1, "ai": 1, "reward": 1, "justesen": 1, "risi": 1, "new": 1, "task": 1, "mask": 1, "subgoals": 1, "eppe": 1}, {"work": 1, "show": 1, "curriculum": 1, "learn": 1, "effectively": 1, "improve": 1, "deep": 1, "rl": 1, "challenge": 1, "task": 1, "include": 1, "robotics": 1, "manipulation": 1, "gamebot": 1, "simulate": 1, "environment": 1, "openai": 1, "gym": 1}, {"also": 1, "explain": 1, "form": 1, "implicit": 1, "curriculum": 1, "learn": 1, "since": 1, "achieve": 2, "goals": 2, "fail": 1, "experience": 1, "easier": 1, "desire": 1}, {"last": 1, "work": 1, "mention": 1, "improve": 1, "require": 1, "extra": 1, "efforts": 1, "epoch": 1, "evaluate": 1, "difficulty": 1, "subgoals": 2, "train": 1, "new": 1, "task": 1}, {"practical": 1, "task": 2, "complex": 1, "goals": 1, "hand": 1, "manipulation": 1, "study": 1, "paper": 1}, {"another": 1, "line": 1, "recent": 1, "work": 1, "burda": 1, "et": 4, "al": 4, "2019": 2, "pathak": 1, "2017": 1, "savinov": 1, "frank": 1, "2013": 1, "investigate": 1, "curiositydriven": 1, "exploration": 1, "deep": 1, "rl": 1, "agents": 1, "within": 1, "interactive": 1, "environments": 1}, {"particular": 1, "either": 1, "replace": 1, "augment": 1, "extrinsic": 1, "usually": 1, "sparse": 1, "reward": 1, "dense": 1, "1": 1, "": 1, "code": 1, "available": 1, "httpsgithubcommengf1cher": 1}, {"2": 1, "": 1, "intrinsic": 1, "reward": 1, "measure": 1, "curiosity": 1, "uncertainty": 1, "agent": 1, "give": 1, "state": 1}, {"thereby": 1, "agent": 1, "encourage": 1, "explore": 1, "unseen": 1, "scenarios": 1, "unexplored": 1, "regions": 1, "environment": 1}, {"show": 1, "curiosity": 1, "drive": 1, "strategy": 1, "improve": 1, "learn": 2, "efficiency": 1, "mitigate": 1, "sparse": 1, "reward": 2, "problem": 1, "successfully": 1, "challenge": 1, "task": 1, "even": 1, "without": 1, "extrinsic": 1}, {"different": 1, "curriculum": 1, "learn": 1, "approach": 2, "usually": 1, "goaloriented": 1, "focus": 2, "exploitation": 1, "curiositydriven": 1, "unsupervisedselfsupervised": 1, "exploration": 1}, {"compare": 1, "strategy": 1, "reshape": 1, "reward": 2, "dynamically": 1, "adaptively": 1, "change": 1, "proportion": 1, "curiosity": 1, "train": 1}, {"number": 1, "rl": 1, "methods": 1, "leverage": 1, "hindsight": 1, "experience": 1, "propose": 1, "since": 1}, {"hindsight": 2, "policy": 1, "gradient": 1, "hpg": 1, "rauber": 1, "et": 1, "al": 1, "2019": 1, "extend": 1, "idea": 1, "train": 1, "goalconditional": 1, "agents": 1, "experience": 1, "onpolicy": 1, "rl": 1, "set": 1}, {"dynamic": 2, "hindsight": 1, "experience": 2, "replay": 1, "dher": 1, "fang": 1, "et": 1, "al": 1, "2019": 1, "assemble": 1, "fail": 1, "train": 1, "policies": 1, "handle": 1, "goals": 1, "rather": 1, "static": 1, "ones": 1, "study": 1}, {"top": 1, "competitive": 1, "experience": 1, "replay": 1, "cer": 1, "liu": 1, "et": 1, "al": 1, "2019": 1, "introduce": 1, "competition": 1, "two": 1, "agents": 1, "better": 1, "exploration": 1}, {"handle": 1, "rawpixel": 1, "input": 1, "nair": 1, "et": 1, "al": 1}, {"2018": 1, "minimize": 1, "pixelmse": 1, "give": 1, "visual": 1, "observations": 1, "extra": 1, "cost": 1, "train": 1, "vae": 1}, {"zhao": 1, "tresp": 1, "2018": 1, "focus": 1, "hindsight": 1, "trajectories": 1, "contain": 1, "higher": 1, "energy": 1, "others": 1, "claim": 1, "valuable": 1, "train": 1}, {"unlike": 1, "work": 1, "curriculum": 1, "learn": 1, "scheme": 1, "generalize": 1, "variety": 1, "settings": 1, "environments": 1, "efficient": 1, "goalconditional": 1, "rl": 1}, {"3": 1, "": 2, "methodology": 1, "section": 1, "briefly": 1, "introduce": 1, "multigoal": 1, "rl": 1, "first": 1}, {"study": 1, "selection": 1, "criteria": 1, "apply": 1, "hindsight": 1, "experience": 1}, {"efficient": 1, "selection": 1, "algorithm": 1, "introduce": 1, "afterwards": 1}, {"end": 1, "present": 1, "cher": 1, "schedule": 1, "goalproximity": 1, "diversitybased": 1, "curiosity": 1, "selection": 1, "criteria": 1}, {"31": 1, "": 2, "multigoal": 2, "rl": 1, "study": 1, "agent": 1, "operate": 1, "environment": 1, "sparse": 1, "reward": 1, "schaul": 1, "et": 2, "al": 2, "2015": 1, "andrychowicz": 1, "2017": 1}, {"time": 1, "step": 1, "agent": 1, "get": 2, "observation": 1, "state": 2, "st": 6, "environment": 1, "take": 1, "action": 1, "response": 1, "apply": 1, "policy": 3, "": 12, "deterministic": 1, "map": 1, "stochastic": 1, "sample": 2, "pat": 1, "receive": 1, "reward": 1, "signal": 1, "rt": 1, "rst": 1, "next": 1, "st1": 1, "transition": 1, "probability": 1, "pst": 1}, {"give": 1, "behavior": 1, "policy": 1, "": 16, "agent": 1, "generate": 1, "trajectory": 1, "s0": 1, "a0": 1, "st": 2, "1": 2, "length": 1, "step": 1, "associate": 1, "transition": 1, "tuple": 1, "rt": 1, "st1": 1}, {"many": 1, "rl": 1, "task": 1, "reward": 1, "depend": 1, "whether": 1, "trajectory": 1, "finally": 1, "reach": 1, "desire": 1, "goal": 1, "g": 1}, {"hence": 1, "successful": 1, "trajectories": 1, "get": 1, "nonnegative": 1, "reward": 1}, {"since": 1, "": 1, "fullytrained": 1, "low": 1, "success": 1, "rate": 1, "collect": 1, "successful": 1, "trajectories": 1, "usually": 1, "insufficient": 1, "train": 1, "result": 1, "sparse": 1, "reward": 1, "problem": 1}, {"address": 1, "sparse": 1, "reward": 1, "problem": 1, "treat": 1, "failures": 1, "successes": 1, "learn": 1, "fail": 1, "experience": 1}, {"offpolicy": 1, "rl": 1, "algorithm": 1, "eg": 1, "dqn": 1, "mnih": 1, "et": 4, "al": 4, "2015": 2, "ddpg": 1, "lillicrap": 1, "naf": 1, "gu": 1, "2016": 1, "sdqn": 1, "metz": 1, "2017": 1, "modify": 1, "desire": 1, "goals": 2, "g": 2, "transition": 1, "tuples": 1, "train": 1, "achieve": 1, "0": 1, "sample": 1, "state": 1, "fail": 1, "experience": 1}, {"desire": 1, "goal": 2, "g": 1, "actual": 1, "agent": 1, "aim": 1, "achieve": 1, "ie": 1, "real": 1, "target": 1}, {"achieve": 2, "goal": 1, "g": 1, "0": 1, "state": 1, "agent": 1, "already": 1, "eg": 1, "cartesian": 1, "position": 1, "fingertip": 1, "robotic": 1, "hand": 1}, {"g": 2, "replace": 1, "0": 1, "": 1, "correspond": 1, "fail": 1, "experience": 1, "assign": 1, "nonnegative": 1, "reward": 1, "thus": 1, "contribute": 1, "learn": 1, "policies": 1}, {"32": 1, "": 2, "goalandcuriositydriven": 1, "selection": 1, "pseudo": 1, "goals": 3, "achieve": 1, "use": 1, "modify": 1, "desire": 1, "uniformly": 1, "sample": 1, "batch": 1, "previous": 1, "experience": 1, "b": 1}, {"contrast": 1, "uniform": 1, "sample": 1, "propose": 1, "select": 1, "subset": 1, "achieve": 2, "goals": 3, "": 1, "b": 1, "accord": 1, "1": 1, "proximity": 1, "desire": 1, "2": 1, "diversity": 1, "reflect": 1, "curiosity": 1, "agent": 1, "explore": 1, "different": 1, "environment": 1}, {"although": 1, "fail": 1, "experience": 1, "turn": 1, "success": 1, "ones": 1, "pseudo": 1, "goals": 1, "different": 1, "two": 1, "quantities": 1, "however": 1, "play": 1, "important": 1, "roles": 1, "guide": 1, "learn": 1, "process": 1}, {"particular": 1, "large": 2, "proximity": 1, "enforce": 1, "train": 1, "proceed": 1, "towards": 1, "desire": 1, "goals": 1, "diversity": 1, "3": 1, "": 1, "lead": 1, "exploration": 1, "different": 1, "state": 1, "regions": 1, "environment": 1}, {"desirable": 1, "tradeoff": 1, "essential": 1, "learn": 1, "efficiency": 1, "generalization": 1, "performance": 1, "result": 1, "agents": 1}, {"selection": 1, "criteria": 1, "select": 1, "subset": 1, "fail": 1, "experience": 1, "replay": 1, "accord": 1, "proximity": 1, "diversity": 1, "define": 1, "base": 1, "similarity": 1, "function": 1, "sim": 1, "": 1, "measure": 1, "liken": 1, "two": 1, "achieve": 1, "goals": 1, "interactive": 1, "environment": 1}, {"give": 1, "distance": 3, "metric": 1, "dis": 1, "": 13, "eg": 1, "euclidean": 1, "sim": 1, "define": 1, "example": 1, "radial": 1, "basis": 1, "function": 1, "rbf": 1, "kernel": 1, "bandwidth": 1, "ie": 2, "disx": 2, "y2": 1, "simx": 3, "exp": 1, "1": 1, "2": 2, "another": 1, "option": 1, "constant": 1, "c": 3, "minus": 1, "large": 1, "enough": 1, "guarantee": 1, "0": 1, "possible": 1, "x": 1}, {"choice": 1, "dis": 1, "": 1, "usually": 1, "determine": 1, "task": 1, "environment": 1}, {"instance": 1, "hand": 1, "manipulation": 1, "task": 1, "define": 1, "disgi": 1, "": 2, "gj": 1, "mean": 1, "distance": 1, "fingertips": 2, "time": 2, "step": 2, "j": 1}, {"able": 1, "select": 1, "subset": 1, "achieve": 1, "goals": 1, "size": 1, "k": 1, "buffer": 1, "experience": 1, "b": 1, "solve": 1, "follow": 1, "combinatorial": 1, "optimization": 1, "maximize": 1, "proximity": 1, "diversity": 1, "max": 1, "abak": 1, "": 3, "f": 1, "fprox": 1, "fdiv": 1}, {"first": 1, "term": 2, "fprox": 2, "associate": 1, "tradeoff": 1, "weight": 1, "": 7, "modular": 1, "function": 1, "x": 1, "simgi": 1, "g": 3, "3": 1, "4": 1, "ia": 1, "reflect": 1, "proximity": 1, "select": 1, "achieve": 1, "goals": 2, "0": 1, "desire": 1, "goal": 1, "second": 1, "fdiv": 1, "measure": 1, "diversity": 1}, {"use": 1, "facility": 1, "location": 1, "function": 1, "cornujols": 1, "et": 2, "al": 2, "1977": 1, "lin": 1, "2009": 1, "compute": 1, "fdiv": 2, "ie": 1, "x": 1, "": 3, "max": 1, "simgi": 1, "gj": 1}, {"5": 1, "jb": 1, "": 2, "ia": 1, "intuitively": 1, "expect": 1, "achieve": 1, "goals": 2, "select": 1, "represent": 1, "b": 1}, {"gj": 4, "b": 1, "fdiv": 1, "find": 1, "achieve": 1, "goal": 1, "gi": 1, "similar": 1, "use": 1, "simgi": 1, "": 3, "measure": 1, "well": 1, "represent": 1}, {"hence": 1, "sum": 1, "simgi": 1, "": 3, "gj": 1, "achieve": 1, "goals": 1, "j": 1, "b": 2, "fdiv": 1, "quantify": 1, "representative": 1, "wrt": 1}, {"widely": 1, "use": 1, "diversity": 1, "metric": 1, "large": 1, "fdiv": 1, "indicate": 1, "every": 1, "goal": 2, "b": 2, "find": 1, "sufficiently": 1, "similar": 1, "word": 1, "span": 1, "space": 1}, {"diverse": 1, "subset": 1, "achieve": 1, "goals": 2, "encourage": 1, "agent": 1, "explore": 1, "new": 1, "state": 1, "unseen": 1, "areas": 1, "environment": 1, "thus": 1, "learn": 1, "reach": 1, "different": 1}, {"facility": 1, "location": 1, "function": 2, "typical": 1, "example": 1, "large": 1, "expressive": 1, "family": 1, "submodular": 1, "satisfy": 1, "diminish": 1, "return": 1, "property": 1, "give": 1, "finite": 1, "grind": 1, "set": 1, "v": 7, "": 12, "b": 5, "element": 1, "fulfill": 1, "f": 4, "abuse": 1, "former": 1, "notations": 1}, {"due": 1, "property": 1, "naturally": 1, "measure": 1, "diversity": 1, "set": 1, "items": 1, "fujishige": 1, "2005": 1, "apply": 1, "variety": 1, "diversitydriven": 1, "task": 1, "achieve": 1, "appeal": 1, "result": 1, "lin": 1, "bilmes": 1, "2011": 1, "batra": 1, "et": 3, "al": 3, "2012": 3, "prasad": 1, "2014": 1, "gillenwater": 1, "fiterau": 1, "dubrawski": 1}, {"although": 1, "choose": 1, "facility": 1, "location": 1, "function": 2, "fdiv": 1, "paper": 1, "submodular": 1, "worth": 1, "study": 1, "curriculum": 1, "learn": 1, "framework": 1}, {"since": 1, "f": 1, "eq": 1}, {"3": 1, "weight": 1, "sum": 1, "nonnegative": 2, "similarity": 1, "modular": 1, "function": 2, "fprox": 1, "submodular": 2, "fdiv": 1, "monotone": 1, "nondecreasing": 1}, {"although": 1, "exactly": 1, "solve": 1, "eq": 1}, {"3": 1, "nphard": 1, "nearoptimal": 1, "solution": 1, "achieve": 1, "greedy": 1, "algorithm": 1, "worstcase": 1, "approximation": 1, "factor": 1, "": 3, "1": 1, "e1": 1, "nemhauser": 1, "et": 1, "al": 1, "1978": 1, "result": 1, "submodularity": 1, "f": 1}, {"greedy": 1, "algorithm": 1, "start": 1, "": 11, "select": 1, "next": 1, "goal": 1, "ba": 1, "bring": 1, "largest": 1, "improvement": 1, "f": 6, "ia": 2, "objective": 1, "ie": 1, "argmaxiba": 1, "repeat": 1, "k": 1, "specific": 1, "define": 1, "eq": 1}, {"3eq": 1}, {"5": 1, "": 11, "x": 1, "f": 1, "ia": 1, "simgi": 2, "g": 1, "max": 2, "0": 1, "gj": 2, "simgl": 1}, {"6": 1, "la": 1, "": 5, "jb": 1, "4": 1, "algorithm": 1, "1": 2, "tochastic": 1, "g": 1, "reedyk": 1, "require": 1, "experience": 1, "buffer": 1, "b": 4, "input": 1, "k": 2, "2": 1, "output": 1, "minibatch": 1, "size": 2, "3": 1, "sample": 1, "batch": 1, "omk": 1, "build": 1, "sparse": 1, "knearest": 1, "neighbor": 1, "graph": 1}, {"4": 1, "initialize": 1, "": 8, "5": 1, "0": 1, "k": 1, "1": 1, "6": 1, "sample": 1, "subset": 1, "b": 2, "size": 1, "ba": 1, "7": 1, "transition": 1, "tuple": 1, "st": 1, "rt": 1, "st1": 1, "8": 1, "calculate": 1, "utility": 1, "score": 1, "f": 1, "ia": 1, "eq": 1}, {"6": 1, "use": 1, "gi": 2, "": 4, "gt0": 1, "g": 1, "base": 1, "current": 1, "state": 1, "st": 1, "9": 1, "end": 2, "10": 1, "add": 1, "transition": 1, "tuple": 1, "maximum": 1, "utility": 1, "score": 1, "f": 2, "ia": 2, "11": 1, "evaluation": 1, "fdiv": 1, "require": 1, "pairwise": 1, "similarity": 1, "two": 1, "goals": 1, "gj": 1, "expensive": 1, "size": 1, "b": 1, "large": 1}, {"practice": 1, "use": 1, "kdtree": 1, "balltree": 1, "build": 1, "sparse": 1, "knearest": 1, "neighbor": 1, "graph": 1, "goals": 1, "b": 1, "run": 1, "greedy": 1, "algorithm": 1}, {"show": 1, "previous": 1, "work": 1, "wei": 1, "et": 1, "al": 1, "2014": 1, "sufficiently": 1, "good": 1, "solution": 1, "achieve": 1, "even": 1, "k": 1, "small": 1, "olog": 1, "b": 1}, {"33": 1, "": 2, "lazier": 1, "lazy": 1, "greedy": 2, "efficient": 1, "selection": 1, "algorithm": 1, "simple": 1, "implement": 1, "usually": 1, "outperform": 1, "optimization": 1, "methods": 1, "eg": 1, "base": 1, "integer": 1, "linear": 1, "program": 1, "suffer": 1, "expensive": 1, "computation": 1, "require": 1, "obk": 1, "function": 1, "evaluations": 1}, {"exist": 1, "several": 1, "accelerations": 1, "eg": 1, "lazy": 2, "greedy": 2, "minoux": 1, "1978": 1, "lazier": 1, "mirzasoleiman": 2, "et": 2, "al": 2, "2015": 1, "greedi": 1, "2016": 1, "either": 1, "close": 1, "approximation": 1, "factor": 1, "enjoy": 1, "significant": 1, "speedups": 1}, {"choose": 1, "lazier": 1, "lazy": 1, "greedy": 1, "speedup": 1, "select": 1, "fail": 1, "experience": 1, "cher": 1, "compatible": 1, "stochastic": 1, "learn": 1, "nature": 1, "offpolicy": 1, "rl": 1, "algorithms": 1}, {"algorithm": 1, "1": 1, "show": 1, "detail": 1, "procedures": 1}, {"step": 1, "random": 1, "subset": 1, "b": 1, "ba": 2, "instead": 1, "select": 1, "goal": 1, "result": 1, "largest": 1, "improvement": 1, "f": 1, "ia": 1}, {"accord": 1, "mirzasoleiman": 1, "et": 1, "al": 1, "2015": 1, "": 4, "obk": 1, "log": 2, "1": 2, "lazier": 1, "lazy": 1, "greedy": 2, "reduce": 1, "approximation": 1, "factor": 1, "vanilla": 1, "algorithm": 1, "require": 1, "ob": 1, "evaluations": 1, "f": 1}, {"34": 1, "": 2, "curriculumguided": 1, "hindsight": 1, "experience": 1, "replay": 1, "tradeoff": 2, "proximity": 1, "diversity": 1, "selection": 1, "achieve": 1, "goals": 1, "reflect": 1, "exploitation": 1, "exploration": 1}, {"similar": 1, "learn": 2, "process": 1, "human": 1, "require": 1, "different": 3, "proportion": 1, "exploitation": 1, "exploration": 1, "stag": 1, "preference": 1, "proximity": 1, "diversity": 1, "curiosity": 1, "episodes": 1, "deep": 1, "rl": 1, "also": 1, "need": 1, "vary": 1}, {"earlier": 1, "episodes": 1, "curiosity": 1, "diverse": 1, "pseudo": 1, "goals": 1, "help": 1, "agent": 1, "explore": 1, "new": 1, "state": 1, "unseen": 1, "areas": 1}, {"thus": 1, "evolve": 1, "rl": 1, "better": 1, "generalization": 1}, {"however": 1, "diverse": 1, "goals": 3, "distract": 1, "learn": 2, "later": 1, "episodes": 1, "proximity": 1, "desire": 1, "important": 1, "agent": 1, "since": 1, "already": 1, "accumulate": 1, "sufficient": 1, "knowledge": 1, "environment": 1, "need": 1, "focus": 1, "achieve": 1, "true": 1, "task": 1}, {"another": 1, "critical": 1, "reason": 1, "avoid": 1, "large": 1, "proximity": 1, "earlier": 2, "episodes": 2, "promote": 1, "later": 2, "agent": 1, "policy": 1, "cannot": 1, "produce": 1, "sufficient": 1, "number": 1, "pseudo": 1, "goals": 2, "close": 1, "desire": 1, "otherwise": 1, "learn": 1, "almost": 1, "accomplish": 1, "never": 1, "suffer": 1, "sparse": 1, "reward": 1, "adequate": 1, "train": 1, "able": 1}, {"follow": 1, "propose": 1, "goalandcuriositydriven": 1, "curriculum": 1, "gcc": 1, "learn": 2, "effective": 1, "scheme": 1, "cher": 1}, {"start": 1, "learn": 1, "reach": 1, "different": 1, "achieve": 2, "goals": 3, "large": 2, "diversity": 1, "gradually": 1, "turn": 1, "focus": 1, "progressively": 1, "approach": 1, "proximity": 1, "desire": 1}, {"achieve": 1, "smoothly": 1, "increase": 1, "weight": 1, "": 1, "proximity": 1, "term": 1, "f": 1, "eq": 1}, {"3": 1}, {"task": 1, "paper": 1, "use": 2, "exponentially": 1, "increase": 1, "": 72, "course": 1, "train": 1, "ie": 3, "1": 11, "0": 14, "5": 2, "7": 2, "algorithm": 3, "2": 2, "curriculumguided": 1, "cher": 1, "require": 1, "offpolicy": 2, "rl": 2, "experience": 1, "buffer": 1, "b": 4, "input": 1, "minibatch": 3, "size": 1, "k": 1, "reward": 1, "function": 1, "r": 1, "initialize": 2, "3": 1, "episode": 2, "4": 1, "sample": 2, "initial": 3, "goal": 1, "g": 11, "state": 2, "s0": 1, "6": 1, "action": 2, "behavioral": 1, "policy": 1, "st": 4, "execute": 1, "observe": 1, "new": 1, "st1": 3, "8": 1, "end": 5, "9": 1, "10": 1, "rt": 2, "rst": 2, "11": 1, "store": 2, "tuple": 2, "12": 1, "13": 1, "n": 1, "14": 1, "select": 1, "subset": 1, "achieve": 2, "goals": 1, "tochastic": 1, "reedyk": 1, "15": 1, "bi": 3, "16": 1, "17": 1, "r0": 2, "18": 1, "19": 1, "20": 1, "optimize": 1, "21": 1, "22": 1, "23": 1, "learn": 1, "pace": 1, "control": 1, "progress": 1, "curriculum": 1, "weight": 1, "proximity": 1, "relatively": 1, "small": 1}, {"complete": 1, "procedures": 1, "curriculumguided": 1, "cher": 1, "find": 1, "algorithm": 1, "2": 1}, {"compare": 1, "vanilla": 1, "major": 1, "differences": 1, "line14": 1, "select": 1, "achieve": 1, "goals": 1, "experience": 1, "buffer": 1, "accord": 1, "proximity": 2, "diversity": 1, "line22": 1, "increase": 1, "weight": 1, "instruct": 1, "curriculum": 1}, {"algorithm": 1, "generalize": 1, "improve": 1, "offpolicy": 1, "rl": 1, "method": 1, "require": 1, "extra": 1, "train": 1, "new": 1, "task": 1}, {"although": 1, "algorithm": 1, "1": 1, "cannot": 1, "exactly": 1, "solve": 1, "combinatorial": 1, "optimization": 1, "eq": 1}, {"3": 1, "worth": 1, "note": 1, "approximate": 1, "solution": 1, "gradually": 1, "approach": 1, "global": 1, "optimal": 1, "curriculum": 1, "proceed": 1, "": 1, "increase": 1}, {"increase": 1, "": 1, "make": 1, "f": 1, "close": 1, "modular": 1, "function": 1}, {"result": 1, "greedy": 1, "solution": 2, "approach": 1, "topk": 1, "rank": 1, "optimal": 1, "modular": 1, "maximization": 1}, {"trend": 1, "theoretically": 1, "analyze": 1, "curvaturedependent": 1, "approximation": 1, "bind": 1, "greedy": 2, "algorithm": 1, "easily": 1, "extend": 1, "lazier": 1, "lazy": 1}, {"improve": 1, "": 11, "1": 4, "e1": 1, "ef": 1, "f": 5, "conforti": 1, "cornuejols": 1, "1984": 1, "curvature": 1, "0": 1, "define": 1, "min": 1, "jb": 1, "jbj": 1}, {"f": 5, "j": 1, "": 11, "8": 1, "0": 1, "modular": 1, "result": 1, "1": 3, "achieve": 1, "global": 1, "optimum": 1, "fully": 1, "curve": 1, "e1": 1}, {"cher": 1, "": 4, "sufficiently": 1, "large": 1, "later": 1, "episodes": 1, "f": 1, "0": 1, "thus": 1, "1": 1}, {"theoretically": 1, "derive": 1, "upper": 1, "bind": 1, "f": 1, "": 5, "1": 1, "curvature": 1, "fdiv": 1, "go": 1, "zero": 1, "see": 1, "appendix": 1}, {"4": 1, "": 2, "experiment": 1, "evaluate": 1, "cher": 1, "compare": 1, "stateoftheart": 1, "baselines": 1, "several": 1, "challenge": 1, "robotic": 1, "manipulation": 1, "task": 1, "simulate": 1, "mujoco": 1, "environments": 1, "todorov": 1, "et": 1, "al": 1, "2012": 1}, {"particular": 1, "use": 1, "simple": 1, "fetch": 1, "environment": 1, "toy": 1, "example": 1, "shadow": 1, "dexterous": 1, "hand": 1, "environments": 1, "openai": 1, "gym": 1, "brockman": 1, "et": 1, "al": 1, "2016": 1}, {"worth": 1, "note": 1, "shadow": 1, "dexterous": 1, "hand": 1, "environments": 3, "also": 1, "difficult": 1, "amongst": 1, "openais": 1, "robotics": 1}, {"6": 1, "": 6, "fetchreach": 1, "toy": 1, "example": 1, "handreach": 1, "handmanipulate": 3, "block": 1, "egg": 1, "pen": 1, "figure": 1, "1": 1, "fetch": 1, "four": 1, "shadow": 1, "dexterous": 1, "hand": 1, "environments": 1}, {"41": 1, "": 2, "environments": 2, "figure": 1, "1": 1, "fetchreach": 1, "environment": 1, "four": 1, "shadow": 1, "dexterous": 1, "hand": 1, "handreach": 1, "block": 1, "manipulation": 3, "handmanipulateblockrotatexyzv0": 1, "egg": 1, "handmanipulateeggfullv0": 1, "pen": 1, "handmanipulatepenrotatev0": 1}, {"fetchreach": 1, "environment": 1, "base": 1, "7dof": 1, "degrees": 1, "freedom": 1, "fetch": 1, "robotics": 1, "arm": 1, "twofingered": 1, "parallel": 1, "gripper": 1}, {"action": 1, "3dimensional": 1, "vector": 1, "specify": 1, "desire": 1, "gripper": 2, "movement": 1, "cartesian": 1, "coordinate": 1, "keep": 1, "close": 1, "process": 1, "reach": 1, "target": 1, "location": 1}, {"observation": 1, "state": 1, "robot": 1}, {"simulate": 1, "environments": 1, "shadow": 1, "dexterous": 1, "hand": 2, "anthropomorphic": 1, "robotic": 1, "24": 1, "dof": 1, "20": 1, "joint": 2, "control": 1, "independently": 1, "whereas": 1, "remain": 1, "ones": 1, "couple": 1}, {"four": 1, "hand": 2, "environments": 1, "action": 1, "20dimensional": 1, "vector": 1, "contain": 1, "absolute": 1, "position": 1, "control": 1, "noncoupled": 1, "joint": 1}, {"observation": 1, "include": 1, "24": 2, "position": 1, "associate": 1, "velocities": 1, "joint": 1}, {"represent": 2, "object": 2, "manipulate": 1, "environment": 1, "provide": 1, "cartesian": 1, "position": 1, "rotation": 1, "7dimensional": 1, "vector": 1, "well": 1, "linear": 1, "angular": 1, "velocities": 1}, {"reward": 2, "sparse": 1, "binary": 1, "agent": 1, "receive": 1, "0": 1, "goal": 1, "achieve": 1, "within": 1, "taskspecific": 1, "tolerance": 1, "1": 1, "otherwise": 1}, {"fetchreach": 1, "goal": 2, "reach": 2, "task": 1, "3dimensional": 1, "vector": 1, "describe": 1, "target": 1, "position": 2, "object": 1, "endeffector": 1, "achieve": 1, "gripper": 1}, {"use": 1, "euclidean": 1, "distance": 1, "disgi": 1, "": 2, "gj": 1}, {"handreach": 1, "goal": 2, "reach": 1, "task": 1, "target": 1, "position": 2, "desire": 1, "fingertips": 1}, {"block": 1, "pen": 1, "manipulations": 1, "goal": 2, "manipulation": 1, "task": 1, "rotation": 2, "target": 1, "pose": 1, "achieve": 1, "blockpen": 1}, {"egg": 2, "manipulation": 2, "goal": 2, "task": 1, "rotation": 2, "location": 2, "target": 1, "pose": 1, "achieve": 1}, {"42": 1, "": 2, "baselines": 1, "evaluation": 1, "different": 1, "methods": 1, "base": 1, "ddpg": 1}, {"use": 1, "different": 1, "methods": 1, "selectsample": 1, "hindsight": 1, "experience": 1, "replay": 1, "train": 1, "policies": 1, "environments": 1, "issue": 1, "sparse": 1, "reward": 1}, {"compare": 1, "cher": 1, "follow": 1, "baselines": 1, "": 1, "ddpg": 1, "lillicrap": 1, "et": 1, "al": 1, "2015": 1, "modelfree": 1, "rl": 1, "algorithm": 1, "continuous": 1, "control": 1}, {"learn": 1, "deterministic": 1, "policy": 1, "stochastic": 1, "counterpart": 1, "explore": 1, "train": 1}, {"": 1, "ddpgher": 1, "andrychowicz": 1, "et": 1, "al": 1, "2017": 1, "sample": 1, "hindsight": 1, "experience": 1, "uniformly": 1, "replay": 1}, {"": 1, "ddpgherebp": 1, "zhao": 1, "tresp": 1, "2018": 1, "use": 1, "energy": 2, "function": 1, "evaluate": 1, "trajectories": 1, "prioritize": 1, "hindsight": 1, "experience": 1, "large": 1}, {"comparison": 1, "dense": 1, "sparse": 1, "reward": 1, "present": 1, "plappert": 1, "et": 1, "al": 1}, {"2018": 1, "show": 1, "advantage": 1, "use": 1, "sparse": 1, "reward": 1}, {"43": 1, "": 2, "train": 2, "set": 1, "environments": 1, "except": 1, "fetchreach": 1, "policies": 1, "single": 1, "machine": 1, "20": 1, "cpu": 1, "core": 1}, {"core": 1, "generate": 1, "experience": 1, "use": 1, "two": 1, "parallel": 1, "rollouts": 1, "mpi": 1, "synchronization": 1}, {"train": 1, "agent": 1, "50": 1, "epochs": 1, "batch": 1, "size": 1, "64": 1}, {"hyperparameters": 1, "nearly": 1, "andrychowicz": 1, "et": 1, "al": 1}, {"2017": 1}, {"cher": 1, "use": 1, "b": 2, "": 5, "128": 1, "k": 1, "64": 1, "3": 1, "algorithm": 1, "1": 1}, {"evaluate": 1, "policies": 1, "epoch": 1, "perform": 1, "10": 1, "deterministic": 1, "test": 2, "rollouts": 2, "per": 1, "mpi": 2, "worker": 1, "compute": 1, "success": 1, "rate": 1, "average": 1, "across": 1, "workers": 1}, {"case": 1, "7": 1, "": 20, "achieve": 2, "goals": 3, "desire": 1, "select": 1, "fetchreachv1": 1, "10": 2, "070": 2, "0625": 1, "0600": 1, "0575": 1, "0550": 1, "0525": 1, "0500": 1, "0475": 1, "0450": 1, "0425": 1, "090": 1, "085": 1, "080": 1, "075": 1, "ny": 1, "065": 1, "ocatio": 1, "l": 1, "060": 1, "055": 1, "06": 1, "04": 1, "ddpg": 1, "ddpgher": 1, "ddpgherebp": 1, "ddpgcher": 1, "02": 1, "00": 1, "0": 1, "5": 1, "15": 1, "20": 1, "25": 1, "epoch": 1, "30": 1, "35": 1, "40": 1, "45": 1, "100": 1, "105": 1, "50": 1, "b": 1, "performance": 1, "toy": 1, "example": 1}, {"110": 1, "115": 1, "locatio": 1, "120": 1, "125": 1, "nx": 1, "130": 1, "135": 1, "": 10, "locationz": 2, "065": 1, "08": 1, "median": 1, "success": 1, "rate": 1, "achieve": 2, "goals": 4, "desire": 1, "select": 1, "060": 1, "055": 1, "050": 1, "045": 1, "10": 1, "c": 1, "earlier": 1, "episode": 1, "cher": 1}, {"11": 1, "": 7, "12": 1, "locatio": 1, "13": 1, "nx": 1, "14": 1, "04": 1, "15": 1, "05": 1, "09": 1, "08": 1, "07": 1, "06": 1, "cation": 1, "lo": 1, "goals": 1, "later": 1, "episode": 1, "cher": 1}, {"figure": 1, "2": 1, "toy": 1, "example": 1, "": 1, "fetchreach": 1}, {"cher": 1, "learn": 1, "much": 1, "faster": 1, "rl": 1, "methods": 1}, {"b": 1, "red": 1, "point": 3, "select": 1, "achieve": 2, "goals": 3, "compose": 1, "diverse": 1, "representative": 1, "subset": 1, "gray": 1, "close": 1, "green": 1, "desire": 1, "since": 1, "cher": 1, "prefer": 1, "diversity": 1, "proximity": 1, "earlier": 1, "episodes": 1}, {"c": 1, "red": 2, "point": 4, "close": 1, "green": 1, "due": 1, "large": 1, "proximity": 2, "later": 1, "episodes": 1, "selection": 1, "criteria": 1, "regions": 1, "many": 1, "gray": 1, "concentrate": 1, "contain": 1, "since": 1, "cher": 1, "prefer": 1, "diversity": 1}, {"08": 2, "": 67, "06": 2, "04": 2, "02": 2, "00": 2, "020": 2, "5": 4, "10": 6, "15": 4, "20": 4, "25": 4, "30": 4, "epoch": 4, "35": 4, "40": 4, "45": 4, "50": 4, "handreach": 1, "0": 7, "015": 2, "010": 2, "005": 2, "000": 2, "b": 1, "block": 2, "handmanipulatepenrotatev0": 1, "ddpg": 4, "ddpgher": 4, "ddpgherebp": 4, "ddpgcher": 4, "025": 2, "handmanipulateeggfullv0": 1, "median": 4, "success": 4, "rate": 4, "handmanipulateblockrotatexyzv0": 1, "handreachv0": 1, "c": 1, "egg": 1, "pen": 1, "figure": 1, "3": 1, "performance": 1, "four": 1, "hand": 1, "environments": 1, "others": 1, "1": 1}, {"repeat": 1, "experiment": 1, "5": 1, "different": 1, "random": 1, "seed": 1, "report": 1, "performance": 1, "compute": 1, "median": 1, "test": 1, "success": 1, "rate": 1, "well": 1, "interquartile": 1, "range": 1}, {"44": 1, "": 2, "toy": 2, "example": 2, "quickly": 1, "prove": 1, "concept": 1, "idea": 1, "first": 1, "study": 1, "simple": 1, "environment": 1, "fetchreach": 1}, {"train": 1, "policies": 1, "use": 1, "one": 1, "cpu": 1, "core": 1}, {"figure": 1, "2a": 1, "depict": 1, "median": 1, "test": 1, "success": 1, "rate": 1, "fetchreach": 1, "environment": 1}, {"fetchreach": 1, "know": 1, "simple": 1, "environment": 1, "easily": 1, "learn": 1, "approach": 1}, {"result": 1, "show": 1, "ddpgcher": 1, "learn": 1, "faster": 1, "baselines": 1}, {"vanilla": 1, "ddpg": 1, "also": 1, "reach": 1, "100": 1, "success": 1, "rate": 1, "last": 1, "much": 1, "later": 1, "ddpgcher": 1}, {"ddpgherebp": 1, "perform": 1, "similarly": 1, "ddpgher": 1, "simple": 1, "task": 1}, {"figure": 1, "2bc": 1, "visualize": 1, "select": 2, "desire": 1, "goals": 3, "g": 1, "green": 1, "star": 1, "achieve": 2, "b": 2, "grey": 1, "circle": 1, "": 1, "algorithm": 1, "1": 1, "red": 1, "triangles": 1, "earlier": 1, "episode": 2, "leave": 1, "later": 1, "right": 1, "ddpgcher": 1}, {"earlier": 1, "episode": 1, "achieve": 2, "goals": 2, "select": 1, "averagely": 1, "spread": 1, "manifold": 1, "b": 2, "imply": 1, "diverse": 1, "representative": 1, "subset": 1}, {"regions": 1, "contain": 1, "several": 1, "select": 1, "goals": 1, "far": 1, "away": 1, "desire": 1, "goal": 1, "since": 1, "proximity": 1, "play": 1, "minor": 1, "role": 1, "earlier": 1, "episodes": 1, "diversity": 1, "dominate": 1, "selection": 1, "criteria": 1}, {"later": 1, "episode": 1, "contrast": 1, "achieve": 1, "goals": 3, "select": 2, "gather": 2, "around": 1, "desire": 1, "regions": 1, "many": 1, "unselected": 1, "none": 1, "indicate": 1, "proximity": 1, "dominate": 1, "diversity": 1, "selection": 1}, {"45": 1, "": 2, "benchmark": 1, "result": 1, "figure": 1, "3": 1, "report": 1, "median": 1, "test": 1, "success": 1, "rate": 1, "achieve": 1, "methods": 1, "improve": 1, "learn": 1, "four": 1, "hand": 1, "environments": 1}, {"similar": 1, "show": 1, "fetchreach": 1, "environment": 1, "ddpgcher": 1, "significantly": 1, "outperform": 1, "baselines": 1}, {"result": 1, "also": 1, "show": 1, "ddpg": 1, "easily": 1, "fail": 1, "environments": 2, "ddpgher": 1, "able": 1, "learn": 1, "partly": 1, "successful": 1, "policies": 1}, {"surprisingly": 1, "ddpgcher": 18, "get": 1, "significant": 1, "improvement": 1, "egg": 2, "pen": 2, "manipulation": 1, "task": 1, "8": 1, "": 104, "06": 2, "04": 2, "02": 2, "00": 2, "0": 25, "5": 4, "10": 10, "15": 4, "20": 4, "25": 4, "30": 4, "epoch": 4, "35": 4, "01": 4, "1": 4, "40": 4, "45": 4, "020": 2, "handreach": 1, "015": 2, "010": 2, "005": 2, "50": 4, "handmanipulatepenrotatev0": 1, "025": 2, "000": 2, "handmanipulateeggfullv0": 1, "median": 4, "success": 4, "rate": 4, "08": 2, "handmanipulateblockrotatexyzv0": 1, "handreachv0": 1, "b": 1, "block": 1, "c": 1, "figure": 1, "4": 1, "performance": 1, "different": 1, "initial": 1, "four": 1, "hand": 1, "environments": 1}, {"06": 2, "04": 2, "": 117, "ddpgcher": 21, "02": 2, "00": 2, "0": 8, "5": 5, "10": 10, "15": 4, "20": 4, "25": 4, "30": 4, "epoch": 4, "35": 4, "fix": 21, "01": 4, "1": 4, "inf": 4, "40": 4, "handreach": 1, "45": 4, "020": 2, "015": 2, "50": 4, "010": 2, "005": 2, "000": 2, "b": 1, "block": 1, "handmanipulatepenrotatev0": 1, "025": 2, "handmanipulateeggfullv0": 1, "median": 4, "success": 4, "rate": 4, "08": 2, "handmanipulateblockrotatexyzv0": 1, "handreachv0": 1, "c": 1, "egg": 1, "pen": 1, "figure": 1, "ablation": 1, "study": 1, "f": 1, "ixed": 1, "four": 1, "hand": 1, "environments": 1}, {"show": 1, "figure": 1, "3c": 1, "3d": 1}, {"task": 1, "know": 1, "difficult": 1, "object": 1, "often": 1, "drop": 1}, {"curriculum": 1, "learn": 2, "equip": 1, "cher": 1, "agent": 1, "quickly": 1, "way": 1, "hold": 1, "object": 1}, {"summary": 1, "ddpgcher": 1, "curriculum": 1, "learn": 1, "select": 1, "hindsight": 1, "experience": 1, "replay": 1, "effectively": 1, "improve": 1, "performance": 1, "ddpgher": 1}, {"figure": 1, "4": 1, "report": 1, "success": 1, "rate": 1, "ddpgcher": 1, "use": 1, "different": 1, "initialization": 1, "0": 1, "": 1}, {"show": 1, "promote": 1, "different": 1, "amount": 1, "proximity": 1, "selection": 1, "affect": 1, "performance": 1}, {"0": 2, "": 1, "ie": 1, "start": 1, "without": 1, "proximity": 1, "prefer": 1, "performance": 1, "degrade": 1}, {"also": 1, "show": 1, "large": 1, "proximity": 1, "improve": 1, "performance": 1}, {"figure": 1, "5": 1, "test": 1, "performance": 1, "ddpgcher": 1, "": 2, "fix": 1, "different": 1, "value": 1, "inf": 1, "refer": 1, "proximityonly": 1}, {"compare": 1, "ddpgcher": 1, "use": 2, "curriculum": 1, "increase": 1, "": 2, "figure": 1, "3": 1, "performance": 1, "cher": 1, "significantly": 1, "vary": 1, "different": 1, "f": 1, "ixed": 1, "perform": 1, "much": 1, "worse": 1}, {"contrast": 1, "ddpgcher": 1, "gradually": 1, "increase": 1, "": 1, "usually": 1, "result": 1, "smoother": 1, "stable": 1, "learn": 2, "process": 1, "rapidly": 1, "accomplish": 1, "challenge": 1, "task": 1}, {"5": 1, "": 2, "conclusion": 1, "main": 1, "contributions": 1, "paper": 1, "summarize": 1, "follow": 1, "1": 1, "introduce": 1, "goalandcuriositydriven": 1, "curriculum": 1, "learn": 1, "hindsight": 1, "experience": 1, "replay": 1}, {"knowledge": 1, "result": 1, "curriculumguided": 1, "cher": 2, "first": 1, "work": 1, "adaptively": 1, "select": 1, "fail": 1, "experience": 1, "replay": 1, "accord": 1, "compatibility": 1, "usefulness": 1, "different": 1, "learn": 2, "stag": 2, "deep": 1, "rl": 2, "2": 1, "show": 2, "large": 2, "diversity": 1, "beneficial": 1, "earlier": 1, "exploration": 1, "proximity": 1, "desire": 1, "goals": 1, "essential": 1, "effective": 1, "exploitation": 1, "later": 1, "3": 1, "sample": 1, "efficiency": 1, "speed": 1, "offpolicy": 1, "algorithms": 1, "significantly": 1, "improve": 1}, {"attribute": 1, "global": 1, "knowledge": 1, "learn": 1, "set": 1, "fail": 1, "experience": 2, "break": 1, "constraint": 1, "local": 1, "oneepisode": 1, "towards": 1, "robust": 1, "strategies": 1, "4": 1, "apply": 1, "cher": 2, "several": 1, "challenge": 1, "continuous": 1, "robotics": 1, "environments": 3, "sparse": 1, "reward": 1, "demonstrate": 1, "effectiveness": 1, "advantage": 1, "herbased": 1, "approach": 1, "5": 1, "make": 1, "assumptions": 1, "task": 2, "potentially": 1, "generalize": 1, "complicate": 1, "settings": 1}, {"acknowledgments": 1, "would": 1, "like": 1, "thank": 1, "tencent": 1, "ai": 1, "lab": 1, "robotics": 1, "x": 1, "provide": 1, "excellent": 1, "research": 1, "environment": 1, "make": 1, "work": 1, "possible": 1}, {"also": 1, "would": 1, "like": 1, "thank": 1, "anonymous": 1, "reviewers": 1}, {"9": 1, "": 1, "reference": 1, "e": 1, "l": 1, "allgower": 1, "k": 1, "georg": 1}, {"introduction": 1, "numerical": 1, "continuation": 1, "methods": 1}, {"society": 1, "industrial": 1, "apply": 1, "mathematics": 1, "2003": 1}, {"andrychowicz": 1, "f": 1, "wolski": 1, "ray": 1, "j": 2, "schneider": 1, "r": 1, "fong": 1, "p": 2, "welinder": 1, "b": 1, "mcgrew": 1, "tobin": 1, "abbeel": 1, "w": 1, "zaremba": 1}, {"hindsight": 1, "experience": 1, "replay": 1}, {"advance": 1, "neural": 1, "information": 1, "process": 1, "systems": 1, "page": 1, "50485058": 1, "2017": 1}, {"basu": 1, "j": 1, "christensen": 1}, {"teach": 1, "classification": 1, "boundaries": 1, "humans": 1}, {"aaai": 1, "conference": 1, "artificial": 1, "intelligence": 1, "page": 1, "109115": 1, "2013": 1}, {"batra": 1, "p": 1, "yadollahpour": 1, "guzmanrivera": 1, "g": 1, "shakhnarovich": 1}, {"diverse": 1, "mbest": 1, "solutions": 1, "markov": 1, "random": 1, "field": 1}, {"european": 1, "conference": 1, "computer": 1, "vision": 1, "page": 1, "116": 1, "2012": 1}, {"bengio": 1}, {"evolve": 1, "culture": 1, "versus": 1, "local": 1, "minima": 1, "page": 1, "109138": 1}, {"springer": 1, "berlin": 1, "heidelberg": 1, "2014": 1}, {"bengio": 1, "j": 2, "louradour": 1, "r": 1, "collobert": 1, "weston": 1}, {"curriculum": 1, "learn": 1}, {"international": 1, "conference": 1, "machine": 1, "learn": 1, "page": 1, "4148": 1, "2009": 1}, {"bengio": 1, "courville": 1, "p": 1, "vincent": 1}, {"representation": 1, "learn": 1, "review": 1, "new": 1, "perspectives": 1}, {"ieee": 1, "transactions": 1, "pattern": 1, "analysis": 1, "machine": 1, "intelligence": 1, "35817981828": 1, "2013": 1}, {"g": 1, "brockman": 1, "v": 1, "cheung": 1, "l": 1, "pettersson": 1, "j": 3, "schneider": 1, "schulman": 1, "tang": 1, "w": 1, "zaremba": 1}, {"openai": 1, "gym": 1, "2016": 1}, {"burda": 1, "h": 1, "edwards": 1, "pathak": 1, "storkey": 1, "darrell": 1}, {"efros": 1}, {"largescale": 1, "study": 1, "curiositydriven": 1, "learn": 1}, {"international": 1, "conference": 1, "learn": 1, "representations": 1, "2019": 1}, {"conforti": 1, "g": 1, "cornuejols": 1}, {"submodular": 1, "set": 1, "function": 1, "matroids": 1, "greedy": 1, "algorithm": 1, "tight": 1, "worstcase": 1, "bound": 1, "generalizations": 1, "radoedmonds": 1, "theorem": 1}, {"discrete": 1, "apply": 1, "mathematics": 1, "73251274": 1, "1984": 1}, {"g": 2, "cornujols": 1, "fisher": 1, "nemhauser": 1}, {"uncapacitated": 1, "location": 1, "problem": 1}, {"annals": 1, "discrete": 1, "mathematics": 1, "1163177": 1, "1977": 1}, {"w": 2, "czarnecki": 1, "jayakumar": 1, "jaderberg": 1, "l": 1, "hasenclever": 1, "teh": 1, "n": 1, "heess": 1, "osindero": 1, "r": 1, "pascanu": 1}, {"mix": 1, "match": 1, "agent": 1, "curricula": 1, "reinforcement": 1, "learn": 1}, {"international": 1, "conference": 1, "machine": 1, "learn": 1, "volume": 1, "80": 1, "page": 1, "10871095": 1, "2018": 1}, {"duan": 1, "x": 1, "chen": 1, "r": 1, "houthooft": 1, "j": 1, "schulman": 1, "p": 1, "abbeel": 1}, {"benchmarking": 1, "deep": 1, "reinforcement": 1, "learn": 1, "continuous": 1, "control": 1}, {"international": 1, "conference": 1, "machine": 1, "learn": 1, "page": 1, "1329": 1, "1338": 1, "2016": 1}, {"eppe": 1, "magg": 1, "wermter": 1}, {"curriculum": 1, "goal": 1, "mask": 1, "continuous": 1, "deep": 1, "reinforcement": 1, "learn": 1}, {"arxiv": 1, "preprint": 1, "arxiv180906146": 1, "2018": 1}, {"fang": 1, "c": 1, "zhou": 1, "b": 2, "shi": 1, "gong": 1, "j": 1, "xu": 1, "zhang": 1}, {"dher": 1, "hindsight": 1, "experience": 1, "replay": 1, "dynamic": 1, "goals": 1}, {"international": 1, "conference": 1, "learn": 1, "representations": 1, "2019": 1}, {"fiterau": 1, "dubrawski": 1}, {"projection": 1, "retrieval": 1, "classification": 1}, {"advance": 1, "neural": 1, "information": 1, "process": 1, "systems": 1, "page": 1, "30233031": 1}, {"2012": 1}, {"c": 1, "florensa": 1, "hold": 1, "wulfmeier": 1, "zhang": 1, "p": 1, "abbeel": 1}, {"reverse": 1, "curriculum": 1, "generation": 1, "reinforcement": 1, "learn": 1}, {"conference": 1, "robot": 1, "learn": 1, "volume": 1, "78": 1, "page": 1, "482495": 1, "2017": 1}, {"p": 1, "fournier": 1, "sigaud": 1, "chetouani": 1, "py": 1}, {"oudeyer": 1}, {"accuracybased": 1, "curriculum": 1, "learn": 2, "deep": 1, "reinforcement": 1}, {"arxiv": 1, "preprint": 1, "arxiv180609614": 1, "2018": 1}, {"frank": 1, "j": 2, "leitner": 1, "f": 1, "stollenga": 1, "frster": 1, "schmidhuber": 1}, {"curiosity": 1, "drive": 1, "reinforcement": 1, "learn": 1, "motion": 1, "plan": 1, "humanoids": 1}, {"frontiers": 1, "neurorobotics": 1, "2013": 1}, {"fujishige": 1}, {"submodular": 1, "function": 1, "optimization": 1}, {"annals": 1, "discrete": 1, "mathematics": 1}, {"elsevier": 1, "2005": 1}, {"10": 1, "": 1, "j": 1, "gillenwater": 1, "kulesza": 1, "b": 1, "taskar": 1}, {"nearoptimal": 1, "map": 1, "inference": 1, "determinantal": 1, "point": 1, "process": 1}, {"advance": 1, "neural": 1, "information": 1, "process": 1, "systems": 1, "page": 1, "27352743": 1, "2012": 1}, {"gu": 1, "lillicrap": 1, "sutskever": 1, "levine": 1}, {"continuous": 1, "deep": 1, "qlearning": 1, "modelbased": 1, "acceleration": 1}, {"international": 1, "conference": 1, "machine": 1, "learn": 1, "page": 1, "28292838": 1, "2016": 1}, {"n": 1, "justesen": 1, "risi": 1}, {"automate": 1, "curriculum": 1, "learn": 1, "reward": 1, "temporally": 1, "rare": 1, "events": 1}, {"ieee": 1, "conference": 1, "computational": 1, "intelligence": 1, "game": 1, "page": 1, "18": 1, "2018": 1}, {"f": 1, "khan": 1, "x": 1, "j": 1, "zhu": 1, "b": 1, "mutlu": 1}, {"humans": 1, "teach": 2, "curriculum": 1, "learn": 1, "dimension": 1}, {"advance": 1, "neural": 1, "information": 1, "process": 1, "systems": 1, "page": 1, "14491457": 1, "2011": 1}, {"p": 1, "kumar": 1, "b": 1, "packer": 1, "koller": 1}, {"selfpaced": 1, "learn": 1, "latent": 1, "variable": 1, "model": 1}, {"advance": 1, "neural": 1, "information": 1, "process": 1, "systems": 1, "page": 1, "11891197": 1, "2010": 1}, {"p": 1, "lillicrap": 1, "j": 2}, {"hunt": 1, "pritzel": 1, "n": 1, "heess": 1, "erez": 1, "tassa": 1, "silver": 1, "wierstra": 1}, {"continuous": 1, "control": 1, "deep": 1, "reinforcement": 1, "learn": 1}, {"arxiv": 1, "preprint": 1, "arxiv150902971": 1, "2015": 1}, {"h": 1, "lin": 1, "j": 1}, {"bilmes": 1}, {"class": 1, "submodular": 1, "function": 1, "document": 1, "summarization": 1}, {"annual": 1, "meet": 1, "association": 1, "computational": 1, "linguistics": 1, "page": 1, "510520": 1, "2011": 1}, {"h": 1, "lin": 1, "j": 1}, {"bilmes": 1, "xie": 1}, {"graphbased": 1, "submodular": 1, "selection": 1, "extractive": 1, "summarization": 1}, {"ieee": 1, "automatic": 1, "speech": 1, "recognition": 1, "understand": 1, "workshop": 1, "merano": 1, "italy": 1, "december": 1, "2009": 1}, {"h": 1, "liu": 1, "trott": 1, "r": 1, "socher": 1, "c": 1, "xiong": 1}, {"competitive": 1, "experience": 1, "replay": 1}, {"international": 1, "conference": 1, "learn": 1, "representations": 1, "2019": 1}, {"l": 1, "metz": 1, "j": 2, "ibarz": 1, "n": 1, "jaitly": 1, "davidson": 1}, {"discrete": 1, "sequential": 1, "prediction": 1, "continuous": 1, "action": 1, "deep": 1, "rl": 1}, {"arxiv": 1, "preprint": 1, "arxiv170505035": 1, "2017": 1}, {"minoux": 1}, {"accelerate": 1, "greedy": 1, "algorithms": 1, "maximize": 1, "submodular": 1, "set": 1, "function": 1}, {"optimization": 1, "techniques": 1, "volume": 1, "7": 1, "lecture": 1, "note": 1, "control": 1, "information": 1, "sciences": 1, "chapter": 1, "27": 1, "page": 1, "234243": 1}, {"springer": 1, "berlin": 1, "heidelberg": 1, "1978": 1}, {"b": 1, "mirzasoleiman": 1, "badanidiyuru": 1, "karbasi": 1, "j": 1, "vondrk": 1, "krause": 1}, {"lazier": 1, "lazy": 1, "greedy": 1}, {"aaai": 1, "conference": 1, "artificial": 1, "intelligence": 1, "page": 1, "18121818": 1, "2015": 1}, {"b": 1, "mirzasoleiman": 1, "karbasi": 1, "r": 1, "sarkar": 1, "krause": 1}, {"distribute": 1, "submodular": 1, "maximization": 1}, {"journal": 1, "machine": 1, "learn": 1, "research": 1, "17238144": 1, "2016": 1}, {"v": 1, "mnih": 1, "k": 1, "kavukcuoglu": 1, "silver": 1}, {"rusu": 1, "j": 1, "veness": 1, "g": 2, "bellemare": 1, "grave": 1, "riedmiller": 1, "k": 1, "fidjeland": 1, "ostrovski": 1, "petersen": 1, "c": 1, "beattie": 1, "sadik": 1, "antonoglou": 1, "h": 1, "king": 1, "kumaran": 1, "wierstra": 1, "legg": 1, "hassabis": 1}, {"humanlevel": 1, "control": 1, "deep": 1, "reinforcement": 1, "learn": 1}, {"nature": 1, "518529": 1, "2015": 1}, {"v": 2, "nair": 1, "pong": 1, "dalal": 1, "bahl": 1, "lin": 1, "levine": 1}, {"visual": 1, "reinforcement": 1, "learn": 1, "imagine": 1, "goals": 1}, {"advance": 1, "neural": 1, "information": 1, "process": 1, "systems": 1, "page": 1, "91919200": 1, "2018": 1}, {"g": 1, "l": 3, "nemhauser": 1, "wolsey": 1, "fisher": 1}, {"analysis": 1, "approximations": 1, "maximize": 1, "submodular": 1, "set": 1, "functionsi": 1}, {"mathematical": 1, "program": 1, "141265294": 1, "1978": 1}, {"ng": 1, "harada": 1, "russell": 1}, {"policy": 1, "invariance": 1, "reward": 2, "transformations": 1, "theory": 1, "application": 1, "shape": 1}, {"international": 1, "conference": 1, "machine": 1, "learn": 1, "volume": 1, "99": 1, "page": 1, "278287": 1, "1999": 1}, {"pathak": 1, "p": 1, "agrawal": 1}, {"efros": 1, "darrell": 1}, {"curiositydriven": 1, "exploration": 1, "selfsupervised": 1, "prediction": 1}, {"international": 1, "conference": 1, "machine": 1, "learn": 1, "2017": 1}, {"plappert": 1, "andrychowicz": 1, "ray": 1, "b": 2, "mcgrew": 1, "baker": 1, "g": 1, "powell": 1, "j": 2, "schneider": 1, "tobin": 1, "chociej": 1, "p": 1, "welinder": 1, "et": 1, "al": 1}, {"multigoal": 1, "reinforcement": 1, "learn": 1, "challenge": 1, "robotics": 1, "environments": 1, "request": 1, "research": 1}, {"arxiv": 1, "preprint": 1, "arxiv180209464": 1, "2018": 1}, {"11": 1, "": 1, "prasad": 1, "jegelka": 1, "batra": 1}, {"submodular": 1, "meet": 1, "structure": 2, "find": 1, "diverse": 1, "subsets": 1, "exponentiallylarge": 1, "item": 1, "set": 1}, {"advance": 1, "neural": 1, "information": 1, "process": 1, "systems": 1, "page": 1, "26452653": 1, "2014": 1}, {"p": 1, "rauber": 1, "ummadisingu": 1, "f": 1, "mutz": 1, "j": 1, "schmidhuber": 1}, {"hindsight": 1, "policy": 1, "gradients": 1}, {"international": 1, "conference": 1, "learn": 1, "representations": 1, "2019": 1}, {"n": 1, "savinov": 1, "raichuk": 1, "vincent": 1, "r": 1, "marinier": 1, "pollefeys": 1, "lillicrap": 1, "gelly": 1}, {"episodic": 1, "curiosity": 1, "reachability": 1}, {"international": 1, "conference": 1, "learn": 1, "representations": 1, "2019": 1}, {"schaul": 1, "horgan": 1, "k": 1, "gregor": 1, "silver": 1}, {"universal": 1, "value": 1, "function": 1, "approximators": 1}, {"international": 1, "conference": 1, "machine": 1, "learn": 1, "page": 1, "13121320": 1, "2015": 1}, {"v": 1, "spitkovsky": 1, "h": 1, "alshawi": 1, "jurafsky": 1}, {"baby": 1, "step": 1, "less": 1, "unsupervised": 1, "dependency": 1, "parse": 1}, {"advance": 1, "neural": 1, "information": 1, "process": 1, "systems": 1, "workshop": 1, "grammar": 1, "induction": 1, "representation": 1, "language": 2, "learn": 1, "2009": 1}, {"j": 1, "supancic": 1, "iii": 1, "ramanan": 1}, {"selfpaced": 1, "learn": 1, "longterm": 1, "track": 1}, {"conference": 1, "computer": 1, "vision": 1, "pattern": 1, "recognition": 1, "page": 1, "23792386": 1, "2013": 1}, {"k": 1, "tang": 1, "v": 1, "ramanathan": 1, "l": 1, "feifei": 1, "koller": 1}, {"shift": 1, "weight": 1, "adapt": 1, "object": 1, "detectors": 1, "image": 1, "video": 1}, {"advance": 1, "neural": 1, "information": 1, "process": 1, "systems": 1, "page": 1, "638646": 1, "2012a": 1}, {"tang": 1, "yb": 1}, {"yang": 1, "gao": 1}, {"selfpaced": 1, "dictionary": 1, "learn": 1, "image": 1, "classification": 1}, {"acm": 1, "international": 1, "conference": 1, "multimedia": 1, "page": 1, "833836": 1, "2012b": 1}, {"tian": 1, "q": 1, "gong": 1, "w": 1, "shang": 1, "wu": 1, "c": 1, "l": 1, "zitnick": 1}, {"elf": 1, "extensive": 1, "lightweight": 1, "flexible": 1, "research": 1, "platform": 1, "realtime": 1, "strategy": 1, "game": 1}, {"advance": 1, "neural": 1, "information": 1, "process": 1, "systems": 1, "page": 1, "26592669": 1, "2017": 1}, {"e": 1, "todorov": 1, "erez": 1, "tassa": 1}, {"mujoco": 1, "physics": 1, "engine": 1, "modelbased": 1, "control": 1}, {"ieeersj": 1, "international": 1, "conference": 1, "intelligent": 1, "robots": 1, "systems": 1, "page": 1, "50265033": 1, "2012": 1}, {"k": 1, "wei": 1, "r": 1, "iyer": 1, "j": 1, "bilmes": 1}, {"fast": 1, "multistage": 1, "submodular": 1, "maximization": 1}, {"international": 1, "conference": 1, "machine": 1, "learn": 1, "2014": 1}, {"wu": 1, "tian": 1}, {"train": 1, "agent": 1, "firstperson": 1, "shooter": 1, "game": 1, "actorcritic": 1, "curriculum": 1, "learn": 1}, {"international": 1, "conference": 1, "learn": 1, "representations": 1, "2017": 1}, {"r": 1, "zhao": 1, "v": 1, "tresp": 1}, {"energybased": 1, "hindsight": 1, "experience": 1, "prioritization": 1}, {"conference": 1, "robot": 1, "learn": 1, "page": 1, "113122": 1, "2018": 1}, {"zhou": 1, "j": 1, "bilmes": 1}, {"minimax": 1, "curriculum": 1, "learn": 1, "machine": 1, "teach": 1, "desirable": 1, "difficulties": 1, "schedule": 1, "diversity": 1}, {"international": 1, "conference": 1, "learn": 1, "representations": 1, "2018": 1}, {"zhou": 1, "wang": 1, "j": 1}, {"bilmes": 1}, {"diverse": 1, "ensemble": 1, "evolution": 1, "curriculum": 1, "datamodel": 1, "marriage": 1}, {"advance": 1, "neural": 1, "information": 1, "process": 1, "systems": 1, "page": 1, "59055916": 1}, {"2018": 1}, {"12": 1}]