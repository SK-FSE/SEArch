[{"finitesample": 1, "analysis": 1, "sarsa": 2, "linear": 1, "function": 1, "approximation": 1, "shaofeng": 1, "zou": 1, "department": 3, "electrical": 1, "engineer": 1, "university": 4, "buffalo": 2, "state": 3, "new": 1, "york": 1, "ny": 1, "14228": 1, "szou3buffaloedu": 1, "tengyu": 1, "xu": 1, "ece": 2, "ohio": 2, "columbus": 2, "oh": 2, "43210": 2, "xu3260osuedu": 1, "": 2, "yingbin": 1, "liang": 1, "liang889osuedu": 1, "abstract": 1, "onpolicy": 1, "algorithm": 1, "learn": 2, "markov": 1, "decision": 1, "process": 1, "policy": 1, "reinforcement": 1}, {"investigate": 1, "sarsa": 1, "algorithm": 1, "linear": 1, "function": 1, "approximation": 1, "noniid": 1}, {"data": 1, "single": 1, "sample": 1, "trajectory": 1, "available": 1}, {"lipschitz": 1, "continuous": 1, "policy": 1, "improvement": 1, "operator": 1, "smooth": 1, "enough": 1, "sarsa": 1, "show": 1, "converge": 1, "asymptotically": 1, "28": 1, "23": 1}, {"however": 1, "nonasymptotic": 1, "analysis": 1, "challenge": 1, "remain": 1, "unsolved": 1, "due": 1, "noniid": 1}, {"sample": 1, "fact": 1, "behavior": 1, "policy": 1, "change": 1, "dynamically": 1, "time": 1}, {"paper": 1, "develop": 1, "novel": 1, "technique": 1, "explicitly": 1, "characterize": 1, "stochastic": 2, "bias": 1, "type": 1, "approximation": 1, "procedures": 1, "timevarying": 1, "markov": 1, "transition": 1, "kernels": 1}, {"approach": 1, "enable": 1, "nonasymptotic": 1, "convergence": 1, "analyse": 1, "type": 1, "stochastic": 1, "approximation": 1, "algorithms": 1, "may": 1, "independent": 1, "interest": 1}, {"use": 1, "bias": 1, "characterization": 1, "technique": 1, "gradient": 1, "descent": 1, "type": 1, "analysis": 2, "provide": 1, "finitesample": 1, "mean": 1, "square": 1, "error": 1, "sarsa": 1, "algorithm": 1}, {"study": 1, "fit": 1, "sarsa": 2, "algorithm": 2, "include": 1, "original": 1, "variant": 1, "28": 1, "special": 1, "case": 1}, {"fit": 2, "sarsa": 1, "algorithm": 1, "provide": 1, "general": 1, "framework": 1, "iterative": 1, "onpolicy": 1, "policy": 1, "iteration": 1, "memory": 1, "computationally": 1, "efficient": 1}, {"fit": 1, "sarsa": 1, "algorithm": 1, "also": 1, "provide": 1, "finitesample": 1, "analysis": 1}, {"1": 1, "": 2, "introduction": 1, "sarsa": 1, "originally": 1, "propose": 1, "31": 1, "onpolicy": 1, "reinforcement": 1, "learn": 1, "algorithm": 1, "continuously": 1, "update": 1, "behavior": 1, "policy": 1, "towards": 1, "attain": 1, "large": 1, "accumulate": 1, "reward": 1, "possible": 1, "time": 1}, {"specifically": 1, "sarsa": 1, "initialize": 1, "state": 1, "policy": 1}, {"time": 1, "instance": 1, "take": 1, "action": 1, "base": 1, "current": 1, "policy": 1, "observe": 1, "next": 1, "state": 1, "receive": 1, "reward": 1}, {"use": 1, "newly": 1, "observe": 1, "information": 1, "first": 1, "update": 1, "estimate": 2, "actionvalue": 2, "function": 2, "improve": 1, "behavior": 1, "policy": 2, "apply": 1, "improvement": 1, "operator": 1, "eg": 1, "greedy": 1}, {"process": 1, "iteratively": 1, "take": 1, "converge": 1, "see": 1, "algorithm": 2, "1": 1, "precise": 1, "description": 1, "sarsa": 1}, {"tabular": 1, "approach": 1, "store": 1, "actionvalue": 1, "function": 1, "convergence": 1, "sarsa": 1, "establish": 1, "33": 1}, {"however": 1, "tabular": 1, "approach": 1, "may": 1, "applicable": 1, "state": 1, "space": 1, "33rd": 1, "conference": 1, "neural": 1, "information": 1, "process": 1, "systems": 1, "neurips": 1, "2019": 1, "vancouver": 1, "canada": 1}, {"large": 1, "continuous": 1}, {"purpose": 1, "sarsa": 1, "incorporate": 1, "parametrized": 1, "function": 1, "approximation": 1, "commonly": 1, "use": 1, "efficient": 1, "scalable": 1}, {"function": 1, "approximation": 1, "approach": 1, "sarsa": 1, "guarantee": 1, "converge": 1, "general": 1, "greedy": 1, "softmax": 1, "policy": 1, "improvement": 1, "operators": 1, "use": 1, "13": 1, "10": 1}, {"however": 1, "certain": 1, "condition": 1, "convergence": 1, "establish": 1}, {"example": 1, "variant": 1, "sarsa": 1, "linear": 1, "function": 2, "approximation": 1, "construct": 1, "28": 1, "two": 1, "policy": 1, "improvements": 1, "temporal": 1, "difference": 1, "td": 1, "learn": 2, "algorithm": 1, "apply": 1, "actionvalue": 1, "till": 1, "convergence": 1}, {"convergence": 1, "algorithm": 1, "establish": 1, "28": 1, "use": 1, "contraction": 1, "argument": 1, "condition": 1, "policy": 1, "improvement": 1, "operator": 1, "lipschitz": 2, "continuous": 1, "constant": 1, "large": 1}, {"convergence": 1, "original": 1, "sarsa": 1, "algorithm": 1, "lipschitz": 1, "condition": 1, "later": 1, "establish": 1, "use": 1, "ode": 1}, {"approach": 1, "23": 1}, {"previous": 1, "study": 1, "sarsa": 2, "28": 1, "23": 1, "mainly": 1, "focus": 1, "asymptotic": 1, "convergence": 1, "analysis": 1, "suggest": 1, "fast": 1, "converge": 1, "accuracy": 1, "solution": 1, "depend": 1, "number": 1, "sample": 2, "ie": 1, "complexity": 1}, {"goal": 1, "paper": 1, "provide": 1, "nonasymptotic": 1, "finitesample": 1, "analysis": 1, "sarsa": 1, "understand": 1, "parameters": 1, "underlie": 1, "markov": 1, "process": 1, "algorithm": 1, "affect": 1, "convergence": 1, "rate": 1}, {"technically": 1, "analysis": 2, "follow": 1, "directly": 1, "exist": 1, "finitesample": 1, "time": 1, "difference": 1, "td": 1, "learn": 1, "4": 1, "34": 1, "qlearning": 1, "32": 1, "sample": 1, "take": 1, "markov": 1, "process": 1, "fix": 1, "transition": 1, "kernel": 1}, {"analysis": 1, "sarsa": 1, "necessarily": 1, "need": 1, "deal": 1, "sample": 1, "take": 1, "markov": 2, "decision": 2, "process": 2, "timevarying": 2, "transition": 2, "kernel": 2, "paper": 1, "develop": 1, "novel": 1, "techniques": 1, "explicitly": 1, "characterize": 1, "stochastic": 1, "bias": 1, "may": 1, "independent": 1, "interest": 1}, {"11": 1, "": 2, "contributions": 1, "paper": 1, "design": 1, "novel": 1, "approach": 1, "analyze": 1, "sarsa": 2, "general": 1, "fit": 1, "algorithm": 1, "develop": 1, "correspond": 1, "finitesample": 1, "error": 1, "bound": 1}, {"particular": 1, "consider": 1, "online": 1, "set": 1, "single": 1, "sample": 2, "trajectory": 1, "markovian": 1, "noise": 1, "available": 1, "ie": 1, "identical": 1, "independently": 1, "distribute": 1, "iid": 1}, {"bias": 1, "characterization": 1, "timevarying": 1, "markov": 1, "process": 1}, {"one": 1, "major": 1, "challenge": 1, "analysis": 1, "due": 1, "fact": 1, "estimate": 1, "gradient": 1, "bias": 1, "noniid": 1}, {"markovian": 1, "noise": 1}, {"exist": 1, "study": 1, "mostly": 1, "focus": 1, "case": 1, "sample": 1, "generate": 1, "accord": 1, "markov": 2, "process": 2, "fix": 1, "transition": 1, "kernel": 1, "eg": 1, "td": 1, "learn": 1, "4": 1, "34": 1, "qlearning": 1, "nearest": 1, "neighbor": 1, "32": 1, "uniform": 1, "ergodicity": 1, "exploit": 1, "decouple": 1, "dependency": 1, "markovian": 1, "noise": 1, "explicitly": 1, "bind": 1, "stochastic": 1, "bias": 1}, {"markov": 1, "process": 1, "timevarying": 1, "transition": 1, "kernel": 1, "property": 1, "uniform": 1, "ergodicity": 1, "hold": 1, "general": 1}, {"paper": 1, "develop": 1, "novel": 1, "approach": 1, "explicitly": 1, "characterize": 1, "stochastic": 1, "bias": 1, "induce": 1, "noniid": 1}, {"sample": 1, "generate": 1, "markov": 1, "process": 1, "timevarying": 1, "transition": 1, "kernels": 1}, {"central": 1, "idea": 1, "approach": 1, "construct": 1, "auxiliary": 1, "markov": 2, "chain": 1, "uniformly": 1, "ergodic": 1, "approximate": 1, "dynamically": 1, "change": 1, "process": 1, "facilitate": 1, "analysis": 1}, {"approach": 1, "also": 1, "apply": 1, "generally": 1, "analyze": 1, "stochastic": 1, "approximation": 1, "sa": 1, "algorithms": 1, "timevarying": 1, "markov": 1, "transition": 1, "kernels": 1, "may": 1, "independent": 1, "interest": 1}, {"finitesample": 1, "analysis": 1, "onpolicy": 1, "sarsa": 1}, {"onpolicy": 1, "sarsa": 1, "algorithm": 1, "estimate": 1, "actionvalue": 1, "function": 1, "change": 2, "time": 1, "behavior": 1, "policy": 1, "also": 1}, {"gradient": 1, "descent": 1, "type": 1, "analysis": 2, "4": 1, "bias": 1, "characterization": 1, "technique": 1, "analyze": 1, "timevarying": 1, "markov": 1, "process": 1, "develop": 1, "finitesample": 1, "onpolicy": 1, "sarsa": 1, "algorithm": 1, "continuous": 1, "state": 1, "space": 1, "linear": 1, "function": 1, "approximation": 1}, {"analysis": 1, "online": 1, "case": 1, "single": 1, "sample": 1, "trajectory": 1, "noniid": 1}, {"data": 1}, {"best": 1, "knowledge": 1, "first": 1, "finitesample": 1, "analysis": 1, "type": 1, "onpolicy": 1, "algorithm": 1, "timevarying": 1, "behavior": 1, "policy": 1}, {"fit": 1, "sarsa": 1, "algorithm": 1}, {"propose": 1, "general": 1, "online": 1, "fit": 2, "sarsa": 2, "algorithm": 1, "two": 1, "policy": 2, "improvements": 1, "step": 1, "take": 2, "obtain": 1, "accurate": 1, "estimate": 1, "actionvalue": 1, "function": 1, "correspond": 1, "behavior": 1, "via": 1, "multiple": 1, "iterations": 1, "rather": 1, "single": 1, "iteration": 1, "original": 1}, {"particular": 1, "include": 1, "variant": 1, "sarsa": 1, "28": 1, "special": 1, "case": 1, "fit": 1, "step": 1, "require": 1, "converge": 1, "policy": 1, "improvement": 1}, {"provide": 1, "nonasymptotic": 1, "analysis": 1, "convergence": 1, "propose": 1, "algorithm": 1}, {"interestingly": 1, "analysis": 1, "indicate": 1, "fit": 2, "step": 1, "stop": 1, "time": 1, "necessarily": 1, "convergence": 2, "without": 1, "affect": 1, "overall": 1, "sarsa": 1, "algorithm": 1}, {"2": 1, "": 3, "12": 1, "relate": 1, "work": 1, "finitesample": 1, "analysis": 1, "td": 1, "learn": 1}, {"asymptotic": 1, "convergence": 1, "td": 1, "algorithm": 1, "establish": 1, "36": 1}, {"finitesample": 1, "analysis": 1, "td": 1, "algorithm": 1, "provide": 1, "9": 1, "19": 1, "iid": 1}, {"set": 1, "4": 1, "34": 1, "recently": 1, "noniid": 1}, {"set": 1, "single": 1, "sample": 1, "trajectory": 1, "available": 1}, {"finite": 1, "sample": 1, "analysis": 1, "twotime": 1, "scale": 1, "methods": 1, "td": 1, "learn": 1, "also": 1, "study": 1, "recently": 1, "iid": 1}, {"set": 1, "8": 1, "noniid": 1}, {"set": 1, "constant": 1, "step": 1, "size": 1, "15": 1, "noniid": 1}, {"set": 1, "diminish": 1, "step": 1, "size": 1, "38": 1}, {"differently": 1, "td": 1, "goal": 1, "estimate": 2, "value": 1, "function": 2, "fix": 1, "policy": 2, "sarsa": 1, "aim": 1, "continuously": 1, "update": 1, "actionvalue": 1, "obtain": 1, "optimal": 1}, {"sample": 2, "td": 1, "algorithm": 1, "generate": 2, "follow": 2, "timeinvariant": 1, "behavior": 2, "policy": 2, "sarsa": 1, "instantaneous": 1, "estimate": 1, "actionvalue": 1, "function": 1, "change": 1, "time": 1}, {"qlearning": 1, "function": 1, "approximation": 1}, {"asymptotic": 1, "convergence": 1, "qlearning": 1, "linear": 1, "function": 1, "approximation": 1, "establish": 1, "23": 1, "certain": 1, "condition": 1}, {"approach": 1, "base": 1, "combination": 1, "qlearning": 1, "kernelbased": 1, "nearest": 2, "neighbor": 2, "regression": 2, "propose": 1, "32": 1, "first": 1, "discretize": 1, "entire": 1, "state": 1, "space": 1, "use": 1, "method": 1, "estimate": 1, "actionvalue": 1, "function": 1}, {"approach": 1, "show": 1, "converge": 1, "finitesample": 1, "analysis": 1, "convergence": 1, "rate": 1, "provide": 1}, {"qlearning": 1, "algorithms": 2, "23": 1, "32": 1, "offpolicy": 1, "fix": 1, "behavior": 2, "policy": 2, "use": 1, "collect": 1, "sample": 1, "whereas": 1, "sarsa": 1, "onpolicy": 1, "algorithm": 1, "timevarying": 1}, {"moreover": 1, "differently": 1, "nearest": 1, "neighbor": 1, "approach": 1, "consider": 1, "sarsa": 1, "linear": 1, "function": 1, "approximation": 1}, {"differences": 1, "require": 1, "different": 1, "techniques": 1, "characterize": 1, "nonasymptotic": 1, "convergence": 1, "rate": 1}, {"onpolicy": 1, "sarsa": 1, "algorithm": 1}, {"sarsa": 1, "originally": 1, "propose": 1, "31": 1, "use": 1, "tabular": 1, "approach": 1, "convergence": 1, "establish": 1, "33": 1}, {"function": 1, "approximation": 1, "sarsa": 1, "guarantee": 1, "converge": 1, "greedy": 1, "softmax": 1, "use": 1}, {"smooth": 1, "enough": 1, "lipschitz": 1, "continuous": 1, "policy": 1, "improvement": 1, "operator": 1, "asymptotic": 1, "convergence": 1, "sarsa": 1, "show": 1, "23": 1, "28": 1}, {"paper": 1, "develop": 1, "nonasymptotic": 1, "finitesample": 1, "analysis": 1, "sarsa": 1, "lipschitz": 1, "continuous": 1, "condition": 1}, {"fit": 1, "valuepolicy": 1, "iteration": 1, "algorithms": 1}, {"leastsquares": 1, "temporal": 1, "difference": 1, "learn": 1, "lstd": 1, "algorithms": 1, "extensively": 1, "study": 1, "6": 1, "5": 1, "25": 1, "20": 1, "12": 1, "29": 1, "30": 1, "35": 1, "37": 1, "reference": 1, "therein": 1, "iteration": 1, "least": 1, "square": 1, "regression": 1, "problem": 1, "base": 1, "batch": 1, "data": 1, "solve": 1}, {"approximate": 1, "fit": 2, "policy": 2, "iteration": 2, "api": 1, "algorithms": 1, "extend": 1, "value": 1, "improvement": 1}, {"several": 1, "variants": 1, "study": 1, "adopt": 1, "different": 1, "objective": 1, "function": 1, "include": 1, "leastsquares": 1, "policy": 3, "iteration": 3, "lspi": 1, "algorithms": 1, "18": 1, "21": 1, "39": 1, "fit": 1, "base": 1, "bellman": 1, "residual": 1, "minimization": 1, "brm": 1, "1": 1, "11": 1, "classificationbased": 1, "algorithm": 1, "22": 1}, {"fit": 1, "sarsa": 1, "algorithm": 2, "paper": 1, "use": 1, "iterative": 1, "way": 1, "td0": 1, "estimate": 1, "actionvalue": 1, "function": 1, "two": 1, "policy": 1, "improvements": 1, "memory": 1, "computationally": 1, "efficient": 1, "batch": 1, "method": 1}, {"differently": 1, "28": 1, "require": 1, "convergent": 1, "td0": 1, "run": 1, "fit": 1, "step": 1}, {"algorithm": 1, "provide": 1, "nonasymptotic": 1, "convergence": 1, "analysis": 1}, {"2": 1, "21": 1, "": 2, "preliminaries": 1, "markov": 2, "decision": 2, "process": 2, "consider": 1, "general": 1, "reinforcement": 1, "learn": 1, "set": 1, "agent": 1, "interact": 1, "stochastic": 1, "environment": 1, "model": 1, "mdp": 1}, {"specifically": 1, "consider": 1, "mdp": 1, "consist": 1, "x": 3, "": 4, "p": 1, "r": 1, "continuous": 1, "state": 1, "space": 1, "rd": 1, "finite": 1, "action": 1, "set": 1}, {"let": 1, "xt": 3, "2": 3, "x": 3, "denote": 2, "state": 1, "time": 2, "action": 2, "measure": 1, "p": 1, "define": 1, "dependent": 1, "r": 1, "transition": 1, "kernel": 1, "underlie": 1, "markov": 1, "chain": 1, "0": 1, "": 6, "pxt1": 1, "u": 3, "pdyx": 1, "measurable": 1, "set": 1}, {"onestage": 1, "reward": 1, "time": 1, "give": 1, "rxt": 1, "": 5, "r": 1, "x": 1}, {"r": 1, "reward": 1, "function": 1, "assume": 1, "uniformly": 1, "bound": 1, "ie": 1, "rx": 1, "2": 2, "0": 1, "rmax": 1, "": 2, "x": 2}, {"finally": 1, "denote": 1, "discount": 1, "factor": 1}, {"stationary": 1, "policy": 1, "map": 1, "state": 1, "x": 3, "2": 1, "probability": 1, "distribution": 1, "depend": 1, "time": 1}, {"policy": 1, "": 4, "correspond": 1, "value": 1, "function": 1, "v": 1, "x": 1}, {"r": 1, "define": 1, "expect": 1, "total": 1, "discount": 1, "reward": 1, "obtain": 1, "action": 1, "execute": 1, "accord": 1, "3": 1, "": 8, "p1": 1, "v": 1, "x0": 2, "e": 1, "t0": 1, "rxt": 1, "x0r": 1}, {"actionvalue": 1, "function": 1, "q": 1, "": 3, "x": 1}, {"r": 1, "define": 1, "q": 1, "x": 1, "": 3, "rx": 1, "pdyx": 1, "av": 1}, {"goal": 1, "find": 1, "optimal": 1, "polx": 1, "icy": 1, "maximize": 1, "value": 1, "function": 1, "initial": 1, "state": 1}, {"optimal": 1, "value": 1, "function": 1, "define": 1, "v": 2, "": 4, "x": 3, "sup": 1, "8x": 1, "2": 1}, {"optimal": 1, "actionvalue": 1, "function": 1, "define": 1, "q": 2, "x": 3, "": 2, "sup": 1, "8x": 1, "2": 1}, {"optimal": 1, "policy": 1, "": 3, "greedy": 1, "spect": 1, "q": 1}, {"verify": 1, "q": 2, "": 2}, {"bellman": 1, "operator": 1, "h": 1, "define": 1, "r": 1, "hqx": 1, "": 2, "rx": 1, "x": 1, "maxb2a": 1, "qy": 1, "bpdyx": 1}, {"clear": 1, "h": 2, "contraction": 1, "sup": 1, "norm": 1, "define": 1, "kqksup": 1, "": 1, "supxa2x": 1, "qx": 1, "optimal": 1, "actionvalue": 1, "function": 1, "q": 1, "fix": 1, "point": 1, "3": 1}, {"22": 1, "": 7, "linear": 1, "function": 2, "approximation": 1, "let": 1, "q": 2, "2": 1, "rn": 1, "family": 1, "realvalued": 1, "define": 1, "x": 1}, {"consider": 1, "problem": 1, "function": 2, "q": 1, "linear": 1, "combination": 1, "set": 1, "n": 1, "fix": 1, "": 2, "x": 1}, {"r": 1, "pn": 1, "": 2, "1": 1}, {"": 1}, {"": 1}, {"": 2, "n": 1}, {"specifically": 1, "": 4, "2": 1, "rn": 1, "q": 1, "x": 3, "i1": 1}, {"assume": 1, "k": 1, "x": 2, "ak2": 1, "": 4, "1": 1, "8x": 1, "2": 1, "ensure": 1, "normalize": 1, "n": 1, "i1": 1}, {"goal": 1, "find": 1, "q": 2, "compact": 1, "representation": 1, "": 1, "approximate": 1, "optimal": 1, "actionvalue": 1, "function": 1, "continuous": 1, "state": 1, "space": 1}, {"3": 1, "31": 1, "": 2, "finitesample": 1, "analysis": 1, "sarsa": 2, "linear": 1, "function": 1, "approximation": 1, "consider": 1, "dependent": 1, "behavior": 1, "policy": 1, "change": 1, "time": 1}, {"specifically": 1, "behavior": 1, "policy": 2, "give": 1, "": 2, "x": 1, "improvement": 1, "operator": 1, "eg": 1, "greedy": 2, "softmax": 1, "mellowmax": 1, "2": 1}, {"suppose": 1, "xt": 1, "": 2, "rt": 1, "0": 1, "sample": 1, "trajectory": 1, "state": 1, "action": 1, "reward": 1, "obtain": 1, "mdp": 1, "follow": 1, "time": 1, "dependent": 1, "behavior": 1, "policy": 1, "see": 1, "algorithm": 1, "1": 1}, {"project": 1, "sarsa": 1, "linear": 1, "function": 1, "approximation": 1, "update": 1, "follow": 1, "t1": 1, "": 19, "proj2r": 2, "gt": 2, "1": 1, "r": 2, "q": 1, "xt": 3, "denote": 1, "temporal": 1, "difference": 1, "time": 1, "xt1": 1, "at1": 1, "arg": 1, "min0": 1, "k0": 1, "k2": 2, "k": 1, "0": 1}, {"": 3, "rxt": 1, "paper": 1, "refer": 1, "gt": 1, "gradient": 2, "although": 1, "function": 1}, {"algorithm": 1, "1": 10, "sarsa": 1, "initialization": 1, "0": 4, "": 17, "x0": 1, "r": 1, "2": 2, "n": 1, "method": 1, "choose": 2, "a0": 1, "accord": 2, "observe": 1, "xt": 1, "rxt": 1, "proj2r": 1, "gt": 2, "policy": 1, "improvement": 1, "end": 1, "projection": 1, "step": 1, "control": 2, "norm": 1, "gradient": 2, "commonly": 1, "use": 1, "technique": 1, "bias": 1, "4": 1, "16": 1, "17": 1, "7": 1, "26": 1}, {"small": 1, "step": 1, "size": 1, "bound": 1, "gradient": 1, "change": 1, "fast": 1}, {"note": 1, "14": 1, "show": 1, "sarsa": 1, "converge": 1, "bound": 2, "region": 1, "thus": 1, "0": 1}, {"imply": 1, "analysis": 1, "still": 1, "hold": 1, "without": 1, "projection": 1, "step": 1}, {"note": 1, "even": 1, "without": 1, "exploit": 1, "fact": 1, "bound": 1, "finitesample": 1, "analysis": 1, "sarsa": 1, "still": 1, "obtain": 1, "combine": 1, "approach": 2, "analyze": 1, "stochastic": 1, "bias": 1, "extension": 1, "34": 1}, {"however": 1, "convey": 1, "central": 1, "idea": 1, "characterize": 1, "stochastic": 1, "bias": 1, "mdp": 1, "dynamically": 1, "change": 1, "transition": 1, "kernel": 1, "focus": 1, "project": 1, "sarsa": 1, "paper": 1}, {"4": 1, "": 1, "consider": 1, "follow": 1, "lipschitz": 1, "continuous": 1, "policy": 1, "improvement": 1, "operator": 1, "28": 1, "23": 1}, {"": 16, "2": 5, "rn": 1, "behavior": 1, "policy": 1, "lipschitz": 2, "respect": 1, "8x": 1, "x": 1, "1": 1, "ax": 2, "ck1": 1, "k2": 1, "c": 1, "0": 1, "constant": 1}, {"discussion": 1, "assumption": 1, "impact": 1, "convergence": 1, "provide": 1, "section": 1, "5": 1}, {"assume": 1, "fix": 1, "": 4, "2": 1, "rn": 1, "markov": 1, "chain": 1, "xt": 1, "0": 1, "induce": 1, "behavior": 1, "policy": 1, "transition": 1, "kernel": 1, "p": 2, "uniformly": 1, "ergodic": 1, "invariant": 1, "measure": 1, "denote": 1, "satisfy": 1, "follow": 1, "assumption": 1}, {"assumption": 1, "1": 1}, {"constants": 1, "": 9, "0": 3, "2": 2, "1": 1, "sup": 1, "dt": 2, "v": 2, "pxt": 1, "x0": 1, "x": 1, "p": 3, "mt": 1, "8t": 1, "x2x": 1, "q": 2, "denote": 1, "totalvariation": 1, "distance": 1, "probability": 1, "measure": 1}, {"denote": 1, "": 3, "probability": 1, "measure": 2, "induce": 1, "invariant": 1, "p": 1, "behavior": 1, "policy": 1}, {"assume": 1, "n": 1, "base": 1, "function": 1, "linearly": 1, "independent": 1, "hilbert": 1, "space": 1, "l2": 1, "x": 1, "": 4, "limit": 1, "point": 1, "algorithm": 1, "1": 1, "define": 1, "next": 1, "section": 1}, {"space": 1, "l2": 1, "x": 2, "": 5, "two": 1, "measurable": 1, "function": 1, "equivalent": 1, "identical": 1, "except": 1, "set": 1, "measure": 1, "zero": 1}, {"32": 1, "": 12, "finitesample": 1, "analysis": 1, "first": 1, "define": 1, "e": 3, "x": 7, "b": 4, "arx": 1, "denote": 1, "expectation": 1, "follow": 3, "invariant": 1, "probability": 1, "measure": 1, "p": 1, "generate": 2, "behavior": 2, "policy": 2, "subsequent": 1, "state": 1, "action": 1, "ie": 1, "transition": 1, "kernel": 1, "py": 1, "2": 1}, {"show": 1, "23": 1, "algorithm": 1, "1": 1, "converge": 1, "unique": 1, "point": 1, "": 7, "satisfy": 1, "follow": 1, "relation": 1, "b": 1, "0": 1, "lipschitz": 1, "constant": 1, "c": 2, "large": 1, "negative": 1, "definite1": 1}, {"1": 3, "let": 1, "g": 1, "": 7, "rmax": 1, "2r": 1, "ga2": 1, "dlog": 1, "e": 1}, {"recall": 1, "2": 1, "policy": 1, "": 2, "lipschitz": 2, "respect": 1, "constant": 1, "c": 1, "make": 1, "follow": 1, "assumption": 1, "28": 1, "23": 1}, {"assumption": 1, "2": 1}, {"lipschitz": 1, "constant": 1, "c": 4, "large": 1, "": 5, "negative": 1, "definite": 1, "denote": 1, "largest": 1, "eigenvalue": 1, "12": 1, "ws": 1, "0": 1}, {"follow": 1, "theorems": 1, "present": 1, "finitesample": 1, "bind": 1, "convergence": 1, "sarsa": 1, "diminish": 1, "constant": 1, "step": 1, "size": 1}, {"theorem": 1, "1": 1}, {"consider": 2, "sarsa": 1, "linear": 1, "function": 1, "approximation": 1, "algorithm": 1, "1": 2, "k": 1, "k2": 1, "": 4, "r": 1, "decay": 1, "step": 1, "size": 1, "2wt1": 1, "0": 1, "w": 1, "ws": 1}, {"assumptions": 1, "1": 3, "2": 2, "g2": 1, "4cag02": 1, "": 15, "12": 1, "c0": 1, "1log": 1, "2g2": 1, "0": 2, "w": 2, "ekt": 1, "k22": 1, "3": 1, "4w2": 1, "w2": 1, "mt": 1}, {"large": 1, "": 10, "0": 2, "log": 1, "hence": 1, "ekt": 1, "k22": 1, "mint": 1, "log3": 1}, {"thus": 1, "guarantee": 1, "accuracy": 1, "ekt": 1, "": 4, "complexity": 1, "give": 1, "log": 1, "1": 2, "3": 1}, {"2": 1, "": 7, "k2": 1, "small": 1, "overall": 1, "sample": 1, "theorem": 1, "1": 1, "indicate": 1, "sarsa": 1, "faster": 1, "convergence": 1, "rate": 1, "exist": 1, "finitesample": 1, "bind": 1, "qlearning": 1, "nearest": 1, "neighbor": 1, "32": 1}, {"theorem": 1, "2": 1}, {"consider": 1, "sarsa": 1, "linear": 1, "function": 1, "approximation": 1, "algorithm": 1, "1": 4, "k": 1, "k2": 1, "": 24, "r": 1, "assumptions": 1, "2": 2, "constant": 1, "step": 1, "size": 1, "0": 6, "2w1": 1, "ekt": 1, "k22": 2, "e": 1, "mint": 1, "20": 1, "ws": 1, "ek0": 1, "g2": 1, "12": 1, "c0": 1, "4gca02": 1, "8": 1, "2ws": 1, "4": 1, "mt": 1}, {"show": 1, "28": 1, "36": 1}, {"": 8, "linearly": 1, "independent": 1, "l2": 1, "x": 1, "negative": 1, "definite": 1, "5": 1, "0": 1, "small": 2, "enough": 2, "isplarge": 1, "algorithm": 1, "converge": 1, "neighborhood": 1}, {"example": 1, "": 3, "1": 1, "upper": 1, "bind": 1, "converge": 1, "zero": 1}, {"1": 1}, {"proof": 1, "theorem": 2, "straightforward": 1, "extension": 1, "1": 1}, {"order": 1, "theorems": 1, "1": 1, "2": 1, "hold": 1, "projection": 1, "radius": 1, "r": 2, "shall": 1, "choose": 1, "k": 1, "k2": 1, "": 2, "however": 1, "unknown": 1, "advance": 1}, {"next": 1, "provide": 1, "upper": 1, "bind": 1, "k": 1, "k2": 1, "": 1, "estimate": 1, "practice": 1, "4": 1}, {"max": 1, "lemma": 1, "1": 1}, {"project": 1, "sarsa": 1, "algorithm": 1, "1": 2, "limit": 1, "point": 1, "": 6, "satisfy": 1, "k": 1, "k2": 1, "rw": 1, "l": 1, "wl": 1, "0": 1, "largest": 1, "eigenvalue": 1, "2": 1}, {"33": 1, "": 2, "outline": 1, "technical": 1, "proof": 1, "theorem": 1, "1": 2, "major": 1, "challenge": 1, "finitesample": 1, "analysis": 1, "sarsa": 1, "lie": 1, "analyze": 1, "stochastic": 1, "bias": 1, "gradient": 1, "twofolds": 1, "noniid": 1}, {"sample": 1, "2": 1, "dynamically": 1, "change": 1, "behavior": 1, "policy": 1}, {"first": 1, "per": 1, "update": 1, "rule": 1, "1": 1, "strong": 2, "couple": 1, "sample": 2, "path": 1, "0": 3, "": 6, "use": 1, "compute": 1, "gradient": 1, "gt": 2, "t1": 1, "introduce": 1, "dependency": 1, "xt": 1, "thus": 1, "bias": 1}, {"moreover": 1, "differently": 1, "td": 1, "learn": 1, "qlearning": 1, "use": 1, "policy": 1, "": 1, "generate": 1, "subsequent": 1, "action": 1, "make": 1, "dependency": 1, "even": 1, "stronger": 1}, {"although": 1, "convergence": 1, "still": 1, "establish": 1, "use": 1, "ode": 1}, {"approach": 1, "23": 1, "order": 1, "derive": 1, "finitesample": 1, "analysis": 1, "stochastic": 1, "bias": 1, "gradient": 1, "need": 1, "explicitly": 1, "characterize": 1, "make": 1, "problem": 1, "challenge": 1}, {"second": 1, "update": 1, "transition": 1, "kernel": 1, "stateaction": 1, "pair": 1, "xt": 1, "": 2, "change": 1, "time": 1}, {"previous": 1, "analyse": 1, "eg": 1, "4": 1, "rely": 1, "facts": 1, "behavior": 1, "policy": 1, "fix": 1, "underlie": 1, "markov": 2, "process": 2, "uniformly": 1, "ergodic": 1, "reach": 1, "stationary": 1, "distribution": 1, "quickly": 1}, {"28": 1, "variant": 1, "sarsa": 1, "study": 1, "two": 1, "policy": 2, "improvements": 1, "behavior": 1, "fix": 1, "td": 1, "method": 1, "use": 1, "estimate": 1, "actionvalue": 1, "function": 1, "convergence": 1}, {"behavior": 1, "policy": 2, "improve": 1, "use": 1, "lipschitz": 1, "continuous": 1, "improvement": 1, "operator": 1}, {"way": 1, "give": 1, "behavior": 1, "policy": 1, "induce": 1, "markov": 1, "process": 1, "reach": 1, "stationary": 1, "distribution": 1, "quickly": 1, "analysis": 1, "conduct": 1}, {"sarsa": 1, "algorithm": 1, "study": 1, "paper": 1, "possess": 1, "nice": 1, "properties": 1}, {"behavior": 1, "policy": 1, "sarsa": 1, "algorithm": 1, "change": 1, "time": 1, "step": 1, "underlie": 1, "markov": 1, "process": 1, "necessarily": 1, "reach": 1, "stationary": 1, "distribution": 1, "due": 1, "lack": 1, "uniform": 1, "ergodicity": 1}, {"provide": 1, "finitesample": 1, "analysis": 1, "major": 1, "technical": 1, "novelty": 1, "lie": 1, "design": 1, "auxiliary": 1, "markov": 2, "chain": 2, "uniformly": 1, "ergodic": 1, "": 1, "approximate": 1, "original": 1, "induce": 1, "sarsa": 1, "algorithm": 1, "careful": 1, "decomposition": 1, "stochastic": 1, "bias": 1}, {"use": 1, "approach": 1, "gradient": 1, "bias": 1, "explicitly": 1, "characterize": 1}, {"together": 1, "gradient": 1, "descent": 1, "type": 1, "analysis": 2, "derive": 1, "finitesample": 1, "sarsa": 1, "algorithm": 1}, {"illustrate": 1, "main": 1, "idea": 1, "proof": 1, "provide": 1, "sketch": 1}, {"note": 1, "step": 1, "3": 1, "contain": 1, "major": 1, "technical": 1, "contributions": 1, "bias": 1, "characterization": 1, "timevarying": 1, "markov": 1, "process": 1}, {"proof": 1, "sketch": 1}, {"first": 1, "introduce": 1, "notations": 1}, {"fix": 1, "": 10, "2": 1, "rn": 1, "define": 1, "g": 2, "e": 1, "gt": 1, "xt": 1, "follow": 1, "stationary": 1, "distribution": 1, "p": 2, "xt1": 1, "at1": 1, "subsequent": 1, "action": 1, "state": 1, "generate": 1, "accord": 1, "policy": 1, "transition": 1, "kernel": 1, "interpret": 1, "noiseless": 1, "gradient": 1}, {"define": 1, "": 5, "h": 1, "gt": 1, "gi": 1}, {"5": 1, "thus": 1, "": 1, "measure": 1, "bias": 1, "cause": 1, "use": 1, "noniid": 1}, {"sample": 1, "estimate": 1, "gradient": 1}, {"step": 1, "1": 1}, {"error": 1, "decomposition": 1}, {"error": 1, "time": 1, "step": 1, "decompose": 1, "recursively": 1, "follow": 1, "ekt1": 1, "": 20, "2": 3, "k2": 3, "ekt": 1, "2t": 2, "eht": 1, "gt": 1, "g": 1, "t2": 1, "ekgt": 1, "et": 1}, {"6": 1, "": 1, "step": 1, "2": 1}, {"gradient": 1, "descent": 1, "type": 1, "analysis": 1}, {"first": 1, "three": 1, "term": 1, "6": 1, "mimic": 1, "analysis": 1, "gradient": 2, "descent": 1, "algorithm": 1, "without": 1, "noise": 1, "accurate": 1, "gt": 1, "use": 1}, {"due": 1, "projection": 1, "step": 1, "1": 1, "kgt": 1, "k2": 1, "upper": 1, "bound": 1, "g": 2, "also": 1, "show": 1, "eht": 1, "": 12, "gt": 1, "6": 1, "c": 1}, {"7": 1, "": 4, "large": 1, "c": 2, "ie": 1, "smooth": 1, "enough": 1, "respect": 1, "negative": 1, "definite": 1}, {"eht": 1, "": 11, "gt": 1, "g": 1, "ws": 1, "ekt": 1, "2": 1, "k2": 1}, {"8": 1, "": 1, "step": 1, "3": 1}, {"stochastic": 1, "bias": 1, "analysis": 1}, {"step": 1, "consist": 1, "major": 1, "technical": 1, "developments": 1}, {"last": 1, "term": 1, "6": 1, "bias": 1, "cause": 1, "use": 1, "single": 1, "sample": 1, "path": 1, "noniid": 1}, {"data": 1, "timevarying": 1, "behavior": 1, "policy": 1}, {"convenience": 1, "rewrite": 1, "": 8, "ot": 2, "xt": 1, "xt1": 1, "at1": 1}, {"bound": 1, "term": 1, "challenge": 1, "due": 1, "strong": 1, "dependency": 1, "ot": 1, "": 1}, {"first": 1, "show": 1, "": 3, "ot": 1, "lipschitz": 1}, {"due": 1, "projection": 1, "step": 1, "change": 1, "slowly": 1, "combine": 1, "two": 1, "facts": 1, "show": 1, "": 14, "0": 1, "ot": 2, "2": 1, "6": 1, "cg": 1, "1": 1, "x": 1}, {"9": 1, "": 5, "step": 1, "intend": 1, "decouple": 1, "dependency": 1, "ot": 2, "consider": 1}, {"markov": 1, "chain": 1, "xt": 1, "": 6, "0": 1, "induce": 1, "sarsa": 1, "uniformly": 1, "ergodic": 1, "satisfy": 1, "assumption": 1, "1": 1, "ot": 1, "would": 1, "reach": 1, "stationary": 1, "distribution": 1, "quickly": 1, "large": 1}, {"however": 1, "argument": 1, "necessarily": 1, "true": 1, "since": 1, "change": 2, "time": 2, "thus": 1, "transition": 1, "kernel": 1, "markov": 1, "chain": 1}, {"idea": 1, "construct": 1, "auxiliary": 1, "markov": 1, "chain": 1, "assist": 1, "proof": 1}, {"consider": 1, "follow": 1, "new": 1, "markov": 1, "chain": 1}, {"time": 2, "": 5, "1": 2, "state": 1, "action": 2, "generate": 2, "accord": 1, "sarsa": 1, "algorithm": 1, "behavior": 1, "policy": 1, "keep": 1, "fix": 1, "subsequent": 1}, {"denote": 1, "ot": 1, "": 6, "xt": 1, "xt1": 1, "at1": 1, "observations": 1, "new": 1, "markov": 1, "chain": 1, "time": 2, "1": 1}, {"new": 1, "markov": 1, "chain": 1, "large": 1, "": 12, "ot": 2, "reach": 1, "stationary": 1, "distribution": 1, "induce": 1, "p": 1, "show": 1, "et": 1, "4g2": 1, "1": 1}, {"10": 1, "": 1, "next": 1, "step": 1, "bind": 1, "difference": 1, "markov": 2, "chain": 2, "generate": 1, "sarsa": 1, "algorithm": 1, "auxiliary": 1, "construct": 1}, {"since": 1, "behavior": 1, "policy": 1, "change": 1, "slowly": 1, "due": 1, "lipschitz": 1, "property": 1, "small": 1, "step": 1, "size": 1, "": 1, "two": 1, "markov": 1, "chain": 1, "deviate": 1, "much": 1}, {"show": 1, "case": 2, "diminish": 1, "step": 2, "size": 2, "similar": 1, "argument": 1, "obtain": 1, "constant": 1, "et": 2, "": 14, "ot": 2, "cag3": 1, "log": 1}, {"w": 1, "": 4, "11": 2, "combine": 1, "9": 1, "10": 1, "yield": 1, "upper": 1, "bind": 1, "et": 1}, {"step": 1, "4": 1}, {"put": 1, "first": 1, "three": 1, "step": 2, "together": 1, "recursively": 1, "apply": 1, "1": 1, "complete": 1, "proof": 1}, {"4": 1, "": 2, "finitesample": 1, "analysis": 1, "fit": 3, "sarsa": 2, "algorithm": 3, "section": 1, "introduce": 1, "general": 2, "onpolicy": 2, "see": 1, "2": 1, "provide": 1, "framework": 1, "policy": 1, "iteration": 1}, {"specifically": 1, "policy": 2, "improvement": 1, "perform": 1, "fit": 1, "step": 1, "consist": 1, "b": 1, "td0": 1, "iterations": 1, "estimate": 1, "actionvalue": 1, "function": 1, "current": 1}, {"general": 1, "fit": 1, "sarsa": 2, "algorithm": 3, "contain": 1, "original": 1, "31": 1, "special": 2, "case": 2, "b": 2, "": 2, "1": 2, "28": 1, "another": 1, "ie": 1, "td0": 1, "converge": 1}, {"moreover": 1, "entire": 1, "algorithm": 1, "use": 1, "one": 1, "single": 1, "markov": 1, "trajectory": 1, "instead": 1, "restart": 1, "state": 1, "x0": 1, "policy": 1, "improvement": 1, "28": 1}, {"differently": 1, "exist": 1, "fit": 3, "policy": 3, "iteration": 2, "algorithms": 1, "regression": 1, "problem": 1, "model": 1, "solve": 1, "two": 1, "improvements": 2, "sarsa": 1, "algorithm": 1, "require": 1, "convergent": 1, "td": 1, "process": 1}, {"show": 1, "onpolicy": 1, "fit": 1, "sarsa": 1, "algorithm": 1, "guarantee": 1, "converge": 1, "arbitrary": 1, "b": 1}, {"overall": 1, "sample": 1, "complexity": 1, "fit": 1, "algorithm": 1, "provide": 1}, {"fact": 1, "need": 1, "number": 1, "b": 1, "td": 1, "iterations": 1, "fit": 1, "step": 1}, {"generally": 1, "set": 1, "number": 1, "td": 3, "iterations": 1, "differently": 1, "control": 1, "estimation": 1, "accuracy": 1, "7": 1, "": 22, "algorithm": 1, "2": 3, "general": 1, "fit": 1, "sarsa": 1, "initialization": 1, "0": 5, "x0": 1, "r": 1, "1": 9, "n": 1, "method": 1, "choose": 2, "a0": 1, "accord": 2, "learn": 1, "policy": 3, "tb": 2, "j": 1, "b": 1, "observe": 1, "xtbj": 1, "rxtbj": 1, "atbj": 2, "tbj": 4, "proj2r": 1, "gtbj": 1, "end": 2, "improvement": 1, "t1b": 2, "actionvalue": 1, "function": 1, "improvements": 1, "use": 1, "finitesample": 1, "bind": 1, "4": 1}, {"analysis": 1, "extend": 1, "general": 1, "scenario": 1, "straightforward": 1, "manner": 1, "mathematical": 1, "expressions": 1, "get": 1, "involve": 1}, {"thus": 1, "focus": 1, "simple": 1, "case": 1, "b": 1, "convey": 1, "central": 1, "idea": 1}, {"follow": 1, "theorem": 1, "provide": 1, "finitesample": 1, "bind": 1, "convergence": 1, "fit": 1, "sarsa": 1, "algorithm": 1}, {"theorem": 1, "3": 1}, {"consider": 1, "fit": 1, "sarsa": 1, "algorithm": 2, "linear": 1, "function": 1, "approximation": 1, "2": 1}, {"suppose": 1, "assumptions": 1, "1": 1, "2": 1, "hold": 1}, {"1": 3, "decay": 1, "step": 1, "size": 1, "": 30, "2tw": 1, "w": 1, "ws": 1, "2": 1, "ekt": 1, "b": 3, "k2": 1, "4g2": 2, "0": 3, "bw": 1, "log": 1, "16": 1, "cg2": 2, "65": 1, "cag3": 1, "02": 1, "05bg2": 1, "w2": 1, "bt": 1, "12": 1, "nb": 1}, {"sufficiently": 1, "large": 1, "": 10, "0": 1, "log": 2, "hence": 1, "ekt": 1, "infnb": 1, "3": 1, "2": 2, "k2": 1}, {"give": 2, "b": 2, "guarantee": 1, "accuracy": 1, "ekt": 1, "": 6, "k2": 1, "small": 1, "overall": 1, "sample": 1, "complexity": 1, "1": 2, "log3": 1}, {"2": 3, "constant": 1, "step": 1, "size": 1, "": 31, "0": 6, "ekt": 1, "b": 3, "e": 1, "1": 1, "2ws": 3, "k2": 2, "b0": 1, "k0": 1, "bg2": 1, "26": 1, "cg2": 1, "8g2": 1, "2ag3": 1, "02": 1, "13": 1, "infnb": 1, "mnb": 1}, {"item": 1, "2": 1, "theorem": 1, "3": 1, "indicate": 1, "small": 2, "enough": 2, "constant": 1, "step": 1, "size": 1, "large": 1, "": 3, "fit": 1, "sarsa": 1, "algorithm": 1, "converge": 1, "neighborhood": 1}, {"theorem": 1, "3": 1, "imply": 1, "fit": 2, "step": 1, "take": 1, "number": 1, "td": 1, "iterations": 1, "necessarily": 1, "converge": 1, "without": 1, "affect": 1, "overall": 1, "convergence": 1, "sample": 1, "complexity": 1, "sarsa": 1, "algorithm": 1}, {"particular": 1, "comparison": 1, "original": 1, "sarsa": 2, "fit": 1, "algorithms": 1, "indicate": 1, "overall": 1, "sample": 1, "complexity": 1}, {"hand": 1, "fit": 2, "sarsa": 2, "algorithm": 2, "computationally": 1, "efficient": 1, "due": 1, "follow": 1, "two": 1, "facts": 1, "number": 2, "sample": 1, "n0": 2, "": 1, "general": 1, "use": 1, "fewer": 1, "b": 2, "policy": 2, "improvement": 2, "operators": 1, "apply": 1, "operator": 1, "inner": 1, "product": 1, "tb": 1, "need": 1, "compute": 1, "complexity": 1, "scale": 1, "linearly": 1, "size": 1, "action": 1, "space": 1}, {"8": 1, "": 4, "5": 1, "discussion": 1, "lipschitz": 2, "continuity": 2, "assumption": 2, "section": 1, "discuss": 1, "policy": 1, "improvement": 1, "operator": 1, "play": 1, "important": 1, "role": 1, "convergence": 1, "sarsa": 1}, {"use": 1, "tabular": 1, "approach": 1, "store": 1, "actionvalues": 1, "convergence": 1, "sarsa": 1, "algorithm": 1, "establish": 1, "33": 1}, {"however": 1, "example": 1, "give": 1, "13": 1, "show": 1, "sarsa": 1, "function": 1, "approximation": 1, "greedy": 1, "policy": 1, "improvement": 1, "operator": 1, "chatter": 1, "converge": 1}, {"later": 1, "14": 1, "show": 1, "sarsa": 1, "converge": 1, "bound": 1, "region": 2, "although": 1, "may": 1, "large": 1, "diverge": 1, "qlearning": 1, "linear": 1, "function": 1, "approximation": 1}, {"one": 1, "possible": 1, "explanation": 1, "nonconvergent": 1, "behavior": 1, "sarsa": 1, "algorithm": 1, "greedy": 1, "softmax": 1, "policy": 1, "improvement": 1, "operators": 1, "discontinuity": 1, "action": 1, "selection": 1, "strategies": 1, "27": 1, "10": 1}, {"specifically": 1, "slight": 1, "change": 2, "estimate": 2, "actionvalue": 2, "function": 2, "may": 1, "result": 1, "big": 1, "behavior": 1, "policy": 1, "thus": 1, "yield": 1, "completely": 1, "different": 1}, {"toward": 1, "understand": 1, "convergence": 1, "sarsa": 2, "10": 1, "show": 2, "approximate": 1, "value": 1, "iteration": 1, "softmax": 1, "policy": 2, "improvement": 2, "guarantee": 2, "fix": 2, "point": 2, "however": 1, "may": 1, "unique": 1, "27": 1, "later": 1, "continuous": 1, "operator": 1, "exist": 1}, {"28": 1, "develop": 1, "convergent": 1, "form": 1, "sarsa": 1, "use": 1, "lipschitz": 2, "continuous": 1, "policy": 1, "improvement": 1, "operator": 1, "demonstrate": 1, "convergence": 1, "unique": 1, "limit": 1, "point": 1, "constant": 1, "large": 1}, {"discuss": 1, "27": 1, "nonconvergence": 1, "example": 2, "13": 1, "contradict": 1, "convergence": 2, "result": 1, "28": 1, "satisfy": 1, "lipschitz": 1, "continuity": 1, "condition": 1, "policy": 1, "improvement": 1, "operator": 1, "essential": 1, "guarantee": 1, "sarsa": 1}, {"paper": 1, "follow": 1, "line": 1, "reason": 1, "consider": 1, "lipschitz": 1, "continuous": 1, "policy": 1, "improvement": 1, "operators": 1}, {"discuss": 1, "28": 1, "lipschitz": 1, "constant": 1, "c": 1, "shall": 1, "choose": 1, "large": 1, "ensure": 1, "convergence": 1, "sarsa": 1, "algorithm": 1}, {"however": 1, "ensure": 1, "exploitation": 1, "one": 1, "generally": 1, "prefer": 1, "large": 1, "lipschitz": 1, "constant": 1, "c": 1, "agent": 1, "choose": 1, "action": 1, "higher": 1, "estimate": 1, "actionvalues": 1}, {"28": 1, "adaptive": 1, "approach": 1, "choose": 1, "policy": 1, "improvement": 1, "operator": 1, "proper": 1, "c": 1, "propose": 1}, {"also": 1, "note": 1, "28": 1, "possible": 1, "convergence": 1, "could": 1, "obtain": 1, "much": 1, "larger": 1, "c": 1, "one": 1, "suggest": 1, "theorems": 1, "1": 1, "2": 1, "3": 1}, {"however": 1, "important": 1, "open": 1, "problem": 1, "sarsa": 1, "algorithms": 3, "lipschitz": 1, "continuous": 2, "operator": 1, "also": 1, "action": 1, "selection": 1, "10": 1, "theoretical": 1, "performance": 1, "characterization": 1, "solutions": 1, "type": 1, "produce": 1}, {"thus": 1, "future": 1, "interest": 1, "investigate": 1, "performance": 1, "policy": 1, "generate": 1, "sarsa": 1, "algorithm": 1, "lipschitz": 1, "continuous": 1, "operator": 1}, {"6": 1, "": 2, "conclusion": 1, "paper": 1, "present": 1, "first": 1, "finitesample": 1, "analysis": 1, "sarsa": 1, "algorithm": 1, "continuous": 1, "state": 1, "space": 1, "linear": 1, "function": 1, "approximation": 1}, {"analysis": 1, "applicable": 1, "online": 1, "case": 1, "single": 1, "sample": 1, "path": 1, "noniid": 1}, {"data": 1}, {"particular": 1, "develop": 1, "novel": 1, "technique": 1, "handle": 1, "stochastic": 2, "bias": 1, "dynamically": 1, "change": 1, "behavior": 1, "policies": 1, "enable": 1, "nonasymptotic": 1, "analysis": 1, "type": 1, "approximation": 1, "algorithms": 1}, {"also": 1, "present": 1, "fit": 2, "sarsa": 1, "algorithm": 1, "provide": 1, "general": 1, "framework": 1, "iterative": 1, "onpolicy": 1, "policy": 1, "iterations": 1}, {"also": 1, "present": 1, "finitesample": 1, "analysis": 1, "fit": 1, "sarsa": 1, "algorithm": 1}, {"acknowledgement": 1, "would": 1, "like": 1, "thank": 1, "anonymous": 1, "reviewer": 1, "area": 1, "chair": 1, "valuable": 1, "comment": 1}, {"work": 1, "xu": 1, "liang": 1, "support": 1, "partby": 1, "us": 1, "national": 1, "science": 1, "foundation": 1, "grant": 1, "ccf1761506": 1, "eccs1818904": 1, "ccf1801855": 1}, {"9": 1, "": 1, "reference": 1, "1": 1, "antos": 1, "c": 1, "szepesvari": 1, "r": 1, "munos": 1}, {"learn": 1, "nearoptimal": 1, "policies": 1, "bellmanresidual": 1, "minimization": 1, "base": 1, "fit": 1, "policy": 1, "iteration": 1, "single": 1, "sample": 1, "path": 1}, {"machine": 1, "learn": 1, "71189": 1, "129": 1, "2008": 1}, {"2": 1, "k": 1, "asadi": 1, "l": 1, "littman": 1}, {"alternative": 1, "softmax": 1, "operator": 1, "reinforcement": 1, "learn": 1}, {"proc": 1}, {"international": 1, "conference": 1, "machine": 1, "learn": 1, "icml": 1, "2016": 1}, {"3": 1, "p": 1, "bertsekas": 1}, {"dynamic": 1, "program": 1, "optimal": 1, "control": 1, "volume": 1, "2": 1}, {"athena": 1, "scientific": 1, "3rd": 1, "edition": 1, "2012": 1}, {"4": 1, "j": 1, "bhandari": 1, "russo": 1, "r": 1, "singal": 1}, {"finite": 1, "time": 1, "analysis": 1, "temporal": 1, "difference": 1, "learn": 1, "linear": 1, "function": 1, "approximation": 1}, {"arxiv": 1, "preprint": 1, "arxiv180602450": 1, "2018": 1}, {"5": 1, "j": 1}, {"boyan": 1}, {"technical": 1, "update": 1, "leastsquares": 1, "temporal": 1, "difference": 1, "learn": 1}, {"machine": 1, "learn": 1, "49233246": 1, "2002": 1}, {"6": 1, "j": 1, "bradtke": 1, "g": 1, "barto": 1}, {"linear": 1, "leastsquares": 1, "algorithms": 1, "temporal": 1, "difference": 1, "learn": 1}, {"machine": 1, "learn": 1, "223357": 1, "1996": 1}, {"7": 1, "bubeck": 1, "et": 1, "al": 1}, {"convex": 1, "optimization": 1, "algorithms": 1, "complexity": 1}, {"foundations": 1, "trend": 1, "r": 1, "machine": 1, "learn": 1, "834231357": 1, "2015": 1}, {"8": 1, "g": 2, "dalal": 1, "b": 1, "szorenyi": 1, "thoppe": 1, "mannor": 1}, {"finite": 1, "sample": 1, "analysis": 1, "twotimescale": 1, "stochastic": 1, "approximation": 1, "applications": 1, "reinforcement": 1, "learn": 1}, {"proc": 1}, {"conference": 1, "learn": 1, "theory": 1, "colt": 1, "2018": 1}, {"9": 1, "g": 2, "dalal": 1, "b": 1, "szrnyi": 1, "thoppe": 1, "mannor": 1}, {"finite": 1, "sample": 1, "analyse": 1, "td0": 1, "function": 1, "approximation": 1}, {"proc": 1}, {"aaai": 2, "conference": 1, "artificial": 1, "intelligence": 1, "2018": 1}, {"10": 1, "p": 1, "de": 1, "farias": 1, "b": 1}, {"van": 1, "roy": 1}, {"existence": 1, "fix": 1, "point": 1, "approximate": 1, "value": 1, "iteration": 1, "temporaldifference": 1, "learn": 1}, {"journal": 1, "optimization": 1, "theory": 1, "applications": 1, "1053589608": 1, "2000": 1}, {"11": 1, "farahmand": 1, "c": 1, "szepesvari": 1, "r": 1, "munos": 1}, {"error": 1, "propagation": 1, "approximate": 1, "policy": 1, "value": 1, "iteration": 1}, {"proc": 1}, {"advance": 1, "neural": 1, "information": 1, "process": 1, "systems": 1, "nip": 1, "2010": 1}, {"12": 1, "ghavamzadeh": 1, "lazaric": 1, "maillard": 1, "r": 1, "munos": 1}, {"lstd": 1, "random": 1, "projections": 1}, {"proc": 1}, {"advance": 1, "neural": 1, "information": 1, "process": 1, "systems": 1, "nip": 1, "2010": 1}, {"13": 1, "g": 1, "j": 1, "gordon": 1}, {"chatter": 1, "sarsa": 1, "": 1, "cmu": 1, "learn": 1, "lab": 1, "internal": 1, "report": 1}, {"1996": 1}, {"14": 1, "g": 1, "j": 1, "gordon": 1}, {"reinforcement": 1, "learn": 1, "function": 1, "approximation": 1, "converge": 1, "region": 1}, {"proc": 1}, {"advance": 1, "neural": 1, "information": 1, "process": 1, "systems": 1, "neurips": 1, "page": 1, "10401046": 1, "2001": 1}, {"15": 1, "h": 1, "gupta": 1, "r": 1, "srikant": 1, "l": 1, "ying": 1}, {"finitetime": 1, "performance": 1, "bound": 1, "adaptive": 1, "learn": 2, "rate": 1, "selection": 1, "two": 1, "timescale": 1, "reinforcement": 1}, {"appear": 1, "proc": 1}, {"advance": 1, "neural": 1, "information": 1, "process": 1, "systems": 1, "neurips": 1, "2019": 1}, {"16": 1, "h": 1, "kushner": 1}, {"stochastic": 1, "approximation": 1, "survey": 1}, {"wiley": 1, "interdisciplinary": 1, "review": 1, "computational": 1, "statistics": 1, "218796": 1, "2010": 1}, {"17": 1, "lacostejulien": 1, "schmidt": 1, "f": 1, "bach": 1}, {"simpler": 1, "approach": 1, "obtain": 1, "o1t": 1, "convergence": 1, "rate": 1, "project": 1, "stochastic": 1, "subgradient": 1, "method": 1}, {"arxiv": 1, "preprint": 1, "arxiv12122002": 1, "2012": 1}, {"18": 1, "g": 1, "lagoudakis": 1, "r": 1, "parr": 1}, {"leastsquares": 1, "policy": 1, "iteration": 1}, {"journal": 1, "machine": 1, "learn": 1, "research": 1, "411071149": 1, "2003": 1}, {"19": 1, "c": 2, "lakshminarayanan": 1, "szepesvari": 1}, {"linear": 1, "stochastic": 1, "approximation": 1, "far": 1, "constant": 1, "stepsize": 1, "iterate": 1, "average": 1, "go": 1}, {"proc": 1}, {"international": 1, "conference": 1, "artificial": 1, "intelligence": 1, "statistics": 1, "aistats": 1, "2018": 1}, {"20": 1, "lazaric": 1, "ghavamzadeh": 1, "r": 1, "munos": 1}, {"finitesample": 1, "analysis": 1, "lstd": 1}, {"proc": 1}, {"international": 1, "conference": 1, "machine": 1, "learn": 1, "icml": 1, "2010": 1}, {"10": 1, "": 1, "21": 1, "lazaric": 1, "ghavamzadeh": 1, "r": 1, "munos": 1}, {"finitesample": 1, "analysis": 1, "leastsquares": 1, "policy": 1, "iteration": 1}, {"journal": 1, "machine": 1, "learn": 1, "research": 1, "1330413074": 1, "2012": 1}, {"22": 1, "lazaric": 1, "ghavamzadeh": 1, "r": 1, "munos": 1}, {"analysis": 1, "classificationbased": 1, "policy": 1, "iteration": 1, "algorithms": 1}, {"journal": 1, "machine": 1, "learn": 1, "research": 1, "17583612": 1, "2016": 1}, {"23": 1, "f": 1, "melo": 1, "p": 1, "meyn": 1, "ribeiro": 1}, {"analysis": 1, "reinforcement": 1, "learn": 1, "function": 1, "approximation": 1}, {"proc": 1}, {"international": 1, "conference": 1, "machine": 1, "learn": 1, "icml": 1, "page": 1, "664671": 1}, {"acm": 1, "2008": 1}, {"24": 1, "mitrophanov": 1}, {"sensitivity": 1, "convergence": 1, "uniformly": 1, "ergodic": 1, "markov": 1, "chain": 1}, {"journal": 1, "apply": 1, "probability": 1, "42410031014": 1, "2005": 1}, {"25": 1, "r": 1, "munos": 1, "c": 1, "szepesvari": 1}, {"finitetime": 1, "bound": 1, "fit": 1, "value": 1, "iteration": 1}, {"journal": 1, "machine": 1, "learn": 1, "research": 1, "9815857": 1, "may": 1, "2008": 1}, {"26": 1, "nemirovski": 1, "juditsky": 1, "g": 1, "lan": 1, "shapiro": 1}, {"robust": 1, "stochastic": 2, "approximation": 1, "approach": 1, "program": 1}, {"siam": 1, "journal": 1, "optimization": 1, "19415741609": 1, "2009": 1}, {"27": 1, "j": 1, "perkins": 1, "pendrith": 1}, {"existence": 1, "fix": 1, "point": 1, "qlearning": 1, "sarsa": 1, "partially": 1, "observable": 1, "domains": 1}, {"proc": 1}, {"international": 1, "conference": 1, "machine": 1, "learn": 1, "icml": 1, "page": 1, "490497": 1, "2002": 1}, {"28": 1, "j": 1, "perkins": 1, "precup": 1}, {"convergent": 1, "form": 1, "approximate": 1, "policy": 1, "iteration": 1}, {"proc": 1}, {"advance": 1, "neural": 1, "information": 1, "process": 1, "systems": 1, "neurips": 1, "page": 1, "16271634": 1, "2003": 1}, {"29": 1, "b": 1}, {"pires": 1, "c": 1, "szepesvari": 1}, {"statistical": 1, "linear": 1, "estimation": 1, "penalize": 1, "estimators": 1, "application": 1, "reinforcement": 1, "learn": 1}, {"proc": 1}, {"international": 1, "conference": 1, "machine": 1, "learn": 1, "icml": 1, "2012": 1}, {"30": 1, "l": 1, "prashanth": 1, "n": 1, "korda": 1, "r": 1, "munos": 1}, {"fast": 1, "lstd": 1, "use": 1, "stochastic": 1, "approximation": 1, "finite": 1, "time": 1, "analysis": 1, "application": 1, "traffic": 1, "control": 1}, {"proc": 1}, {"joint": 1, "european": 1, "conference": 1, "machine": 1, "learn": 1, "knowledge": 1, "discovery": 1, "databases": 1, "2013": 1}, {"31": 1, "g": 1, "rummery": 1, "niranjan": 1}, {"online": 1, "qlearning": 1, "use": 1, "connectionist": 1, "systems": 1}, {"technical": 1, "report": 1, "cambridge": 1, "university": 1, "engineer": 1, "department": 1, "sept": 1, "1994": 1}, {"32": 1, "shah": 1, "q": 1, "xie": 1}, {"qlearning": 1, "nearest": 1, "neighbor": 1}, {"proc": 1}, {"advance": 1, "neural": 1, "information": 1, "process": 1, "systems": 1, "neurips": 1, "2018": 1}, {"33": 1, "singh": 1, "jaakkola": 1, "l": 1, "littman": 1, "c": 1, "szepesvri": 1}, {"convergence": 1, "result": 1, "singlestep": 1, "onpolicy": 1, "reinforcementlearning": 1, "algorithms": 1}, {"machine": 1, "learn": 1, "383287308": 1, "2000": 1}, {"34": 1, "r": 1, "srikant": 1, "l": 1, "ying": 1}, {"finitetime": 1, "error": 1, "bound": 1, "linear": 1, "stochastic": 1, "approximation": 1, "td": 1, "learn": 1}, {"proc": 1}, {"annual": 1, "conference": 1, "learn": 1, "theory": 1, "colt": 1, "2019": 1}, {"35": 1, "tagorti": 1, "b": 1, "scherrer": 1}, {"rate": 1, "convergence": 1, "error": 1, "bound": 1, "lstd": 1, "": 2}, {"proc": 1}, {"international": 1, "conference": 1, "machine": 1, "learn": 1, "icml": 1, "2015": 1}, {"36": 1, "j": 1, "n": 1, "tsitsiklis": 1, "b": 1, "roy": 1}, {"analysis": 1, "temporaldifference": 1, "learn": 1, "function": 1, "approximation": 1}, {"ieee": 1, "transactions": 1, "automatic": 1, "control": 1, "425674690": 1, "may": 1, "1997": 1}, {"37": 1, "tu": 1, "b": 1, "recht": 1}, {"leastsquares": 1, "temporal": 1, "difference": 1, "learn": 1, "linear": 1, "quadratic": 1, "regulator": 1}, {"proc": 1}, {"international": 1, "conference": 1, "machine": 1, "learn": 1, "icml": 1, "2018": 1}, {"38": 1, "xu": 1, "zou": 1, "sand": 1, "liang": 1}, {"two": 1, "timescale": 1, "offpolicy": 1, "td": 1, "learn": 1, "nonasymptotic": 1, "analysis": 1, "markovian": 1, "sample": 1}, {"appear": 1, "proc": 1}, {"advance": 1, "neural": 1, "information": 1, "process": 1, "systems": 1, "neurips": 1, "2019": 1}, {"39": 1, "z": 2, "yang": 1, "xie": 1, "wang": 1}, {"theoretical": 1, "analysis": 1, "deep": 1, "qlearning": 1}, {"arxiv": 1, "190100137": 1, "jan": 1, "2019": 1}, {"11": 1}]